2025-03-26 02:26:02,013 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NameNode STARTUP_MSG:   host = master/172.20.1.14 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:02,018 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:02,087 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2025-03-26 02:26:02,183 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:02,244 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2025-03-26 02:26:02,244 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:02,252 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use master:9000 to access this namenode/service.
2025-03-26 02:26:02,252 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://master:9000
2025-03-26 02:26:02,363 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:02,377 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:26:02,379 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2025-03-26 02:26:02,385 INFO org.eclipse.jetty.util.log: Logging initialized @657ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:02,447 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:02,451 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2025-03-26 02:26:02,458 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:02,460 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-03-26 02:26:02,460 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:02,460 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:02,462 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-03-26 02:26:02,462 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:26:02,462 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:26:02,475 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-03-26 02:26:02,483 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2025-03-26 02:26:02,484 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:02,500 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:02,500 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:02,501 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:02,509 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:02,510 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b4c50bc{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:02,511 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79207381{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:26:02,542 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@c7045b9{hdfs,/,file:///hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/hdfs}
2025-03-26 02:26:02,546 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@17503f6b{HTTP/1.1, (http/1.1)}{0.0.0.0:9870}
2025-03-26 02:26:02,546 INFO org.eclipse.jetty.server.Server: Started @818ms
2025-03-26 02:26:02,687 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:26:02,687 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:26:02,714 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:26:02,736 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:26:02,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:26:02,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:26:02,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:26:02,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:26:02,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:26:02,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:26:02,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:26:02,755 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:02,758 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.15" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:02,759 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.16" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:02,759 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.17" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:02,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:26:02,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:26:02,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:26:02
2025-03-26 02:26:02,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:26:02,763 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:26:02,763 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:26:02,763 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:02,763 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:26:02,768 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:26:02,768 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:26:02,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:26:02,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:26:02,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:26:02,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:26:02,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:26:02,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:26:02,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:26:02,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:26:02,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:26:02,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:26:02,789 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:26:02,789 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:02,789 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:02,789 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:02,798 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:26:02,798 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:26:02,798 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:02,798 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:26:02,800 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:26:02,800 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:26:02,800 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:26:02,800 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:26:02,803 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:26:02,811 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:26:02,815 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:26:02,815 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:26:02,815 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:02,815 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:26:02,822 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:26:02,822 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:26:02,822 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:26:02,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2025-03-26 02:26:02,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-03-26 02:26:02,827 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 910.5 MB = 279.7 KB
2025-03-26 02:26:02,827 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2025-03-26 02:26:02,827 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:02,827 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2025-03-26 02:26:02,840 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 259@master
2025-03-26 02:26:02,861 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2025-03-26 02:26:02,861 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2025-03-26 02:26:02,861 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/tmp/dfs/name/current
2025-03-26 02:26:02,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:26:02,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:26:02,911 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:26:02,914 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/name/current/fsimage_0000000000000000000
2025-03-26 02:26:02,914 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:26:02,917 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2025-03-26 02:26:02,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-03-26 02:26:02,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 158 msecs
2025-03-26 02:26:02,987 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:26:03,072 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Enable NameNode state context:false
2025-03-26 02:26:03,072 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master:9000
2025-03-26 02:26:03,078 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:03,085 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2025-03-26 02:26:03,187 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-03-26 02:26:03,208 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2025-03-26 02:26:03,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor: Initialized the Default Decommission and Maintenance monitor
2025-03-26 02:26:03,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Start MarkedDeleteBlockScrubber thread
2025-03-26 02:26:03,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2025-03-26 02:26:03,221 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2025-03-26 02:26:03,221 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2025-03-26 02:26:03,221 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2025-03-26 02:26:03,270 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:03,271 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2025-03-26 02:26:03,275 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 39 msec
2025-03-26 02:26:03,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2025-03-26 02:26:03,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2025-03-26 02:26:03,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2025-03-26 02:26:03,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2025-03-26 02:26:03,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2025-03-26 02:26:03,279 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master/172.20.1.14:9000
2025-03-26 02:26:03,280 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 12 thread(s)
2025-03-26 02:26:03,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2025-03-26 02:26:03,286 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds name space=1 storage space=0 storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2025-03-26 02:26:03,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-03-26 02:26:04,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave0/172.20.1.15 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:04,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:04,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave1/172.20.1.16 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:04,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:04,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave2/172.20.1.17 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:04,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:04,606 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:26:04,681 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:04,727 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:26:04,727 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:04,778 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:26:04,797 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:26:04,847 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:04,856 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:26:04,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave0
2025-03-26 02:26:04,860 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:04,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:26:04,866 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:04,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:26:04,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:26:04,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:26:04,886 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:04,903 INFO org.eclipse.jetty.util.log: Logging initialized @916ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:04,927 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:26:04,927 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:04,953 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:26:04,953 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:04,970 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:04,976 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:26:04,981 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:04,983 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:26:04,983 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:04,983 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:05,044 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34903
2025-03-26 02:26:05,045 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:05,061 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:05,061 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:05,062 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:26:05,071 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:05,071 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:26:05,087 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:05,097 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:05,099 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:26:05,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2025-03-26 02:26:05,103 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:05,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:26:05,109 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:26:05,113 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:05,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2025-03-26 02:26:05,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:26:05,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:26:05,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:26:05,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:26:05,127 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:26:05,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:26:05,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:26:05,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:26:05,134 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:34903}
2025-03-26 02:26:05,136 INFO org.eclipse.jetty.server.Server: Started @1149ms
2025-03-26 02:26:05,164 INFO org.eclipse.jetty.util.log: Logging initialized @1178ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:05,177 INFO org.eclipse.jetty.util.log: Logging initialized @1149ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:05,179 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:26:05,236 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:26:05,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:26:05,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:26:05,249 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:05,255 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:26:05,255 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:05,259 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:05,262 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:05,264 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:26:05,264 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:05,264 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:05,265 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:26:05,273 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:05,274 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:26:05,274 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:05,275 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:05,275 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:05,292 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:26:05,345 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33911
2025-03-26 02:26:05,346 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:05,354 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37061
2025-03-26 02:26:05,355 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:05,374 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:05,374 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:05,375 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:26:05,376 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:05,376 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:05,378 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:26:05,386 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6c372fe6{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:05,387 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@14fa86ae{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:26:05,394 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6c372fe6{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:05,395 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@14fa86ae{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:26:05,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:26:05,440 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@42b02722{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:26:05,447 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@3370f42{HTTP/1.1, (http/1.1)}{localhost:37061}
2025-03-26 02:26:05,447 INFO org.eclipse.jetty.server.Server: Started @1420ms
2025-03-26 02:26:05,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:26:05,451 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@42b02722{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:26:05,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:26:05,458 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@3370f42{HTTP/1.1, (http/1.1)}{localhost:33911}
2025-03-26 02:26:05,458 INFO org.eclipse.jetty.server.Server: Started @1472ms
2025-03-26 02:26:05,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000 starting to offer service
2025-03-26 02:26:05,465 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:05,466 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:26:05,507 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:26:05,518 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:26:05,573 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:26:05,586 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:26:05,591 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:05,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:26:05,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:26:05,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:26:05,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:26:05,607 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:05,629 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:05,631 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:05,644 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:26:05,649 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:26:05,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000
2025-03-26 02:26:05,656 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:26:05,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 94@slave0
2025-03-26 02:26:05,661 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 906524901. Formatting...
2025-03-26 02:26:05,662 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-1fa7a2d5-3afc-43cd-bb62-99c452c21434 for directory /data/tmp/dfs/data
2025-03-26 02:26:05,709 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:05,709 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:05,710 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1131994297-172.20.1.14-1742955960730 is not formatted. Formatting ...
2025-03-26 02:26:05,711 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1131994297-172.20.1.14-1742955960730 directory /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current
2025-03-26 02:26:05,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=906524901;bpid=BP-1131994297-172.20.1.14-1742955960730;lv=-57;nsInfo=lv=-66;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730;bpid=BP-1131994297-172.20.1.14-1742955960730;dnuuid=null
2025-03-26 02:26:05,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 7372a77e-76ec-4505-ae05-24bed3ec1154
2025-03-26 02:26:05,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:26:05,809 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1fa7a2d5-3afc-43cd-bb62-99c452c21434
2025-03-26 02:26:05,809 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:26:05,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:26:05,816 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:26:05,823 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:26:05,834 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:05,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data...
2025-03-26 02:26:05,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:26:05,844 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current, will proceed with Du for space computation calculation,
2025-03-26 02:26:05,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:26:05,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:26:05,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:26:05,872 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1131994297-172.20.1.14-1742955960730 on /data/tmp/dfs/data: 37ms
2025-03-26 02:26:05,872 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1131994297-172.20.1.14-1742955960730: 38ms
2025-03-26 02:26:05,873 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current/replicas doesn't exist
2025-03-26 02:26:05,873 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data...
2025-03-26 02:26:05,875 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data: 2ms
2025-03-26 02:26:05,875 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730: 3ms
2025-03-26 02:26:05,876 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:26:05,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:26:05,881 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:05,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000 starting to offer service
2025-03-26 02:26:05,883 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:26:05,888 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:26:05,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000 starting to offer service
2025-03-26 02:26:05,891 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data
2025-03-26 02:26:05,893 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-1fa7a2d5-3afc-43cd-bb62-99c452c21434): finished scanning block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:05,932 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:26:05,933 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 9185836ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:26:05,936 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-1fa7a2d5-3afc-43cd-bb62-99c452c21434): no suitable block pools found to scan.  Waiting 1814399956 ms.
2025-03-26 02:26:05,941 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:05,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1131994297-172.20.1.14-1742955960730 (Datanode Uuid 7372a77e-76ec-4505-ae05-24bed3ec1154) service to master/172.20.1.14:9000 beginning handshake with NN
2025-03-26 02:26:05,954 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:26:06,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000
2025-03-26 02:26:06,032 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:26:06,035 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) storage 7372a77e-76ec-4505-ae05-24bed3ec1154
2025-03-26 02:26:06,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 7372a77e-76ec-4505-ae05-24bed3ec1154 (172.20.1.15:9866).
2025-03-26 02:26:06,037 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.15:9866
2025-03-26 02:26:06,041 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 94@slave2
2025-03-26 02:26:06,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000
2025-03-26 02:26:06,042 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 906524901. Formatting...
2025-03-26 02:26:06,043 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-c12092e2-d9e7-4706-8df0-65851dfa26a7 for directory /data/tmp/dfs/data
2025-03-26 02:26:06,047 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:26:06,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1131994297-172.20.1.14-1742955960730 (Datanode Uuid 7372a77e-76ec-4505-ae05-24bed3ec1154) service to master/172.20.1.14:9000 successfully registered with NN
2025-03-26 02:26:06,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.14:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:26:06,053 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 95@slave1
2025-03-26 02:26:06,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 906524901. Formatting...
2025-03-26 02:26:06,056 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-2c4eafe5-9696-4689-8eec-e64beca8b021 for directory /data/tmp/dfs/data
2025-03-26 02:26:06,075 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,075 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,076 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1131994297-172.20.1.14-1742955960730 is not formatted. Formatting ...
2025-03-26 02:26:06,076 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1131994297-172.20.1.14-1742955960730 directory /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current
2025-03-26 02:26:06,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=906524901;bpid=BP-1131994297-172.20.1.14-1742955960730;lv=-57;nsInfo=lv=-66;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730;bpid=BP-1131994297-172.20.1.14-1742955960730;dnuuid=null
2025-03-26 02:26:06,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 95dfd055-2daa-423b-a78c-81d3cae22127
2025-03-26 02:26:06,095 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,095 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,096 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1131994297-172.20.1.14-1742955960730 is not formatted. Formatting ...
2025-03-26 02:26:06,096 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:26:06,097 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1131994297-172.20.1.14-1742955960730 directory /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current
2025-03-26 02:26:06,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=906524901;bpid=BP-1131994297-172.20.1.14-1742955960730;lv=-57;nsInfo=lv=-66;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730;bpid=BP-1131994297-172.20.1.14-1742955960730;dnuuid=null
2025-03-26 02:26:06,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID a786e12c-eb47-49c4-acb5-28b43b2d2445
2025-03-26 02:26:06,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-1fa7a2d5-3afc-43cd-bb62-99c452c21434 for DN 172.20.1.15:9866
2025-03-26 02:26:06,120 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:26:06,166 INFO BlockStateChange: BLOCK* processReport 0xf7298045d0d81d26 with lease ID 0xe75520fbc87ea02c: Processing first storage report for DS-1fa7a2d5-3afc-43cd-bb62-99c452c21434 from datanode DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730)
2025-03-26 02:26:06,168 INFO BlockStateChange: BLOCK* processReport 0xf7298045d0d81d26 with lease ID 0xe75520fbc87ea02c: from storage DS-1fa7a2d5-3afc-43cd-bb62-99c452c21434 node DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2025-03-26 02:26:06,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c12092e2-d9e7-4706-8df0-65851dfa26a7
2025-03-26 02:26:06,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:26:06,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xf7298045d0d81d26 with lease ID 0xe75520fbc87ea02c to namenode: master/172.20.1.14:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msecs to generate and 70 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:26:06,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:26:06,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,209 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:26:06,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-2c4eafe5-9696-4689-8eec-e64beca8b021
2025-03-26 02:26:06,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:26:06,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:26:06,233 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:26:06,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,241 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data...
2025-03-26 02:26:06,249 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,250 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data...
2025-03-26 02:26:06,253 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current, will proceed with Du for space computation calculation,
2025-03-26 02:26:06,261 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current, will proceed with Du for space computation calculation,
2025-03-26 02:26:06,288 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1131994297-172.20.1.14-1742955960730 on /data/tmp/dfs/data: 48ms
2025-03-26 02:26:06,288 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1131994297-172.20.1.14-1742955960730: 48ms
2025-03-26 02:26:06,304 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1131994297-172.20.1.14-1742955960730 on /data/tmp/dfs/data: 53ms
2025-03-26 02:26:06,304 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1131994297-172.20.1.14-1742955960730: 55ms
2025-03-26 02:26:06,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current/replicas doesn't exist
2025-03-26 02:26:06,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data...
2025-03-26 02:26:06,306 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data: 1ms
2025-03-26 02:26:06,307 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:26:06,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730: 2ms
2025-03-26 02:26:06,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1131994297-172.20.1.14-1742955960730/current/replicas doesn't exist
2025-03-26 02:26:06,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data...
2025-03-26 02:26:06,312 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:26:06,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data: 1ms
2025-03-26 02:26:06,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1131994297-172.20.1.14-1742955960730: 23ms
2025-03-26 02:26:06,315 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:26:06,319 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data
2025-03-26 02:26:06,322 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-2c4eafe5-9696-4689-8eec-e64beca8b021): finished scanning block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,334 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:26:06,335 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:26:06,336 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 15753932ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:26:06,337 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1131994297-172.20.1.14-1742955960730 on volume /data/tmp/dfs/data
2025-03-26 02:26:06,338 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-2c4eafe5-9696-4689-8eec-e64beca8b021): no suitable block pools found to scan.  Waiting 1814399981 ms.
2025-03-26 02:26:06,339 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-c12092e2-d9e7-4706-8df0-65851dfa26a7): finished scanning block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,341 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 5075032ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:26:06,341 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:26:06,351 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-c12092e2-d9e7-4706-8df0-65851dfa26a7): no suitable block pools found to scan.  Waiting 1814399986 ms.
2025-03-26 02:26:06,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1131994297-172.20.1.14-1742955960730 (Datanode Uuid 95dfd055-2daa-423b-a78c-81d3cae22127) service to master/172.20.1.14:9000 beginning handshake with NN
2025-03-26 02:26:06,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1131994297-172.20.1.14-1742955960730 (Datanode Uuid a786e12c-eb47-49c4-acb5-28b43b2d2445) service to master/172.20.1.14:9000 beginning handshake with NN
2025-03-26 02:26:06,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.16:9866, datanodeUuid=a786e12c-eb47-49c4-acb5-28b43b2d2445, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) storage a786e12c-eb47-49c4-acb5-28b43b2d2445
2025-03-26 02:26:06,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN a786e12c-eb47-49c4-acb5-28b43b2d2445 (172.20.1.16:9866).
2025-03-26 02:26:06,479 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.16:9866
2025-03-26 02:26:06,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1131994297-172.20.1.14-1742955960730 (Datanode Uuid a786e12c-eb47-49c4-acb5-28b43b2d2445) service to master/172.20.1.14:9000 successfully registered with NN
2025-03-26 02:26:06,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.14:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:26:06,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) storage 95dfd055-2daa-423b-a78c-81d3cae22127
2025-03-26 02:26:06,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 95dfd055-2daa-423b-a78c-81d3cae22127 (172.20.1.17:9866).
2025-03-26 02:26:06,492 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.17:9866
2025-03-26 02:26:06,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1131994297-172.20.1.14-1742955960730 (Datanode Uuid 95dfd055-2daa-423b-a78c-81d3cae22127) service to master/172.20.1.14:9000 successfully registered with NN
2025-03-26 02:26:06,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.14:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:26:06,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2c4eafe5-9696-4689-8eec-e64beca8b021 for DN 172.20.1.16:9866
2025-03-26 02:26:06,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c12092e2-d9e7-4706-8df0-65851dfa26a7 for DN 172.20.1.17:9866
2025-03-26 02:26:06,539 INFO BlockStateChange: BLOCK* processReport 0xba6cb9ebbd96a0ad with lease ID 0xe75520fbc87ea02d: Processing first storage report for DS-2c4eafe5-9696-4689-8eec-e64beca8b021 from datanode DatanodeRegistration(172.20.1.16:9866, datanodeUuid=a786e12c-eb47-49c4-acb5-28b43b2d2445, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730)
2025-03-26 02:26:06,539 INFO BlockStateChange: BLOCK* processReport 0xba6cb9ebbd96a0ad with lease ID 0xe75520fbc87ea02d: from storage DS-2c4eafe5-9696-4689-8eec-e64beca8b021 node DatanodeRegistration(172.20.1.16:9866, datanodeUuid=a786e12c-eb47-49c4-acb5-28b43b2d2445, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 02:26:06,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xba6cb9ebbd96a0ad with lease ID 0xe75520fbc87ea02d to namenode: master/172.20.1.14:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msecs to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:26:06,552 INFO BlockStateChange: BLOCK* processReport 0x4d40fad29ab6a7b1 with lease ID 0xe75520fbc87ea02e: Processing first storage report for DS-c12092e2-d9e7-4706-8df0-65851dfa26a7 from datanode DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730)
2025-03-26 02:26:06,552 INFO BlockStateChange: BLOCK* processReport 0x4d40fad29ab6a7b1 with lease ID 0xe75520fbc87ea02e: from storage DS-c12092e2-d9e7-4706-8df0-65851dfa26a7 node DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 02:26:06,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1131994297-172.20.1.14-1742955960730
2025-03-26 02:26:06,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x4d40fad29ab6a7b1 with lease ID 0xe75520fbc87ea02e to namenode: master/172.20.1.14:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msecs to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:26:07,294 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting SecondaryNameNode STARTUP_MSG:   host = master/172.20.1.14 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:07,300 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:07,558 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:07,602 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:07,602 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2025-03-26 02:26:07,891 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:26:07,904 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/namesecondary/in_use.lock acquired by nodename 466@master
2025-03-26 02:26:07,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:26:07,940 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:26:07,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:26:07,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:26:07,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:26:07,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:26:07,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:26:07,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:26:07,980 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:07,986 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.15" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:07,986 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.16" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:07,986 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.17" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:07,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:26:07,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:26:07,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:26:07
2025-03-26 02:26:07,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:26:08,000 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:26:08,000 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:08,001 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:26:08,001 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:26:08,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:26:08,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:26:08,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:26:08,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:26:08,108 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:26:08,108 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:08,108 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:08,108 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:08,120 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:26:08,120 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:26:08,120 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:08,120 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:26:08,121 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:26:08,121 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:26:08,121 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:26:08,121 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:26:08,129 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:26:08,136 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:26:08,142 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:26:08,142 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:26:08,142 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:08,142 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:26:08,150 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:26:08,150 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:26:08,150 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:26:08,165 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2025-03-26 02:26:08,165 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2025-03-26 02:26:08,166 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:26:08,173 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:9868
2025-03-26 02:26:08,190 INFO org.eclipse.jetty.util.log: Logging initialized @1192ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:08,251 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:08,254 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2025-03-26 02:26:08,260 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:08,262 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:08,262 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2025-03-26 02:26:08,262 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:08,265 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:26:08,265 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context secondary
2025-03-26 02:26:08,265 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:26:08,285 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9868
2025-03-26 02:26:08,286 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:08,305 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:08,305 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:08,306 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:08,315 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:08,317 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b73be9f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:26:08,317 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d9b7a8a{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:08,354 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@62e6b5c8{secondary,/,file:///hadoop/share/hadoop/hdfs/webapps/secondary/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/secondary}
2025-03-26 02:26:08,359 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2025-03-26 02:26:08,359 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6622fc65{HTTP/1.1, (http/1.1)}{0.0.0.0:9868}
2025-03-26 02:26:08,359 INFO org.eclipse.jetty.server.Server: Started @1362ms
2025-03-26 02:26:10,803 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting ResourceManager STARTUP_MSG:   host = master/172.20.1.14 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:10,808 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:11,065 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMInfo MBean
2025-03-26 02:26:11,070 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/hadoop/etc/hadoop/core-site.xml
2025-03-26 02:26:11,104 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:11,104 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:11,126 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/hadoop/etc/hadoop/yarn-site.xml
2025-03-26 02:26:11,131 INFO org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics: Registering GenericEventTypeMetrics
2025-03-26 02:26:11,132 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2025-03-26 02:26:11,154 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2025-03-26 02:26:11,158 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2025-03-26 02:26:11,164 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2025-03-26 02:26:11,182 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2025-03-26 02:26:11,183 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2025-03-26 02:26:11,183 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2025-03-26 02:26:11,203 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2025-03-26 02:26:11,204 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2025-03-26 02:26:11,204 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2025-03-26 02:26:11,204 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2025-03-26 02:26:11,235 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:11,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2025-03-26 02:26:11,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:11,264 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2025-03-26 02:26:11,266 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2025-03-26 02:26:11,270 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2025-03-26 02:26:11,503 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2025-03-26 02:26:11,504 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.
2025-03-26 02:26:11,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager
2025-03-26 02:26:11,508 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.15" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:11,508 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.16" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:11,508 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.17" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:11,508 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2025-03-26 02:26:11,511 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/hadoop/etc/hadoop/capacity-scheduler.xml
2025-03-26 02:26:11,515 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Maximum allocation = <memory:8192, vCores:4>
2025-03-26 02:26:11,515 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1024, vCores:1>
2025-03-26 02:26:11,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*, , reservationsContinueLooking=true, orderingPolicy=utilization, priority=0
2025-03-26 02:26:11,552 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2025-03-26 02:26:11,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root
2025-03-26 02:26:11,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root.default
2025-03-26 02:26:11,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing root.default capacity = 1.0 [= (float) configuredCapacity / 100 ] absoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ] maxCapacity = 1.0 [= configuredMaxCapacity ] absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ] effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0> userLimit = 100 [= configuredUserLimit ] userLimitFactor = 1.0 [= configuredUserLimitFactor ] maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)] maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ] maxParallelApps = 2147483647 usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)] absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory] maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ] minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ] maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ] numContainers = 0 [= currentNumContainers ] state = RUNNING [= configuredState ] acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ] nodeLocalityDelay = 40 rackLocalityAdditionalDelay = -1 labels=*, reservationsContinueLooking = true preemptionDisabled = true defaultAppPriorityPerQueue = 0 priority = 0 maxLifetime = -1 seconds defaultLifetime = -1 seconds
2025-03-26 02:26:11,564 INFO org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false
2025-03-26 02:26:11,564 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2025-03-26 02:26:11,564 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.WorkflowPriorityMappingsManager: Initialized workflow priority mappings, override: false
2025-03-26 02:26:11,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false, assignMultipleEnabled=true, maxAssignPerHeartbeat=100, offswitchPerHeartbeatLimit=1
2025-03-26 02:26:11,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are
2025-03-26 02:26:11,573 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2025-03-26 02:26:11,578 INFO org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].
2025-03-26 02:26:11,578 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.
2025-03-26 02:26:11,578 INFO tp top of AMS Processing chain.
2025-03-26 02:26:11,584 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: TimelineServicePublisher is not configured
2025-03-26 02:26:11,605 INFO org.eclipse.jetty.util.log: Logging initialized @1066ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:11,694 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:11,697 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2025-03-26 02:26:11,701 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:11,703 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2025-03-26 02:26:11,703 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2025-03-26 02:26:11,703 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2025-03-26 02:26:11,704 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2025-03-26 02:26:11,704 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:11,704 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:11,951 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:11,954 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2025-03-26 02:26:11,955 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:11,972 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:11,972 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:11,972 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:11,983 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:11,987 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:11,997 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:26:11,997 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:11,999 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@232a7d73{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:11,999 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@305a0c5f{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:12,574 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@7add323c{cluster,/,file:///tmp/jetty-master-8088-hadoop-yarn-common-3_3_4_jar-_-any-3454262265508703596/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/cluster}
2025-03-26 02:26:12,580 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@5b068087{HTTP/1.1, (http/1.1)}{master:8088}
2025-03-26 02:26:12,581 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2025-03-26 02:26:12,581 INFO org.eclipse.jetty.server.Server: Started @2042ms
2025-03-26 02:26:12,728 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:12,772 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2025-03-26 02:26:12,897 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:12,897 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2025-03-26 02:26:12,898 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2025-03-26 02:26:12,898 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2025-03-26 02:26:12,907 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:26:12,907 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:12,907 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:26:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:26:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2025-03-26 02:26:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2025-03-26 02:26:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2025-03-26 02:26:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2025-03-26 02:26:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2025-03-26 02:26:12,908 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2025-03-26 02:26:12,984 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Created store directory :file:/tmp/hadoop-yarn-root/node-attribute
2025-03-26 02:26:13,000 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished create editlog file at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.editlog
2025-03-26 02:26:13,000 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished write mirror at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.mirror
2025-03-26 02:26:13,013 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$ForwardingEventHandler
2025-03-26 02:26:13,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Starting NodeSortingService=MultiNodeSortingManager
2025-03-26 02:26:13,020 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:13,021 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2025-03-26 02:26:13,023 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:13,023 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2025-03-26 02:26:13,025 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2025-03-26 02:26:13,030 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:13,038 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:13,040 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2025-03-26 02:26:13,044 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2025-03-26 02:26:13,045 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:13,045 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2025-03-26 02:26:13,101 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:13,101 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2025-03-26 02:26:13,103 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2025-03-26 02:26:13,104 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:13,104 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2025-03-26 02:26:13,253 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave0/172.20.1.15 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:13,259 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:13,301 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave2/172.20.1.17 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:13,308 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:13,351 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave1/172.20.1.16 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:13,365 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:13,416 INFO org.apache.hadoop.yarn.server.webproxy.ProxyCA: Created Certificate for OU=YARN-fbb1e7f7-a6c6-4932-987f-6e22311864de
2025-03-26 02:26:13,466 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2025-03-26 02:26:13,466 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing CA Certificate and Private Key
2025-03-26 02:26:13,586 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:26:13,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:26:13,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:26:13,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:26:13,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:26:13,680 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:26:13,694 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:26:13,694 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:26:13,695 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:26:13,748 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:26:13,749 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:26:13,749 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:26:13,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:26:13,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:26:13,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:26:13,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:26:13,751 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:26:13,760 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:26:13,760 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:26:13,790 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:13,834 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:13,835 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:26:13,840 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:26:13,855 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:13,864 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:13,882 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:26:13,883 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:26:13,883 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:26:13,884 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:26:13,884 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:26:13,884 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:26:13,885 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:26:13,886 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:26:13,895 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:26:13,896 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:26:13,897 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:26:13,897 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:26:13,897 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:26:13,900 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:26:13,900 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:26:13,904 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:26:13,905 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:26:13,905 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:26:13,906 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:26:13,906 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:26:13,906 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:26:13,907 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:26:13,908 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:26:13,911 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:26:13,921 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:26:13,922 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:26:13,922 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:26:13,922 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:26:13,923 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:26:13,937 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:13,938 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:13,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:26:13,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:26:13,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:26:13,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:26:13,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:26:13,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:26:13,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:26:13,940 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:26:13,941 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:26:13,941 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:26:13,942 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:13,942 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:26:13,965 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:13,965 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:26:13,996 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:14,012 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:26:14,012 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:14,020 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:26:14,036 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:14,038 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:26:14,042 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:26:14,042 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:14,047 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:14,052 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:26:14,067 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:26:14,068 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:14,068 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:26:14,068 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:14,071 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave0:38849
2025-03-26 02:26:14,076 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:14,077 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:26:14,079 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:14,080 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:26:14,080 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:26:14,081 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:14,081 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:26:14,081 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:26:14,082 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:26:14,083 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:26:14,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:26:14,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:26:14,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave0/172.20.1.15:38849
2025-03-26 02:26:14,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:26:14,083 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:26:14,087 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:26:14,101 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:26:14,109 INFO org.eclipse.jetty.util.log: Logging initialized @1156ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:14,113 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:26:14,113 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:26:14,115 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:26:14,115 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:26:14,115 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:26:14,116 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:26:14,116 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:26:14,116 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:26:14,134 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:14,134 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:14,135 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:26:14,136 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:26:14,136 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:26:14,136 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:26:14,136 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:26:14,136 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:26:14,136 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:26:14,136 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:26:14,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:26:14,139 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:26:14,139 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:26:14,140 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:26:14,144 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:26:14,149 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:26:14,151 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:26:14,152 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:26:14,171 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:14,171 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:14,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:26:14,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:26:14,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:26:14,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:26:14,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:26:14,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:26:14,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:26:14,176 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:26:14,177 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:26:14,177 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:26:14,178 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:26:14,182 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:26:14,185 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:14,192 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:26:14,196 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:14,198 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:14,199 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:26:14,199 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:26:14,199 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:26:14,199 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:14,199 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:26:14,199 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:14,215 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:14,255 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:26:14,268 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:26:14,304 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:26:14,305 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:14,310 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:26:14,315 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave2:36643
2025-03-26 02:26:14,316 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:14,316 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:26:14,321 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:14,321 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:26:14,323 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:26:14,327 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:14,327 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:26:14,327 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:26:14,327 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:26:14,328 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave1:36879
2025-03-26 02:26:14,332 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:26:14,332 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave2/172.20.1.17:36643
2025-03-26 02:26:14,332 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:26:14,334 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:14,334 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:26:14,336 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:26:14,337 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:14,337 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:26:14,337 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:26:14,337 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:26:14,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:26:14,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave1/172.20.1.16:36879
2025-03-26 02:26:14,341 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:26:14,345 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:26:14,358 INFO org.eclipse.jetty.util.log: Logging initialized @1411ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:14,368 INFO org.eclipse.jetty.util.log: Logging initialized @1401ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:14,440 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:14,447 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:14,452 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:26:14,452 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:14,453 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:26:14,453 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:14,457 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:26:14,461 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:14,463 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:14,463 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:26:14,463 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:14,463 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:14,464 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:26:14,464 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:26:14,464 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:26:14,464 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:26:14,465 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:26:14,465 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:26:14,465 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:26:14,465 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:14,465 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:14,476 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:14,476 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:14,478 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:26:14,494 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:14,496 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:14,497 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:14,805 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:26:14,805 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:14,806 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:14,816 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:14,817 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:26:14,818 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:14,826 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:14,826 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:14,827 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:14,840 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:14,840 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:14,840 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:14,842 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:26:14,848 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:14,848 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:14,858 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:14,867 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:14,868 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:14,970 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-5313344545582701108/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:26:14,975 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:26:14,975 INFO org.eclipse.jetty.server.Server: Started @2023ms
2025-03-26 02:26:14,976 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:26:14,982 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave0:38849
2025-03-26 02:26:14,987 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8031
2025-03-26 02:26:14,998 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:15,470 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-8324026379750739778/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:26:15,478 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:26:15,478 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:26:15,478 INFO org.eclipse.jetty.server.Server: Started @2531ms
2025-03-26 02:26:15,479 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave2:36643
2025-03-26 02:26:15,486 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8031
2025-03-26 02:26:15,507 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:15,510 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave0:38849 Node Transitioned from NEW to RUNNING
2025-03-26 02:26:15,530 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-556259671424845957/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:26:15,539 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:26:15,539 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:26:15,539 INFO org.eclipse.jetty.server.Server: Started @2572ms
2025-03-26 02:26:15,540 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave0(cmPort: 38849 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave0:38849
2025-03-26 02:26:15,554 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave1:36879
2025-03-26 02:26:15,554 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 2126508117
2025-03-26 02:26:15,554 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave0:38849 clusterResource: <memory:8192, vCores:8>
2025-03-26 02:26:15,555 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:15,555 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave0:38849 with total resource of <memory:8192, vCores:8>
2025-03-26 02:26:15,555 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 538124754
2025-03-26 02:26:15,561 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8031
2025-03-26 02:26:15,703 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave2(cmPort: 36643 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave2:36643
2025-03-26 02:26:15,703 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave2:36643 Node Transitioned from NEW to RUNNING
2025-03-26 02:26:15,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave2:36643 clusterResource: <memory:16384, vCores:16>
2025-03-26 02:26:15,714 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave2:36643 with total resource of <memory:8192, vCores:8>
2025-03-26 02:26:15,714 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 2126508117
2025-03-26 02:26:15,714 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 538124754
2025-03-26 02:26:15,735 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave1(cmPort: 36879 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave1:36879
2025-03-26 02:26:15,736 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave1:36879 Node Transitioned from NEW to RUNNING
2025-03-26 02:26:15,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave1:36879 clusterResource: <memory:24576, vCores:24>
2025-03-26 02:26:15,744 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave1:36879 with total resource of <memory:8192, vCores:8>
2025-03-26 02:26:15,744 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 2126508117
2025-03-26 02:26:15,744 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 538124754
2025-03-26 02:26:16,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:16,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:16,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /file.txt._COPYING_
2025-03-26 02:26:17,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741825_1001 src: /172.20.1.14:32768 dest: /172.20.1.17:9866
2025-03-26 02:26:17,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741825_1001 src: /172.20.1.17:33902 dest: /172.20.1.16:9866
2025-03-26 02:26:17,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741825_1001 src: /172.20.1.16:58224 dest: /172.20.1.15:9866
2025-03-26 02:26:17,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58224, dest: /172.20.1.15:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1116486006_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741825_1001, duration(ns): 26771635
2025-03-26 02:26:17,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33902, dest: /172.20.1.16:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1116486006_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741825_1001, duration(ns): 27051489
2025-03-26 02:26:17,172 INFO terminating
2025-03-26 02:26:17,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:32768, dest: /172.20.1.17:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1116486006_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741825_1001, duration(ns): 28591559
2025-03-26 02:26:17,176 INFO terminating
2025-03-26 02:26:17,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /file.txt._COPYING_
2025-03-26 02:26:17,589 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /file.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1116486006_1
2025-03-26 02:26:19,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /cluster.txt._COPYING_
2025-03-26 02:26:19,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741826_1002 src: /172.20.1.14:51530 dest: /172.20.1.15:9866
2025-03-26 02:26:19,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741826_1002 src: /172.20.1.15:39388 dest: /172.20.1.16:9866
2025-03-26 02:26:19,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741826_1002 src: /172.20.1.16:52370 dest: /172.20.1.17:9866
2025-03-26 02:26:19,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52370, dest: /172.20.1.17:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1073978964_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741826_1002, duration(ns): 5202724
2025-03-26 02:26:19,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39388, dest: /172.20.1.16:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1073978964_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741826_1002, duration(ns): 15090223
2025-03-26 02:26:19,148 INFO terminating
2025-03-26 02:26:19,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51530, dest: /172.20.1.15:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1073978964_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741826_1002, duration(ns): 16723539
2025-03-26 02:26:19,150 INFO terminating
2025-03-26 02:26:19,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /cluster.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1073978964_1
2025-03-26 02:26:20,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /page.txt._COPYING_
2025-03-26 02:26:20,547 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741827_1003 src: /172.20.1.14:34366 dest: /172.20.1.17:9866
2025-03-26 02:26:20,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741827_1003 src: /172.20.1.17:50542 dest: /172.20.1.15:9866
2025-03-26 02:26:20,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741827_1003 src: /172.20.1.15:39402 dest: /172.20.1.16:9866
2025-03-26 02:26:20,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39402, dest: /172.20.1.16:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-797582283_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741827_1003, duration(ns): 9811988
2025-03-26 02:26:20,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50542, dest: /172.20.1.15:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-797582283_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741827_1003, duration(ns): 11088776
2025-03-26 02:26:20,618 INFO terminating
2025-03-26 02:26:20,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34366, dest: /172.20.1.17:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-797582283_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741827_1003, duration(ns): 12250070
2025-03-26 02:26:20,619 INFO terminating
2025-03-26 02:26:20,622 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /page.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-797582283_1
2025-03-26 02:26:22,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /lr_test.txt._COPYING_
2025-03-26 02:26:22,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741828_1004 src: /172.20.1.14:34372 dest: /172.20.1.17:9866
2025-03-26 02:26:22,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741828_1004 src: /172.20.1.17:33918 dest: /172.20.1.16:9866
2025-03-26 02:26:22,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741828_1004 src: /172.20.1.16:58232 dest: /172.20.1.15:9866
2025-03-26 02:26:22,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58232, dest: /172.20.1.15:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-458589214_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741828_1004, duration(ns): 7300888
2025-03-26 02:26:22,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33918, dest: /172.20.1.16:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-458589214_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741828_1004, duration(ns): 5817866
2025-03-26 02:26:22,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34372, dest: /172.20.1.17:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-458589214_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741828_1004, duration(ns): 8748528
2025-03-26 02:26:22,145 INFO terminating
2025-03-26 02:26:22,146 INFO terminating
2025-03-26 02:26:22,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /lr_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-458589214_1
2025-03-26 02:26:25,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/graphx/users.txt._COPYING_
2025-03-26 02:26:25,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741829_1005 src: /172.20.1.14:49346 dest: /172.20.1.16:9866
2025-03-26 02:26:25,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741829_1005 src: /172.20.1.16:52380 dest: /172.20.1.17:9866
2025-03-26 02:26:25,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741829_1005 src: /172.20.1.17:50552 dest: /172.20.1.15:9866
2025-03-26 02:26:25,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50552, dest: /172.20.1.15:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741829_1005, duration(ns): 6877651
2025-03-26 02:26:25,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52380, dest: /172.20.1.17:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741829_1005, duration(ns): 9497005
2025-03-26 02:26:25,076 INFO terminating
2025-03-26 02:26:25,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49346, dest: /172.20.1.16:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741829_1005, duration(ns): 10917095
2025-03-26 02:26:25,078 INFO terminating
2025-03-26 02:26:25,081 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/users.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,098 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/graphx/followers.txt._COPYING_
2025-03-26 02:26:25,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741830_1006 src: /172.20.1.14:49352 dest: /172.20.1.16:9866
2025-03-26 02:26:25,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741830_1006 src: /172.20.1.16:58238 dest: /172.20.1.15:9866
2025-03-26 02:26:25,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741830_1006 src: /172.20.1.15:35386 dest: /172.20.1.17:9866
2025-03-26 02:26:25,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35386, dest: /172.20.1.17:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741830_1006, duration(ns): 3359433
2025-03-26 02:26:25,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58238, dest: /172.20.1.15:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741830_1006, duration(ns): 4671642
2025-03-26 02:26:25,112 INFO terminating
2025-03-26 02:26:25,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49352, dest: /172.20.1.16:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741830_1006, duration(ns): 6102815
2025-03-26 02:26:25,117 INFO terminating
2025-03-26 02:26:25,119 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/followers.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,137 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_fpgrowth.txt._COPYING_
2025-03-26 02:26:25,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741831_1007 src: /172.20.1.14:49368 dest: /172.20.1.16:9866
2025-03-26 02:26:25,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741831_1007 src: /172.20.1.16:52388 dest: /172.20.1.17:9866
2025-03-26 02:26:25,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741831_1007 src: /172.20.1.17:50560 dest: /172.20.1.15:9866
2025-03-26 02:26:25,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50560, dest: /172.20.1.15:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741831_1007, duration(ns): 4003454
2025-03-26 02:26:25,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52388, dest: /172.20.1.17:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741831_1007, duration(ns): 5176920
2025-03-26 02:26:25,150 INFO terminating
2025-03-26 02:26:25,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49368, dest: /172.20.1.16:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741831_1007, duration(ns): 7132564
2025-03-26 02:26:25,153 INFO terminating
2025-03-26 02:26:25,155 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_fpgrowth.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,167 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/pagerank_data.txt._COPYING_
2025-03-26 02:26:25,167 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741832_1008 src: /172.20.1.14:51532 dest: /172.20.1.15:9866
2025-03-26 02:26:25,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741832_1008 src: /172.20.1.15:35392 dest: /172.20.1.17:9866
2025-03-26 02:26:25,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741832_1008 src: /172.20.1.17:33932 dest: /172.20.1.16:9866
2025-03-26 02:26:25,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33932, dest: /172.20.1.16:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741832_1008, duration(ns): 4975481
2025-03-26 02:26:25,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35392, dest: /172.20.1.17:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741832_1008, duration(ns): 6561816
2025-03-26 02:26:25,181 INFO terminating
2025-03-26 02:26:25,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51532, dest: /172.20.1.15:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741832_1008, duration(ns): 7440413
2025-03-26 02:26:25,184 INFO terminating
2025-03-26 02:26:25,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pagerank_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_
2025-03-26 02:26:25,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741833_1009 src: /172.20.1.14:34384 dest: /172.20.1.17:9866
2025-03-26 02:26:25,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741833_1009 src: /172.20.1.17:50574 dest: /172.20.1.15:9866
2025-03-26 02:26:25,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741833_1009 src: /172.20.1.15:39408 dest: /172.20.1.16:9866
2025-03-26 02:26:25,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39408, dest: /172.20.1.16:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741833_1009, duration(ns): 4286596
2025-03-26 02:26:25,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50574, dest: /172.20.1.15:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741833_1009, duration(ns): 12207350
2025-03-26 02:26:25,220 INFO terminating
2025-03-26 02:26:25,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34384, dest: /172.20.1.17:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741833_1009, duration(ns): 13409117
2025-03-26 02:26:25,222 INFO terminating
2025-03-26 02:26:25,223 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_lda_data.txt._COPYING_
2025-03-26 02:26:25,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741834_1010 src: /172.20.1.14:51540 dest: /172.20.1.15:9866
2025-03-26 02:26:25,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741834_1010 src: /172.20.1.15:39412 dest: /172.20.1.16:9866
2025-03-26 02:26:25,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741834_1010 src: /172.20.1.16:52394 dest: /172.20.1.17:9866
2025-03-26 02:26:25,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52394, dest: /172.20.1.17:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741834_1010, duration(ns): 2900605
2025-03-26 02:26:25,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39412, dest: /172.20.1.16:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741834_1010, duration(ns): 4677399
2025-03-26 02:26:25,246 INFO terminating
2025-03-26 02:26:25,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51540, dest: /172.20.1.15:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741834_1010, duration(ns): 5851124
2025-03-26 02:26:25,247 INFO terminating
2025-03-26 02:26:25,249 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/als/test.data._COPYING_
2025-03-26 02:26:25,262 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,262 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741835_1011 src: /172.20.1.14:51554 dest: /172.20.1.15:9866
2025-03-26 02:26:25,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741835_1011 src: /172.20.1.15:39428 dest: /172.20.1.16:9866
2025-03-26 02:26:25,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741835_1011 src: /172.20.1.16:52396 dest: /172.20.1.17:9866
2025-03-26 02:26:25,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52396, dest: /172.20.1.17:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741835_1011, duration(ns): 4111464
2025-03-26 02:26:25,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39428, dest: /172.20.1.16:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741835_1011, duration(ns): 5723879
2025-03-26 02:26:25,277 INFO terminating
2025-03-26 02:26:25,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51554, dest: /172.20.1.15:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741835_1011, duration(ns): 6706372
2025-03-26 02:26:25,278 INFO terminating
2025-03-26 02:26:25,280 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/test.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_
2025-03-26 02:26:25,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741836_1012 src: /172.20.1.14:34398 dest: /172.20.1.17:9866
2025-03-26 02:26:25,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741836_1012 src: /172.20.1.17:33946 dest: /172.20.1.16:9866
2025-03-26 02:26:25,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741836_1012 src: /172.20.1.16:58248 dest: /172.20.1.15:9866
2025-03-26 02:26:25,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58248, dest: /172.20.1.15:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741836_1012, duration(ns): 3904344
2025-03-26 02:26:25,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33946, dest: /172.20.1.16:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741836_1012, duration(ns): 4822232
2025-03-26 02:26:25,311 INFO terminating
2025-03-26 02:26:25,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34398, dest: /172.20.1.17:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741836_1012, duration(ns): 9230992
2025-03-26 02:26:25,313 INFO terminating
2025-03-26 02:26:25,315 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_kmeans_data.txt._COPYING_
2025-03-26 02:26:25,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741837_1013 src: /172.20.1.14:49382 dest: /172.20.1.16:9866
2025-03-26 02:26:25,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741837_1013 src: /172.20.1.16:58252 dest: /172.20.1.15:9866
2025-03-26 02:26:25,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741837_1013 src: /172.20.1.15:35400 dest: /172.20.1.17:9866
2025-03-26 02:26:25,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35400, dest: /172.20.1.17:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741837_1013, duration(ns): 3656902
2025-03-26 02:26:25,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58252, dest: /172.20.1.15:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741837_1013, duration(ns): 4990498
2025-03-26 02:26:25,339 INFO terminating
2025-03-26 02:26:25,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49382, dest: /172.20.1.16:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741837_1013, duration(ns): 5897722
2025-03-26 02:26:25,340 INFO terminating
2025-03-26 02:26:25,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/ridge-data/lpsa.data._COPYING_
2025-03-26 02:26:25,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741838_1014 src: /172.20.1.14:49394 dest: /172.20.1.16:9866
2025-03-26 02:26:25,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741838_1014 src: /172.20.1.16:52404 dest: /172.20.1.17:9866
2025-03-26 02:26:25,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741838_1014 src: /172.20.1.17:50590 dest: /172.20.1.15:9866
2025-03-26 02:26:25,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50590, dest: /172.20.1.15:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741838_1014, duration(ns): 5237011
2025-03-26 02:26:25,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52404, dest: /172.20.1.17:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741838_1014, duration(ns): 6038696
2025-03-26 02:26:25,379 INFO terminating
2025-03-26 02:26:25,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49394, dest: /172.20.1.16:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741838_1014, duration(ns): 7237744
2025-03-26 02:26:25,380 INFO terminating
2025-03-26 02:26:25,382 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/ridge-data/lpsa.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/gmm_data.txt._COPYING_
2025-03-26 02:26:25,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741839_1015 src: /172.20.1.14:49396 dest: /172.20.1.16:9866
2025-03-26 02:26:25,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741839_1015 src: /172.20.1.16:58268 dest: /172.20.1.15:9866
2025-03-26 02:26:25,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741839_1015 src: /172.20.1.15:35410 dest: /172.20.1.17:9866
2025-03-26 02:26:25,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35410, dest: /172.20.1.17:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741839_1015, duration(ns): 5164958
2025-03-26 02:26:25,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58268, dest: /172.20.1.15:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741839_1015, duration(ns): 6040653
2025-03-26 02:26:25,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,405 INFO terminating
2025-03-26 02:26:25,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49396, dest: /172.20.1.16:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741839_1015, duration(ns): 6556759
2025-03-26 02:26:25,407 INFO terminating
2025-03-26 02:26:25,408 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/gmm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_
2025-03-26 02:26:25,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741840_1016 src: /172.20.1.14:49398 dest: /172.20.1.16:9866
2025-03-26 02:26:25,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741840_1016 src: /172.20.1.16:52412 dest: /172.20.1.17:9866
2025-03-26 02:26:25,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741840_1016 src: /172.20.1.17:50602 dest: /172.20.1.15:9866
2025-03-26 02:26:25,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50602, dest: /172.20.1.15:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741840_1016, duration(ns): 4136396
2025-03-26 02:26:25,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52412, dest: /172.20.1.17:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741840_1016, duration(ns): 6615998
2025-03-26 02:26:25,438 INFO terminating
2025-03-26 02:26:25,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49398, dest: /172.20.1.16:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741840_1016, duration(ns): 8511434
2025-03-26 02:26:25,440 INFO terminating
2025-03-26 02:26:25,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_libsvm_data.txt._COPYING_
2025-03-26 02:26:25,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741841_1017 src: /172.20.1.14:34400 dest: /172.20.1.17:9866
2025-03-26 02:26:25,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741841_1017 src: /172.20.1.17:50604 dest: /172.20.1.15:9866
2025-03-26 02:26:25,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741841_1017 src: /172.20.1.15:39432 dest: /172.20.1.16:9866
2025-03-26 02:26:25,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39432, dest: /172.20.1.16:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741841_1017, duration(ns): 4017456
2025-03-26 02:26:25,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50604, dest: /172.20.1.15:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741841_1017, duration(ns): 5536581
2025-03-26 02:26:25,471 INFO terminating
2025-03-26 02:26:25,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34400, dest: /172.20.1.17:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741841_1017, duration(ns): 6460887
2025-03-26 02:26:25,472 INFO terminating
2025-03-26 02:26:25,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,482 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_movielens_data.txt._COPYING_
2025-03-26 02:26:25,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741842_1018 src: /172.20.1.14:49406 dest: /172.20.1.16:9866
2025-03-26 02:26:25,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741842_1018 src: /172.20.1.16:52416 dest: /172.20.1.17:9866
2025-03-26 02:26:25,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741842_1018 src: /172.20.1.17:50620 dest: /172.20.1.15:9866
2025-03-26 02:26:25,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50620, dest: /172.20.1.15:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741842_1018, duration(ns): 3770063
2025-03-26 02:26:25,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52416, dest: /172.20.1.17:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741842_1018, duration(ns): 4379136
2025-03-26 02:26:25,496 INFO terminating
2025-03-26 02:26:25,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49406, dest: /172.20.1.16:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741842_1018, duration(ns): 7372167
2025-03-26 02:26:25,499 INFO terminating
2025-03-26 02:26:25,501 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_movielens_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_svm_data.txt._COPYING_
2025-03-26 02:26:25,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741843_1019 src: /172.20.1.14:34408 dest: /172.20.1.17:9866
2025-03-26 02:26:25,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741843_1019 src: /172.20.1.17:33948 dest: /172.20.1.16:9866
2025-03-26 02:26:25,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741843_1019 src: /172.20.1.16:58276 dest: /172.20.1.15:9866
2025-03-26 02:26:25,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58276, dest: /172.20.1.15:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741843_1019, duration(ns): 3403829
2025-03-26 02:26:25,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33948, dest: /172.20.1.16:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741843_1019, duration(ns): 4102531
2025-03-26 02:26:25,522 INFO terminating
2025-03-26 02:26:25,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34408, dest: /172.20.1.17:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741843_1019, duration(ns): 5099147
2025-03-26 02:26:25,524 INFO terminating
2025-03-26 02:26:25,526 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_svm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/license.txt._COPYING_
2025-03-26 02:26:25,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741844_1020 src: /172.20.1.14:49414 dest: /172.20.1.16:9866
2025-03-26 02:26:25,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741844_1020 src: /172.20.1.16:58282 dest: /172.20.1.15:9866
2025-03-26 02:26:25,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741844_1020 src: /172.20.1.15:35412 dest: /172.20.1.17:9866
2025-03-26 02:26:25,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35412, dest: /172.20.1.17:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741844_1020, duration(ns): 4924558
2025-03-26 02:26:25,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58282, dest: /172.20.1.15:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741844_1020, duration(ns): 6425670
2025-03-26 02:26:25,564 INFO terminating
2025-03-26 02:26:25,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49414, dest: /172.20.1.16:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741844_1020, duration(ns): 7595945
2025-03-26 02:26:25,566 INFO terminating
2025-03-26 02:26:25,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_
2025-03-26 02:26:25,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741845_1021 src: /172.20.1.14:34416 dest: /172.20.1.17:9866
2025-03-26 02:26:25,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741845_1021 src: /172.20.1.17:50624 dest: /172.20.1.15:9866
2025-03-26 02:26:25,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741845_1021 src: /172.20.1.15:39436 dest: /172.20.1.16:9866
2025-03-26 02:26:25,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39436, dest: /172.20.1.16:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741845_1021, duration(ns): 3698231
2025-03-26 02:26:25,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50624, dest: /172.20.1.15:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741845_1021, duration(ns): 4460053
2025-03-26 02:26:25,599 INFO terminating
2025-03-26 02:26:25,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34416, dest: /172.20.1.17:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741845_1021, duration(ns): 5384586
2025-03-26 02:26:25,600 INFO terminating
2025-03-26 02:26:25,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_
2025-03-26 02:26:25,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741846_1022 src: /172.20.1.14:51558 dest: /172.20.1.15:9866
2025-03-26 02:26:25,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741846_1022 src: /172.20.1.15:39452 dest: /172.20.1.16:9866
2025-03-26 02:26:25,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741846_1022 src: /172.20.1.16:52426 dest: /172.20.1.17:9866
2025-03-26 02:26:25,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52426, dest: /172.20.1.17:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741846_1022, duration(ns): 3592521
2025-03-26 02:26:25,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39452, dest: /172.20.1.16:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741846_1022, duration(ns): 4266434
2025-03-26 02:26:25,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51558, dest: /172.20.1.15:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741846_1022, duration(ns): 5091356
2025-03-26 02:26:25,624 INFO terminating
2025-03-26 02:26:25,624 INFO terminating
2025-03-26 02:26:25,626 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,637 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_
2025-03-26 02:26:25,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741847_1023 src: /172.20.1.14:51572 dest: /172.20.1.15:9866
2025-03-26 02:26:25,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741847_1023 src: /172.20.1.15:39458 dest: /172.20.1.16:9866
2025-03-26 02:26:25,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741847_1023 src: /172.20.1.16:52434 dest: /172.20.1.17:9866
2025-03-26 02:26:25,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52434, dest: /172.20.1.17:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741847_1023, duration(ns): 2268491
2025-03-26 02:26:25,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39458, dest: /172.20.1.16:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741847_1023, duration(ns): 4000967
2025-03-26 02:26:25,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51572, dest: /172.20.1.15:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741847_1023, duration(ns): 5379091
2025-03-26 02:26:25,648 INFO terminating
2025-03-26 02:26:25,649 INFO terminating
2025-03-26 02:26:25,650 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_
2025-03-26 02:26:25,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741848_1024 src: /172.20.1.14:51586 dest: /172.20.1.15:9866
2025-03-26 02:26:25,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741848_1024 src: /172.20.1.15:39466 dest: /172.20.1.16:9866
2025-03-26 02:26:25,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741848_1024 src: /172.20.1.16:52442 dest: /172.20.1.17:9866
2025-03-26 02:26:25,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52442, dest: /172.20.1.17:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741848_1024, duration(ns): 3418719
2025-03-26 02:26:25,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39466, dest: /172.20.1.16:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741848_1024, duration(ns): 5848535
2025-03-26 02:26:25,672 INFO terminating
2025-03-26 02:26:25,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51586, dest: /172.20.1.15:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741848_1024, duration(ns): 7131075
2025-03-26 02:26:25,673 INFO terminating
2025-03-26 02:26:25,674 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/license.txt._COPYING_
2025-03-26 02:26:25,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741849_1025 src: /172.20.1.14:49428 dest: /172.20.1.16:9866
2025-03-26 02:26:25,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741849_1025 src: /172.20.1.16:58292 dest: /172.20.1.15:9866
2025-03-26 02:26:25,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741849_1025 src: /172.20.1.15:35418 dest: /172.20.1.17:9866
2025-03-26 02:26:25,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35418, dest: /172.20.1.17:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741849_1025, duration(ns): 3077093
2025-03-26 02:26:25,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58292, dest: /172.20.1.15:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741849_1025, duration(ns): 4408618
2025-03-26 02:26:25,697 INFO terminating
2025-03-26 02:26:25,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49428, dest: /172.20.1.16:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741849_1025, duration(ns): 5385638
2025-03-26 02:26:25,705 INFO terminating
2025-03-26 02:26:25,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,718 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_
2025-03-26 02:26:25,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741850_1026 src: /172.20.1.14:49436 dest: /172.20.1.16:9866
2025-03-26 02:26:25,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741850_1026 src: /172.20.1.16:52452 dest: /172.20.1.17:9866
2025-03-26 02:26:25,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741850_1026 src: /172.20.1.17:50638 dest: /172.20.1.15:9866
2025-03-26 02:26:25,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50638, dest: /172.20.1.15:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741850_1026, duration(ns): 3792744
2025-03-26 02:26:25,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52452, dest: /172.20.1.17:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741850_1026, duration(ns): 4945606
2025-03-26 02:26:25,733 INFO terminating
2025-03-26 02:26:25,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49436, dest: /172.20.1.16:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741850_1026, duration(ns): 5599340
2025-03-26 02:26:25,735 INFO terminating
2025-03-26 02:26:25,736 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_
2025-03-26 02:26:25,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741851_1027 src: /172.20.1.14:51600 dest: /172.20.1.15:9866
2025-03-26 02:26:25,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741851_1027 src: /172.20.1.15:39470 dest: /172.20.1.16:9866
2025-03-26 02:26:25,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741851_1027 src: /172.20.1.16:52464 dest: /172.20.1.17:9866
2025-03-26 02:26:25,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52464, dest: /172.20.1.17:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741851_1027, duration(ns): 2945929
2025-03-26 02:26:25,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39470, dest: /172.20.1.16:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741851_1027, duration(ns): 4055745
2025-03-26 02:26:25,760 INFO terminating
2025-03-26 02:26:25,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51600, dest: /172.20.1.15:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741851_1027, duration(ns): 6625054
2025-03-26 02:26:25,761 INFO terminating
2025-03-26 02:26:25,762 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_
2025-03-26 02:26:25,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741852_1028 src: /172.20.1.14:34430 dest: /172.20.1.17:9866
2025-03-26 02:26:25,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741852_1028 src: /172.20.1.17:50652 dest: /172.20.1.15:9866
2025-03-26 02:26:25,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741852_1028 src: /172.20.1.15:39480 dest: /172.20.1.16:9866
2025-03-26 02:26:25,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39480, dest: /172.20.1.16:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741852_1028, duration(ns): 2474246
2025-03-26 02:26:25,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50652, dest: /172.20.1.15:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741852_1028, duration(ns): 6113390
2025-03-26 02:26:25,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34430, dest: /172.20.1.17:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741852_1028, duration(ns): 7420005
2025-03-26 02:26:25,790 INFO terminating
2025-03-26 02:26:25,791 INFO terminating
2025-03-26 02:26:25,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_
2025-03-26 02:26:25,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741853_1029 src: /172.20.1.14:49440 dest: /172.20.1.16:9866
2025-03-26 02:26:25,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741853_1029 src: /172.20.1.16:52472 dest: /172.20.1.17:9866
2025-03-26 02:26:25,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741853_1029 src: /172.20.1.17:50656 dest: /172.20.1.15:9866
2025-03-26 02:26:25,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:50656, dest: /172.20.1.15:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741853_1029, duration(ns): 3515255
2025-03-26 02:26:25,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52472, dest: /172.20.1.17:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741853_1029, duration(ns): 4976616
2025-03-26 02:26:25,813 INFO terminating
2025-03-26 02:26:25,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49440, dest: /172.20.1.16:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741853_1029, duration(ns): 5877892
2025-03-26 02:26:25,815 INFO terminating
2025-03-26 02:26:25,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,825 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_
2025-03-26 02:26:25,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741854_1030 src: /172.20.1.14:51614 dest: /172.20.1.15:9866
2025-03-26 02:26:25,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741854_1030 src: /172.20.1.15:39486 dest: /172.20.1.16:9866
2025-03-26 02:26:25,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741854_1030 src: /172.20.1.16:52484 dest: /172.20.1.17:9866
2025-03-26 02:26:25,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52484, dest: /172.20.1.17:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741854_1030, duration(ns): 3094831
2025-03-26 02:26:25,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39486, dest: /172.20.1.16:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741854_1030, duration(ns): 3499562
2025-03-26 02:26:25,836 INFO terminating
2025-03-26 02:26:25,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51614, dest: /172.20.1.15:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741854_1030, duration(ns): 4203712
2025-03-26 02:26:25,837 INFO terminating
2025-03-26 02:26:25,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,851 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_
2025-03-26 02:26:25,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741855_1031 src: /172.20.1.14:34446 dest: /172.20.1.17:9866
2025-03-26 02:26:25,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741855_1031 src: /172.20.1.17:33958 dest: /172.20.1.16:9866
2025-03-26 02:26:25,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741855_1031 src: /172.20.1.16:58298 dest: /172.20.1.15:9866
2025-03-26 02:26:25,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58298, dest: /172.20.1.15:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741855_1031, duration(ns): 3900894
2025-03-26 02:26:25,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33958, dest: /172.20.1.16:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741855_1031, duration(ns): 4514339
2025-03-26 02:26:25,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34446, dest: /172.20.1.17:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741855_1031, duration(ns): 5136068
2025-03-26 02:26:25,862 INFO terminating
2025-03-26 02:26:25,863 INFO terminating
2025-03-26 02:26:25,864 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,870 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_
2025-03-26 02:26:25,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741856_1032 src: /172.20.1.14:51620 dest: /172.20.1.15:9866
2025-03-26 02:26:25,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741856_1032 src: /172.20.1.15:39498 dest: /172.20.1.16:9866
2025-03-26 02:26:25,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741856_1032 src: /172.20.1.16:52490 dest: /172.20.1.17:9866
2025-03-26 02:26:25,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52490, dest: /172.20.1.17:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741856_1032, duration(ns): 4093049
2025-03-26 02:26:25,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39498, dest: /172.20.1.16:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741856_1032, duration(ns): 5836269
2025-03-26 02:26:25,883 INFO terminating
2025-03-26 02:26:25,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51620, dest: /172.20.1.15:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741856_1032, duration(ns): 6968416
2025-03-26 02:26:25,884 INFO terminating
2025-03-26 02:26:25,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_
2025-03-26 02:26:25,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741857_1033 src: /172.20.1.14:51624 dest: /172.20.1.15:9866
2025-03-26 02:26:25,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741857_1033 src: /172.20.1.15:35422 dest: /172.20.1.17:9866
2025-03-26 02:26:25,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741857_1033 src: /172.20.1.17:33966 dest: /172.20.1.16:9866
2025-03-26 02:26:25,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33966, dest: /172.20.1.16:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741857_1033, duration(ns): 2904039
2025-03-26 02:26:25,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35422, dest: /172.20.1.17:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741857_1033, duration(ns): 3952005
2025-03-26 02:26:25,905 INFO terminating
2025-03-26 02:26:25,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51624, dest: /172.20.1.15:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741857_1033, duration(ns): 5107472
2025-03-26 02:26:25,906 INFO terminating
2025-03-26 02:26:25,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_
2025-03-26 02:26:25,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741858_1034 src: /172.20.1.14:51626 dest: /172.20.1.15:9866
2025-03-26 02:26:25,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741858_1034 src: /172.20.1.15:39506 dest: /172.20.1.16:9866
2025-03-26 02:26:25,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741858_1034 src: /172.20.1.16:52492 dest: /172.20.1.17:9866
2025-03-26 02:26:25,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:52492, dest: /172.20.1.17:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741858_1034, duration(ns): 2592224
2025-03-26 02:26:25,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39506, dest: /172.20.1.16:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741858_1034, duration(ns): 3443220
2025-03-26 02:26:25,925 INFO terminating
2025-03-26 02:26:25,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51626, dest: /172.20.1.15:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741858_1034, duration(ns): 4569774
2025-03-26 02:26:25,927 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,927 INFO terminating
2025-03-26 02:26:25,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/pic_data.txt._COPYING_
2025-03-26 02:26:25,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741859_1035 src: /172.20.1.14:51642 dest: /172.20.1.15:9866
2025-03-26 02:26:25,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741859_1035 src: /172.20.1.15:35424 dest: /172.20.1.17:9866
2025-03-26 02:26:25,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741859_1035 src: /172.20.1.17:33982 dest: /172.20.1.16:9866
2025-03-26 02:26:25,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33982, dest: /172.20.1.16:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741859_1035, duration(ns): 3517327
2025-03-26 02:26:25,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35424, dest: /172.20.1.17:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741859_1035, duration(ns): 4069232
2025-03-26 02:26:25,947 INFO terminating
2025-03-26 02:26:25,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51642, dest: /172.20.1.15:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741859_1035, duration(ns): 4749335
2025-03-26 02:26:25,948 INFO terminating
2025-03-26 02:26:25,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pic_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/kmeans_data.txt._COPYING_
2025-03-26 02:26:25,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741860_1036 src: /172.20.1.14:34460 dest: /172.20.1.17:9866
2025-03-26 02:26:25,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741860_1036 src: /172.20.1.17:33996 dest: /172.20.1.16:9866
2025-03-26 02:26:25,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741860_1036 src: /172.20.1.16:58308 dest: /172.20.1.15:9866
2025-03-26 02:26:25,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58308, dest: /172.20.1.15:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741860_1036, duration(ns): 2990351
2025-03-26 02:26:25,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33996, dest: /172.20.1.16:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741860_1036, duration(ns): 3658577
2025-03-26 02:26:25,970 INFO terminating
2025-03-26 02:26:25,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:34460, dest: /172.20.1.17:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741860_1036, duration(ns): 4165272
2025-03-26 02:26:25,971 INFO terminating
2025-03-26 02:26:25,972 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:25,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/streaming/AFINN-111.txt._COPYING_
2025-03-26 02:26:25,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741861_1037 src: /172.20.1.14:49456 dest: /172.20.1.16:9866
2025-03-26 02:26:25,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741861_1037 src: /172.20.1.16:58324 dest: /172.20.1.15:9866
2025-03-26 02:26:25,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741861_1037 src: /172.20.1.15:35436 dest: /172.20.1.17:9866
2025-03-26 02:26:25,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35436, dest: /172.20.1.17:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741861_1037, duration(ns): 1990021
2025-03-26 02:26:25,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58324, dest: /172.20.1.15:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741861_1037, duration(ns): 6026963
2025-03-26 02:26:25,994 INFO terminating
2025-03-26 02:26:25,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49456, dest: /172.20.1.16:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_216299208_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741861_1037, duration(ns): 7190405
2025-03-26 02:26:25,996 INFO terminating
2025-03-26 02:26:25,997 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/streaming/AFINN-111.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_216299208_1
2025-03-26 02:26:27,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_
2025-03-26 02:26:27,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741862_1038 src: /172.20.1.14:46860 dest: /172.20.1.15:9866
2025-03-26 02:26:27,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741862_1038 src: /172.20.1.15:59034 dest: /172.20.1.16:9866
2025-03-26 02:26:27,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741862_1038 src: /172.20.1.16:57720 dest: /172.20.1.17:9866
2025-03-26 02:26:27,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57720, dest: /172.20.1.17:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741862_1038, duration(ns): 7958951
2025-03-26 02:26:27,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46860, dest: /172.20.1.15:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741862_1038, duration(ns): 9106036
2025-03-26 02:26:27,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59034, dest: /172.20.1.16:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741862_1038, duration(ns): 7801546
2025-03-26 02:26:27,494 INFO terminating
2025-03-26 02:26:27,494 INFO terminating
2025-03-26 02:26:27,498 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_
2025-03-26 02:26:27,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,516 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,516 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,516 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741863_1039 src: /172.20.1.14:37334 dest: /172.20.1.17:9866
2025-03-26 02:26:27,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741863_1039 src: /172.20.1.17:47648 dest: /172.20.1.15:9866
2025-03-26 02:26:27,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47648, dest: /172.20.1.15:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741863_1039, duration(ns): 7616139
2025-03-26 02:26:27,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37334, dest: /172.20.1.17:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741863_1039, duration(ns): 8127922
2025-03-26 02:26:27,529 INFO terminating
2025-03-26 02:26:27,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/wordcount.py._COPYING_
2025-03-26 02:26:27,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,552 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,552 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,552 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741864_1040 src: /172.20.1.14:46862 dest: /172.20.1.15:9866
2025-03-26 02:26:27,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741864_1040 src: /172.20.1.15:39438 dest: /172.20.1.17:9866
2025-03-26 02:26:27,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39438, dest: /172.20.1.17:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741864_1040, duration(ns): 1636395
2025-03-26 02:26:27,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46862, dest: /172.20.1.15:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741864_1040, duration(ns): 2162983
2025-03-26 02:26:27,558 INFO terminating
2025-03-26 02:26:27,561 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/transitive_closure.py._COPYING_
2025-03-26 02:26:27,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,574 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,574 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,574 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741865_1041 src: /172.20.1.14:37338 dest: /172.20.1.17:9866
2025-03-26 02:26:27,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741865_1041 src: /172.20.1.17:47662 dest: /172.20.1.15:9866
2025-03-26 02:26:27,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47662, dest: /172.20.1.15:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741865_1041, duration(ns): 1014427
2025-03-26 02:26:27,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37338, dest: /172.20.1.17:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741865_1041, duration(ns): 1576189
2025-03-26 02:26:27,580 INFO terminating
2025-03-26 02:26:27,581 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/transitive_closure.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,587 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,587 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,587 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_
2025-03-26 02:26:27,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741866_1042 src: /172.20.1.14:46872 dest: /172.20.1.15:9866
2025-03-26 02:26:27,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741866_1042 src: /172.20.1.15:39442 dest: /172.20.1.17:9866
2025-03-26 02:26:27,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39442, dest: /172.20.1.17:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741866_1042, duration(ns): 1010912
2025-03-26 02:26:27,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46872, dest: /172.20.1.15:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741866_1042, duration(ns): 1497842
2025-03-26 02:26:27,593 INFO terminating
2025-03-26 02:26:27,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/pi.py._COPYING_
2025-03-26 02:26:27,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,602 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,602 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,602 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741867_1043 src: /172.20.1.14:37348 dest: /172.20.1.17:9866
2025-03-26 02:26:27,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741867_1043 src: /172.20.1.17:47664 dest: /172.20.1.15:9866
2025-03-26 02:26:27,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47664, dest: /172.20.1.15:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741867_1043, duration(ns): 3339800
2025-03-26 02:26:27,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37348, dest: /172.20.1.17:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741867_1043, duration(ns): 3734276
2025-03-26 02:26:27,610 INFO terminating
2025-03-26 02:26:27,611 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pi.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,617 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,617 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,617 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sort.py._COPYING_
2025-03-26 02:26:27,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741868_1044 src: /172.20.1.14:37354 dest: /172.20.1.17:9866
2025-03-26 02:26:27,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741868_1044 src: /172.20.1.17:47670 dest: /172.20.1.15:9866
2025-03-26 02:26:27,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47670, dest: /172.20.1.15:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741868_1044, duration(ns): 1945364
2025-03-26 02:26:27,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37354, dest: /172.20.1.17:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741868_1044, duration(ns): 2347247
2025-03-26 02:26:27,625 INFO terminating
2025-03-26 02:26:27,626 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sort.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/status_api_demo.py._COPYING_
2025-03-26 02:26:27,633 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,633 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,633 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,633 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,633 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045 src: /172.20.1.14:37360 dest: /172.20.1.17:9866
2025-03-26 02:26:27,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045 src: /172.20.1.17:47684 dest: /172.20.1.15:9866
2025-03-26 02:26:27,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47684, dest: /172.20.1.15:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045, duration(ns): 2318449
2025-03-26 02:26:27,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37360, dest: /172.20.1.17:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045, duration(ns): 2674377
2025-03-26 02:26:27,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,640 INFO terminating
2025-03-26 02:26:27,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/status_api_demo.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/avro_inputformat.py._COPYING_
2025-03-26 02:26:27,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,647 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,647 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,647 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046 src: /172.20.1.14:37376 dest: /172.20.1.17:9866
2025-03-26 02:26:27,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046 src: /172.20.1.17:47694 dest: /172.20.1.15:9866
2025-03-26 02:26:27,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47694, dest: /172.20.1.15:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046, duration(ns): 1110771
2025-03-26 02:26:27,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,653 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/avro_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37376, dest: /172.20.1.17:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046, duration(ns): 1524889
2025-03-26 02:26:27,653 INFO terminating
2025-03-26 02:26:27,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/logistic_regression.py._COPYING_
2025-03-26 02:26:27,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,660 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,660 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,660 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047 src: /172.20.1.14:37390 dest: /172.20.1.17:9866
2025-03-26 02:26:27,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047 src: /172.20.1.17:47710 dest: /172.20.1.15:9866
2025-03-26 02:26:27,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47710, dest: /172.20.1.15:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047, duration(ns): 2185068
2025-03-26 02:26:27,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37390, dest: /172.20.1.17:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047, duration(ns): 2314023
2025-03-26 02:26:27,668 INFO terminating
2025-03-26 02:26:27,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,676 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,677 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/kmeans.py._COPYING_
2025-03-26 02:26:27,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,677 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,677 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,677 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048 src: /172.20.1.14:46882 dest: /172.20.1.15:9866
2025-03-26 02:26:27,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048 src: /172.20.1.15:39456 dest: /172.20.1.17:9866
2025-03-26 02:26:27,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46882, dest: /172.20.1.15:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048, duration(ns): 1573018
2025-03-26 02:26:27,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39456, dest: /172.20.1.17:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048, duration(ns): 845808
2025-03-26 02:26:27,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,683 INFO terminating
2025-03-26 02:26:27,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_
2025-03-26 02:26:27,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,702 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,702 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,702 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741873_1049 src: /172.20.1.14:37400 dest: /172.20.1.17:9866
2025-03-26 02:26:27,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741873_1049 src: /172.20.1.17:47724 dest: /172.20.1.15:9866
2025-03-26 02:26:27,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47724, dest: /172.20.1.15:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741873_1049, duration(ns): 1288206
2025-03-26 02:26:27,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,709 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37400, dest: /172.20.1.17:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741873_1049, duration(ns): 1568456
2025-03-26 02:26:27,709 INFO terminating
2025-03-26 02:26:27,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_
2025-03-26 02:26:27,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,717 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,717 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,717 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741874_1050 src: /172.20.1.14:37412 dest: /172.20.1.17:9866
2025-03-26 02:26:27,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741874_1050 src: /172.20.1.17:47732 dest: /172.20.1.15:9866
2025-03-26 02:26:27,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37412, dest: /172.20.1.17:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741874_1050, duration(ns): 2018612
2025-03-26 02:26:27,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47732, dest: /172.20.1.15:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741874_1050, duration(ns): 1898958
2025-03-26 02:26:27,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,723 INFO terminating
2025-03-26 02:26:27,724 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_
2025-03-26 02:26:27,732 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,732 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,732 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,732 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,732 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051 src: /172.20.1.14:37416 dest: /172.20.1.17:9866
2025-03-26 02:26:27,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051 src: /172.20.1.17:47742 dest: /172.20.1.15:9866
2025-03-26 02:26:27,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47742, dest: /172.20.1.15:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051, duration(ns): 1651242
2025-03-26 02:26:27,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,738 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37416, dest: /172.20.1.17:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051, duration(ns): 1355636
2025-03-26 02:26:27,738 INFO terminating
2025-03-26 02:26:27,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_
2025-03-26 02:26:27,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,746 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,746 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,746 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052 src: /172.20.1.14:46884 dest: /172.20.1.15:9866
2025-03-26 02:26:27,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052 src: /172.20.1.15:39460 dest: /172.20.1.17:9866
2025-03-26 02:26:27,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39460, dest: /172.20.1.17:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052, duration(ns): 1283355
2025-03-26 02:26:27,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,754 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46884, dest: /172.20.1.15:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052, duration(ns): 1762763
2025-03-26 02:26:27,754 INFO terminating
2025-03-26 02:26:27,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_
2025-03-26 02:26:27,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,764 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,764 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,764 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053 src: /172.20.1.14:46898 dest: /172.20.1.15:9866
2025-03-26 02:26:27,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053 src: /172.20.1.15:39462 dest: /172.20.1.17:9866
2025-03-26 02:26:27,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46898, dest: /172.20.1.15:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053, duration(ns): 1590059
2025-03-26 02:26:27,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39462, dest: /172.20.1.17:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053, duration(ns): 1034083
2025-03-26 02:26:27,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,769 INFO terminating
2025-03-26 02:26:27,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_
2025-03-26 02:26:27,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,777 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,777 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,777 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054 src: /172.20.1.14:37418 dest: /172.20.1.17:9866
2025-03-26 02:26:27,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054 src: /172.20.1.17:47758 dest: /172.20.1.15:9866
2025-03-26 02:26:27,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37418, dest: /172.20.1.17:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054, duration(ns): 1382281
2025-03-26 02:26:27,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47758, dest: /172.20.1.15:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054, duration(ns): 1227219
2025-03-26 02:26:27,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,782 INFO terminating
2025-03-26 02:26:27,784 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_
2025-03-26 02:26:27,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,794 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,794 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,794 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741879_1055 src: /172.20.1.14:37422 dest: /172.20.1.17:9866
2025-03-26 02:26:27,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741879_1055 src: /172.20.1.17:47764 dest: /172.20.1.15:9866
2025-03-26 02:26:27,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37422, dest: /172.20.1.17:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741879_1055, duration(ns): 1479733
2025-03-26 02:26:27,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47764, dest: /172.20.1.15:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741879_1055, duration(ns): 1252959
2025-03-26 02:26:27,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,800 INFO terminating
2025-03-26 02:26:27,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,810 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_
2025-03-26 02:26:27,810 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,810 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,810 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,810 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741880_1056 src: /172.20.1.14:46914 dest: /172.20.1.15:9866
2025-03-26 02:26:27,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741880_1056 src: /172.20.1.15:39476 dest: /172.20.1.17:9866
2025-03-26 02:26:27,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39476, dest: /172.20.1.17:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741880_1056, duration(ns): 1065494
2025-03-26 02:26:27,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46914, dest: /172.20.1.15:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741880_1056, duration(ns): 1860440
2025-03-26 02:26:27,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,815 INFO terminating
2025-03-26 02:26:27,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,820 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_
2025-03-26 02:26:27,820 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,820 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,820 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,820 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,820 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,820 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057 src: /172.20.1.14:37438 dest: /172.20.1.17:9866
2025-03-26 02:26:27,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057 src: /172.20.1.17:47770 dest: /172.20.1.15:9866
2025-03-26 02:26:27,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47770, dest: /172.20.1.15:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057, duration(ns): 1334918
2025-03-26 02:26:27,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,827 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37438, dest: /172.20.1.17:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057, duration(ns): 1868293
2025-03-26 02:26:27,827 INFO terminating
2025-03-26 02:26:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,832 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,832 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,832 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_
2025-03-26 02:26:27,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058 src: /172.20.1.14:46930 dest: /172.20.1.15:9866
2025-03-26 02:26:27,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058 src: /172.20.1.15:39482 dest: /172.20.1.17:9866
2025-03-26 02:26:27,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39482, dest: /172.20.1.17:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058, duration(ns): 1215797
2025-03-26 02:26:27,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,840 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46930, dest: /172.20.1.15:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058, duration(ns): 1667945
2025-03-26 02:26:27,840 INFO terminating
2025-03-26 02:26:27,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_
2025-03-26 02:26:27,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,847 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,847 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,847 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059 src: /172.20.1.14:46932 dest: /172.20.1.15:9866
2025-03-26 02:26:27,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059 src: /172.20.1.15:39498 dest: /172.20.1.17:9866
2025-03-26 02:26:27,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39498, dest: /172.20.1.17:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059, duration(ns): 973400
2025-03-26 02:26:27,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46932, dest: /172.20.1.15:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059, duration(ns): 3536407
2025-03-26 02:26:27,855 INFO terminating
2025-03-26 02:26:27,856 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_
2025-03-26 02:26:27,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,864 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,864 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,864 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060 src: /172.20.1.14:37448 dest: /172.20.1.17:9866
2025-03-26 02:26:27,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060 src: /172.20.1.17:47778 dest: /172.20.1.15:9866
2025-03-26 02:26:27,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47778, dest: /172.20.1.15:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060, duration(ns): 1661019
2025-03-26 02:26:27,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37448, dest: /172.20.1.17:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060, duration(ns): 2134282
2025-03-26 02:26:27,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,871 INFO terminating
2025-03-26 02:26:27,872 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_
2025-03-26 02:26:27,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,884 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,884 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,884 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741885_1061 src: /172.20.1.14:46934 dest: /172.20.1.15:9866
2025-03-26 02:26:27,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741885_1061 src: /172.20.1.15:39510 dest: /172.20.1.17:9866
2025-03-26 02:26:27,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46934, dest: /172.20.1.15:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741885_1061, duration(ns): 2050871
2025-03-26 02:26:27,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39510, dest: /172.20.1.17:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741885_1061, duration(ns): 1427535
2025-03-26 02:26:27,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741885_1061, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,891 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,891 INFO terminating
2025-03-26 02:26:27,902 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_
2025-03-26 02:26:27,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,902 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,902 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,902 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741886_1062 src: /172.20.1.14:37460 dest: /172.20.1.17:9866
2025-03-26 02:26:27,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741886_1062 src: /172.20.1.17:47780 dest: /172.20.1.15:9866
2025-03-26 02:26:27,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47780, dest: /172.20.1.15:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741886_1062, duration(ns): 2373480
2025-03-26 02:26:27,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741886_1062, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37460, dest: /172.20.1.17:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741886_1062, duration(ns): 2998481
2025-03-26 02:26:27,914 INFO terminating
2025-03-26 02:26:27,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_
2025-03-26 02:26:27,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,926 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,926 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,926 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063 src: /172.20.1.14:46944 dest: /172.20.1.15:9866
2025-03-26 02:26:27,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063 src: /172.20.1.15:39522 dest: /172.20.1.17:9866
2025-03-26 02:26:27,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39522, dest: /172.20.1.17:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063, duration(ns): 1469037
2025-03-26 02:26:27,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46944, dest: /172.20.1.15:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063, duration(ns): 2376094
2025-03-26 02:26:27,933 INFO terminating
2025-03-26 02:26:27,934 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_
2025-03-26 02:26:27,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,941 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,941 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,941 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064 src: /172.20.1.14:37468 dest: /172.20.1.17:9866
2025-03-26 02:26:27,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064 src: /172.20.1.17:47788 dest: /172.20.1.15:9866
2025-03-26 02:26:27,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47788, dest: /172.20.1.15:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064, duration(ns): 1403556
2025-03-26 02:26:27,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37468, dest: /172.20.1.17:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064, duration(ns): 2012926
2025-03-26 02:26:27,948 INFO terminating
2025-03-26 02:26:27,949 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,957 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_
2025-03-26 02:26:27,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,957 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,957 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,957 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065 src: /172.20.1.14:46956 dest: /172.20.1.15:9866
2025-03-26 02:26:27,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065 src: /172.20.1.15:39530 dest: /172.20.1.17:9866
2025-03-26 02:26:27,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39530, dest: /172.20.1.17:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065, duration(ns): 1271003
2025-03-26 02:26:27,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46956, dest: /172.20.1.15:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065, duration(ns): 1821523
2025-03-26 02:26:27,963 INFO terminating
2025-03-26 02:26:27,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_
2025-03-26 02:26:27,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,969 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,969 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,969 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066 src: /172.20.1.14:37476 dest: /172.20.1.17:9866
2025-03-26 02:26:27,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066 src: /172.20.1.17:47798 dest: /172.20.1.15:9866
2025-03-26 02:26:27,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37476, dest: /172.20.1.17:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066, duration(ns): 1984415
2025-03-26 02:26:27,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47798, dest: /172.20.1.15:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066, duration(ns): 1760790
2025-03-26 02:26:27,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,975 INFO terminating
2025-03-26 02:26:27,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:26:27,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,982 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,982 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,982 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741891_1067 src: /172.20.1.14:37478 dest: /172.20.1.17:9866
2025-03-26 02:26:27,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741891_1067 src: /172.20.1.17:47806 dest: /172.20.1.15:9866
2025-03-26 02:26:27,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47806, dest: /172.20.1.15:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741891_1067, duration(ns): 1591020
2025-03-26 02:26:27,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741891_1067, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:27,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37478, dest: /172.20.1.17:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741891_1067, duration(ns): 2230793
2025-03-26 02:26:27,989 INFO terminating
2025-03-26 02:26:27,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_
2025-03-26 02:26:27,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,996 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,996 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,996 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741892_1068 src: /172.20.1.14:37492 dest: /172.20.1.17:9866
2025-03-26 02:26:27,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741892_1068 src: /172.20.1.17:47808 dest: /172.20.1.15:9866
2025-03-26 02:26:28,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37492, dest: /172.20.1.17:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741892_1068, duration(ns): 2059404
2025-03-26 02:26:28,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47808, dest: /172.20.1.15:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741892_1068, duration(ns): 1719685
2025-03-26 02:26:28,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741892_1068, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,003 INFO terminating
2025-03-26 02:26:28,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_
2025-03-26 02:26:28,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,010 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,010 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,010 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069 src: /172.20.1.14:37498 dest: /172.20.1.17:9866
2025-03-26 02:26:28,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069 src: /172.20.1.17:47816 dest: /172.20.1.15:9866
2025-03-26 02:26:28,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47816, dest: /172.20.1.15:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069, duration(ns): 1366146
2025-03-26 02:26:28,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37498, dest: /172.20.1.17:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069, duration(ns): 2051287
2025-03-26 02:26:28,017 INFO terminating
2025-03-26 02:26:28,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,032 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,032 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,032 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,033 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/__init__.py._COPYING_
2025-03-26 02:26:28,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070 src: /172.20.1.14:37514 dest: /172.20.1.17:9866
2025-03-26 02:26:28,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070 src: /172.20.1.17:47832 dest: /172.20.1.15:9866
2025-03-26 02:26:28,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37514, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070, duration(ns): 1463416
2025-03-26 02:26:28,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47832, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070, duration(ns): 1288392
2025-03-26 02:26:28,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,039 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,039 INFO terminating
2025-03-26 02:26:28,046 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_
2025-03-26 02:26:28,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,046 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,046 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,046 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071 src: /172.20.1.14:37530 dest: /172.20.1.17:9866
2025-03-26 02:26:28,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071 src: /172.20.1.17:47840 dest: /172.20.1.15:9866
2025-03-26 02:26:28,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47840, dest: /172.20.1.15:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071, duration(ns): 1069922
2025-03-26 02:26:28,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,053 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37530, dest: /172.20.1.17:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071, duration(ns): 1317420
2025-03-26 02:26:28,053 INFO terminating
2025-03-26 02:26:28,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_
2025-03-26 02:26:28,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,059 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,059 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,059 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072 src: /172.20.1.14:37546 dest: /172.20.1.17:9866
2025-03-26 02:26:28,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072 src: /172.20.1.17:47850 dest: /172.20.1.15:9866
2025-03-26 02:26:28,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37546, dest: /172.20.1.17:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072, duration(ns): 1168773
2025-03-26 02:26:28,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47850, dest: /172.20.1.15:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072, duration(ns): 994878
2025-03-26 02:26:28,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,064 INFO terminating
2025-03-26 02:26:28,065 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_
2025-03-26 02:26:28,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,070 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,070 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,070 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741897_1073 src: /172.20.1.14:46958 dest: /172.20.1.15:9866
2025-03-26 02:26:28,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741897_1073 src: /172.20.1.15:39538 dest: /172.20.1.17:9866
2025-03-26 02:26:28,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46958, dest: /172.20.1.15:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741897_1073, duration(ns): 1370721
2025-03-26 02:26:28,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39538, dest: /172.20.1.17:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741897_1073, duration(ns): 687298
2025-03-26 02:26:28,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741897_1073, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,076 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,076 INFO terminating
2025-03-26 02:26:28,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,082 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_
2025-03-26 02:26:28,083 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,083 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741898_1074 src: /172.20.1.14:46960 dest: /172.20.1.15:9866
2025-03-26 02:26:28,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741898_1074 src: /172.20.1.15:39550 dest: /172.20.1.17:9866
2025-03-26 02:26:28,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39550, dest: /172.20.1.17:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741898_1074, duration(ns): 667657
2025-03-26 02:26:28,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741898_1074, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,087 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46960, dest: /172.20.1.15:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741898_1074, duration(ns): 1057923
2025-03-26 02:26:28,087 INFO terminating
2025-03-26 02:26:28,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_
2025-03-26 02:26:28,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,093 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,093 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,093 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075 src: /172.20.1.14:37548 dest: /172.20.1.17:9866
2025-03-26 02:26:28,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075 src: /172.20.1.17:47856 dest: /172.20.1.15:9866
2025-03-26 02:26:28,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37548, dest: /172.20.1.17:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075, duration(ns): 1322580
2025-03-26 02:26:28,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47856, dest: /172.20.1.15:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075, duration(ns): 1058167
2025-03-26 02:26:28,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,097 INFO terminating
2025-03-26 02:26:28,098 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_
2025-03-26 02:26:28,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,104 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,104 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,104 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076 src: /172.20.1.14:46966 dest: /172.20.1.15:9866
2025-03-26 02:26:28,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076 src: /172.20.1.15:39554 dest: /172.20.1.17:9866
2025-03-26 02:26:28,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46966, dest: /172.20.1.15:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076, duration(ns): 1620651
2025-03-26 02:26:28,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39554, dest: /172.20.1.17:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076, duration(ns): 1072143
2025-03-26 02:26:28,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,109 INFO terminating
2025-03-26 02:26:28,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_
2025-03-26 02:26:28,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,115 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,115 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,115 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077 src: /172.20.1.14:46982 dest: /172.20.1.15:9866
2025-03-26 02:26:28,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077 src: /172.20.1.15:39558 dest: /172.20.1.17:9866
2025-03-26 02:26:28,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39558, dest: /172.20.1.17:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077, duration(ns): 669001
2025-03-26 02:26:28,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46982, dest: /172.20.1.15:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077, duration(ns): 1485247
2025-03-26 02:26:28,121 INFO terminating
2025-03-26 02:26:28,122 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_
2025-03-26 02:26:28,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,136 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078 src: /172.20.1.14:37552 dest: /172.20.1.17:9866
2025-03-26 02:26:28,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078 src: /172.20.1.17:47868 dest: /172.20.1.15:9866
2025-03-26 02:26:28,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37552, dest: /172.20.1.17:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078, duration(ns): 1047213
2025-03-26 02:26:28,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47868, dest: /172.20.1.15:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078, duration(ns): 1498567
2025-03-26 02:26:28,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,141 INFO terminating
2025-03-26 02:26:28,142 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_
2025-03-26 02:26:28,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,151 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,151 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,151 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741903_1079 src: /172.20.1.14:37564 dest: /172.20.1.17:9866
2025-03-26 02:26:28,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741903_1079 src: /172.20.1.17:47870 dest: /172.20.1.15:9866
2025-03-26 02:26:28,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37564, dest: /172.20.1.17:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741903_1079, duration(ns): 1000475
2025-03-26 02:26:28,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47870, dest: /172.20.1.15:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741903_1079, duration(ns): 779846
2025-03-26 02:26:28,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741903_1079, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,155 INFO terminating
2025-03-26 02:26:28,156 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,160 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_
2025-03-26 02:26:28,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,160 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,160 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,160 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741904_1080 src: /172.20.1.14:37576 dest: /172.20.1.17:9866
2025-03-26 02:26:28,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741904_1080 src: /172.20.1.17:47882 dest: /172.20.1.15:9866
2025-03-26 02:26:28,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47882, dest: /172.20.1.15:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741904_1080, duration(ns): 1134086
2025-03-26 02:26:28,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741904_1080, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,165 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37576, dest: /172.20.1.17:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741904_1080, duration(ns): 645939
2025-03-26 02:26:28,165 INFO terminating
2025-03-26 02:26:28,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/correlations.py._COPYING_
2025-03-26 02:26:28,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,176 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,176 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,176 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081 src: /172.20.1.14:46986 dest: /172.20.1.15:9866
2025-03-26 02:26:28,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081 src: /172.20.1.15:39574 dest: /172.20.1.17:9866
2025-03-26 02:26:28,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39574, dest: /172.20.1.17:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081, duration(ns): 818594
2025-03-26 02:26:28,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46986, dest: /172.20.1.15:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081, duration(ns): 1285759
2025-03-26 02:26:28,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,180 INFO terminating
2025-03-26 02:26:28,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,190 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_
2025-03-26 02:26:28,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,190 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,190 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,190 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082 src: /172.20.1.14:37580 dest: /172.20.1.17:9866
2025-03-26 02:26:28,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082 src: /172.20.1.17:47888 dest: /172.20.1.15:9866
2025-03-26 02:26:28,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47888, dest: /172.20.1.15:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082, duration(ns): 730684
2025-03-26 02:26:28,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,195 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37580, dest: /172.20.1.17:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082, duration(ns): 1248913
2025-03-26 02:26:28,195 INFO terminating
2025-03-26 02:26:28,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_
2025-03-26 02:26:28,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,201 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,201 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,201 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083 src: /172.20.1.14:46994 dest: /172.20.1.15:9866
2025-03-26 02:26:28,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083 src: /172.20.1.15:39578 dest: /172.20.1.17:9866
2025-03-26 02:26:28,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39578, dest: /172.20.1.17:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083, duration(ns): 750668
2025-03-26 02:26:28,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46994, dest: /172.20.1.15:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083, duration(ns): 1139459
2025-03-26 02:26:28,206 INFO terminating
2025-03-26 02:26:28,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_
2025-03-26 02:26:28,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,215 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,215 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,215 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084 src: /172.20.1.14:46998 dest: /172.20.1.15:9866
2025-03-26 02:26:28,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084 src: /172.20.1.15:39586 dest: /172.20.1.17:9866
2025-03-26 02:26:28,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46998, dest: /172.20.1.15:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084, duration(ns): 1321813
2025-03-26 02:26:28,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39586, dest: /172.20.1.17:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084, duration(ns): 966085
2025-03-26 02:26:28,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,219 INFO terminating
2025-03-26 02:26:28,221 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_
2025-03-26 02:26:28,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,228 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,228 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,228 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741909_1085 src: /172.20.1.14:37594 dest: /172.20.1.17:9866
2025-03-26 02:26:28,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741909_1085 src: /172.20.1.17:47902 dest: /172.20.1.15:9866
2025-03-26 02:26:28,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47902, dest: /172.20.1.15:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741909_1085, duration(ns): 806973
2025-03-26 02:26:28,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37594, dest: /172.20.1.17:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741909_1085, duration(ns): 1263601
2025-03-26 02:26:28,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741909_1085, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,233 INFO terminating
2025-03-26 02:26:28,234 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_
2025-03-26 02:26:28,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,238 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,238 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,238 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741910_1086 src: /172.20.1.14:37608 dest: /172.20.1.17:9866
2025-03-26 02:26:28,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741910_1086 src: /172.20.1.17:47914 dest: /172.20.1.15:9866
2025-03-26 02:26:28,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37608, dest: /172.20.1.17:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741910_1086, duration(ns): 1415964
2025-03-26 02:26:28,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47914, dest: /172.20.1.15:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741910_1086, duration(ns): 829980
2025-03-26 02:26:28,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741910_1086, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,243 INFO terminating
2025-03-26 02:26:28,244 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_
2025-03-26 02:26:28,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,250 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,250 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,250 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087 src: /172.20.1.14:47012 dest: /172.20.1.15:9866
2025-03-26 02:26:28,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087 src: /172.20.1.15:39602 dest: /172.20.1.17:9866
2025-03-26 02:26:28,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39602, dest: /172.20.1.17:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087, duration(ns): 581431
2025-03-26 02:26:28,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47012, dest: /172.20.1.15:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087, duration(ns): 982749
2025-03-26 02:26:28,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,254 INFO terminating
2025-03-26 02:26:28,255 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,259 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_
2025-03-26 02:26:28,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,259 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,259 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,259 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088 src: /172.20.1.14:47014 dest: /172.20.1.15:9866
2025-03-26 02:26:28,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088 src: /172.20.1.15:39610 dest: /172.20.1.17:9866
2025-03-26 02:26:28,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47014, dest: /172.20.1.15:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088, duration(ns): 956989
2025-03-26 02:26:28,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39610, dest: /172.20.1.17:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088, duration(ns): 582935
2025-03-26 02:26:28,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,263 INFO terminating
2025-03-26 02:26:28,264 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_
2025-03-26 02:26:28,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,272 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,272 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,272 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089 src: /172.20.1.14:37614 dest: /172.20.1.17:9866
2025-03-26 02:26:28,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089 src: /172.20.1.17:47920 dest: /172.20.1.15:9866
2025-03-26 02:26:28,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47920, dest: /172.20.1.15:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089, duration(ns): 1641080
2025-03-26 02:26:28,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,277 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37614, dest: /172.20.1.17:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089, duration(ns): 1888067
2025-03-26 02:26:28,277 INFO terminating
2025-03-26 02:26:28,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_
2025-03-26 02:26:28,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,285 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,285 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,285 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090 src: /172.20.1.14:37628 dest: /172.20.1.17:9866
2025-03-26 02:26:28,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090 src: /172.20.1.17:47924 dest: /172.20.1.15:9866
2025-03-26 02:26:28,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47924, dest: /172.20.1.15:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090, duration(ns): 744419
2025-03-26 02:26:28,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37628, dest: /172.20.1.17:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090, duration(ns): 699337
2025-03-26 02:26:28,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,290 INFO terminating
2025-03-26 02:26:28,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_
2025-03-26 02:26:28,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,295 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,295 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,295 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741915_1091 src: /172.20.1.14:37642 dest: /172.20.1.17:9866
2025-03-26 02:26:28,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741915_1091 src: /172.20.1.17:47926 dest: /172.20.1.15:9866
2025-03-26 02:26:28,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47926, dest: /172.20.1.15:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741915_1091, duration(ns): 645724
2025-03-26 02:26:28,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741915_1091, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37642, dest: /172.20.1.17:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741915_1091, duration(ns): 891650
2025-03-26 02:26:28,299 INFO terminating
2025-03-26 02:26:28,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,306 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_
2025-03-26 02:26:28,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,306 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,306 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,306 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741916_1092 src: /172.20.1.14:47016 dest: /172.20.1.15:9866
2025-03-26 02:26:28,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741916_1092 src: /172.20.1.15:39620 dest: /172.20.1.17:9866
2025-03-26 02:26:28,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47016, dest: /172.20.1.15:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741916_1092, duration(ns): 945985
2025-03-26 02:26:28,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39620, dest: /172.20.1.17:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741916_1092, duration(ns): 597969
2025-03-26 02:26:28,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741916_1092, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,310 INFO terminating
2025-03-26 02:26:28,312 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_
2025-03-26 02:26:28,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,316 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,316 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,316 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093 src: /172.20.1.14:37652 dest: /172.20.1.17:9866
2025-03-26 02:26:28,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093 src: /172.20.1.17:47940 dest: /172.20.1.15:9866
2025-03-26 02:26:28,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47940, dest: /172.20.1.15:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093, duration(ns): 675149
2025-03-26 02:26:28,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37652, dest: /172.20.1.17:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093, duration(ns): 758593
2025-03-26 02:26:28,320 INFO terminating
2025-03-26 02:26:28,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_
2025-03-26 02:26:28,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,326 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,326 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,326 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094 src: /172.20.1.14:47018 dest: /172.20.1.15:9866
2025-03-26 02:26:28,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094 src: /172.20.1.15:39636 dest: /172.20.1.17:9866
2025-03-26 02:26:28,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47018, dest: /172.20.1.15:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094, duration(ns): 2608972
2025-03-26 02:26:28,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39636, dest: /172.20.1.17:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094, duration(ns): 619666
2025-03-26 02:26:28,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,331 INFO terminating
2025-03-26 02:26:28,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,339 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,339 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,339 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,340 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/__init__.py._COPYING_
2025-03-26 02:26:28,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095 src: /172.20.1.14:47032 dest: /172.20.1.15:9866
2025-03-26 02:26:28,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095 src: /172.20.1.15:39644 dest: /172.20.1.17:9866
2025-03-26 02:26:28,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39644, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095, duration(ns): 870017
2025-03-26 02:26:28,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47032, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095, duration(ns): 1220772
2025-03-26 02:26:28,344 INFO terminating
2025-03-26 02:26:28,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/pagerank.py._COPYING_
2025-03-26 02:26:28,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,351 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096 src: /172.20.1.14:37654 dest: /172.20.1.17:9866
2025-03-26 02:26:28,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096 src: /172.20.1.17:47952 dest: /172.20.1.15:9866
2025-03-26 02:26:28,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47952, dest: /172.20.1.15:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096, duration(ns): 699600
2025-03-26 02:26:28,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,356 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pagerank.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37654, dest: /172.20.1.17:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096, duration(ns): 1305085
2025-03-26 02:26:28,356 INFO terminating
2025-03-26 02:26:28,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_
2025-03-26 02:26:28,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,369 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,369 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,369 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741921_1097 src: /172.20.1.14:37666 dest: /172.20.1.17:9866
2025-03-26 02:26:28,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741921_1097 src: /172.20.1.17:47958 dest: /172.20.1.15:9866
2025-03-26 02:26:28,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37666, dest: /172.20.1.17:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741921_1097, duration(ns): 1894238
2025-03-26 02:26:28,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47958, dest: /172.20.1.15:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741921_1097, duration(ns): 1641914
2025-03-26 02:26:28,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741921_1097, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,376 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,376 INFO terminating
2025-03-26 02:26:28,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_
2025-03-26 02:26:28,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,383 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,383 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,383 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741922_1098 src: /172.20.1.14:37676 dest: /172.20.1.17:9866
2025-03-26 02:26:28,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741922_1098 src: /172.20.1.17:47964 dest: /172.20.1.15:9866
2025-03-26 02:26:28,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37676, dest: /172.20.1.17:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741922_1098, duration(ns): 1578602
2025-03-26 02:26:28,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47964, dest: /172.20.1.15:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741922_1098, duration(ns): 1337963
2025-03-26 02:26:28,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741922_1098, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,388 INFO terminating
2025-03-26 02:26:28,389 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_
2025-03-26 02:26:28,393 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,393 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,393 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099 src: /172.20.1.14:37682 dest: /172.20.1.17:9866
2025-03-26 02:26:28,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099 src: /172.20.1.17:47980 dest: /172.20.1.15:9866
2025-03-26 02:26:28,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37682, dest: /172.20.1.17:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099, duration(ns): 841738
2025-03-26 02:26:28,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47980, dest: /172.20.1.15:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099, duration(ns): 676704
2025-03-26 02:26:28,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,396 INFO terminating
2025-03-26 02:26:28,397 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_
2025-03-26 02:26:28,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,403 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,403 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,403 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100 src: /172.20.1.14:37698 dest: /172.20.1.17:9866
2025-03-26 02:26:28,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100 src: /172.20.1.17:47982 dest: /172.20.1.15:9866
2025-03-26 02:26:28,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47982, dest: /172.20.1.15:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100, duration(ns): 674028
2025-03-26 02:26:28,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37698, dest: /172.20.1.17:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100, duration(ns): 1810491
2025-03-26 02:26:28,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,408 INFO terminating
2025-03-26 02:26:28,409 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,412 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,413 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_
2025-03-26 02:26:28,413 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,413 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101 src: /172.20.1.14:47044 dest: /172.20.1.15:9866
2025-03-26 02:26:28,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101 src: /172.20.1.15:39650 dest: /172.20.1.17:9866
2025-03-26 02:26:28,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47044, dest: /172.20.1.15:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101, duration(ns): 1267374
2025-03-26 02:26:28,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39650, dest: /172.20.1.17:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101, duration(ns): 625934
2025-03-26 02:26:28,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,417 INFO terminating
2025-03-26 02:26:28,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_
2025-03-26 02:26:28,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,422 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102 src: /172.20.1.14:37712 dest: /172.20.1.17:9866
2025-03-26 02:26:28,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102 src: /172.20.1.17:47986 dest: /172.20.1.15:9866
2025-03-26 02:26:28,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37712, dest: /172.20.1.17:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102, duration(ns): 906744
2025-03-26 02:26:28,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47986, dest: /172.20.1.15:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102, duration(ns): 671065
2025-03-26 02:26:28,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,427 INFO terminating
2025-03-26 02:26:28,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,431 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_
2025-03-26 02:26:28,432 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,432 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741927_1103 src: /172.20.1.14:37728 dest: /172.20.1.17:9866
2025-03-26 02:26:28,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741927_1103 src: /172.20.1.17:47988 dest: /172.20.1.15:9866
2025-03-26 02:26:28,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37728, dest: /172.20.1.17:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741927_1103, duration(ns): 1117861
2025-03-26 02:26:28,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47988, dest: /172.20.1.15:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741927_1103, duration(ns): 794094
2025-03-26 02:26:28,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741927_1103, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,437 INFO terminating
2025-03-26 02:26:28,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,441 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,441 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,441 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_
2025-03-26 02:26:28,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741928_1104 src: /172.20.1.14:37742 dest: /172.20.1.17:9866
2025-03-26 02:26:28,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741928_1104 src: /172.20.1.17:47996 dest: /172.20.1.15:9866
2025-03-26 02:26:28,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47996, dest: /172.20.1.15:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741928_1104, duration(ns): 800905
2025-03-26 02:26:28,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37742, dest: /172.20.1.17:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741928_1104, duration(ns): 1350184
2025-03-26 02:26:28,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741928_1104, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,447 INFO terminating
2025-03-26 02:26:28,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_
2025-03-26 02:26:28,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,454 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,454 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,454 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105 src: /172.20.1.14:37754 dest: /172.20.1.17:9866
2025-03-26 02:26:28,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105 src: /172.20.1.17:48002 dest: /172.20.1.15:9866
2025-03-26 02:26:28,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48002, dest: /172.20.1.15:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105, duration(ns): 753869
2025-03-26 02:26:28,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37754, dest: /172.20.1.17:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105, duration(ns): 981834
2025-03-26 02:26:28,459 INFO terminating
2025-03-26 02:26:28,460 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_
2025-03-26 02:26:28,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,465 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106 src: /172.20.1.14:37758 dest: /172.20.1.17:9866
2025-03-26 02:26:28,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106 src: /172.20.1.17:48012 dest: /172.20.1.15:9866
2025-03-26 02:26:28,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48012, dest: /172.20.1.15:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106, duration(ns): 871478
2025-03-26 02:26:28,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37758, dest: /172.20.1.17:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106, duration(ns): 1493993
2025-03-26 02:26:28,471 INFO terminating
2025-03-26 02:26:28,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_
2025-03-26 02:26:28,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,480 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107 src: /172.20.1.14:37772 dest: /172.20.1.17:9866
2025-03-26 02:26:28,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107 src: /172.20.1.17:48026 dest: /172.20.1.15:9866
2025-03-26 02:26:28,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37772, dest: /172.20.1.17:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107, duration(ns): 1233310
2025-03-26 02:26:28,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48026, dest: /172.20.1.15:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107, duration(ns): 1021822
2025-03-26 02:26:28,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,485 INFO terminating
2025-03-26 02:26:28,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,491 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_
2025-03-26 02:26:28,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,491 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,491 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,491 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108 src: /172.20.1.14:37788 dest: /172.20.1.17:9866
2025-03-26 02:26:28,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108 src: /172.20.1.17:48028 dest: /172.20.1.15:9866
2025-03-26 02:26:28,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37788, dest: /172.20.1.17:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108, duration(ns): 1052661
2025-03-26 02:26:28,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48028, dest: /172.20.1.15:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108, duration(ns): 722724
2025-03-26 02:26:28,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,497 INFO terminating
2025-03-26 02:26:28,498 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,503 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741933_1109 src: /172.20.1.14:47060 dest: /172.20.1.15:9866
2025-03-26 02:26:28,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741933_1109 src: /172.20.1.15:39662 dest: /172.20.1.17:9866
2025-03-26 02:26:28,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47060, dest: /172.20.1.15:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741933_1109, duration(ns): 1043541
2025-03-26 02:26:28,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39662, dest: /172.20.1.17:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741933_1109, duration(ns): 695742
2025-03-26 02:26:28,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741933_1109, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,510 INFO terminating
2025-03-26 02:26:28,512 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_
2025-03-26 02:26:28,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,516 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,516 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,516 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741934_1110 src: /172.20.1.14:37800 dest: /172.20.1.17:9866
2025-03-26 02:26:28,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741934_1110 src: /172.20.1.17:48044 dest: /172.20.1.15:9866
2025-03-26 02:26:28,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37800, dest: /172.20.1.17:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741934_1110, duration(ns): 902548
2025-03-26 02:26:28,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48044, dest: /172.20.1.15:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741934_1110, duration(ns): 620089
2025-03-26 02:26:28,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741934_1110, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,520 INFO terminating
2025-03-26 02:26:28,521 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,529 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,529 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,529 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,530 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_
2025-03-26 02:26:28,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111 src: /172.20.1.14:47064 dest: /172.20.1.15:9866
2025-03-26 02:26:28,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111 src: /172.20.1.15:39668 dest: /172.20.1.17:9866
2025-03-26 02:26:28,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39668, dest: /172.20.1.17:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111, duration(ns): 765164
2025-03-26 02:26:28,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,534 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47064, dest: /172.20.1.15:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111, duration(ns): 1143510
2025-03-26 02:26:28,534 INFO terminating
2025-03-26 02:26:28,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_
2025-03-26 02:26:28,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,538 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,538 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,538 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112 src: /172.20.1.14:47068 dest: /172.20.1.15:9866
2025-03-26 02:26:28,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112 src: /172.20.1.15:39680 dest: /172.20.1.17:9866
2025-03-26 02:26:28,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47068, dest: /172.20.1.15:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112, duration(ns): 868288
2025-03-26 02:26:28,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39680, dest: /172.20.1.17:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112, duration(ns): 484701
2025-03-26 02:26:28,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,541 INFO terminating
2025-03-26 02:26:28,542 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_
2025-03-26 02:26:28,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,546 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,546 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,546 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113 src: /172.20.1.14:47072 dest: /172.20.1.15:9866
2025-03-26 02:26:28,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113 src: /172.20.1.15:39684 dest: /172.20.1.17:9866
2025-03-26 02:26:28,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47072, dest: /172.20.1.15:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113, duration(ns): 950393
2025-03-26 02:26:28,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39684, dest: /172.20.1.17:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113, duration(ns): 649842
2025-03-26 02:26:28,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,550 INFO terminating
2025-03-26 02:26:28,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,554 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,555 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_
2025-03-26 02:26:28,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114 src: /172.20.1.14:47082 dest: /172.20.1.15:9866
2025-03-26 02:26:28,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114 src: /172.20.1.15:39698 dest: /172.20.1.17:9866
2025-03-26 02:26:28,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39698, dest: /172.20.1.17:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114, duration(ns): 1076875
2025-03-26 02:26:28,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47082, dest: /172.20.1.15:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114, duration(ns): 1726670
2025-03-26 02:26:28,560 INFO terminating
2025-03-26 02:26:28,561 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,567 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_
2025-03-26 02:26:28,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,567 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,567 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,567 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741939_1115 src: /172.20.1.14:47084 dest: /172.20.1.15:9866
2025-03-26 02:26:28,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741939_1115 src: /172.20.1.15:39702 dest: /172.20.1.17:9866
2025-03-26 02:26:28,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39702, dest: /172.20.1.17:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741939_1115, duration(ns): 712928
2025-03-26 02:26:28,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741939_1115, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47084, dest: /172.20.1.15:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741939_1115, duration(ns): 1137489
2025-03-26 02:26:28,571 INFO terminating
2025-03-26 02:26:28,572 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_
2025-03-26 02:26:28,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,576 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,576 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,576 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741940_1116 src: /172.20.1.14:47092 dest: /172.20.1.15:9866
2025-03-26 02:26:28,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741940_1116 src: /172.20.1.15:39714 dest: /172.20.1.17:9866
2025-03-26 02:26:28,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39714, dest: /172.20.1.17:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741940_1116, duration(ns): 720754
2025-03-26 02:26:28,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741940_1116, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47092, dest: /172.20.1.15:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741940_1116, duration(ns): 1057291
2025-03-26 02:26:28,583 INFO terminating
2025-03-26 02:26:28,584 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_
2025-03-26 02:26:28,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,590 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,590 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,590 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117 src: /172.20.1.14:47108 dest: /172.20.1.15:9866
2025-03-26 02:26:28,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117 src: /172.20.1.15:39724 dest: /172.20.1.17:9866
2025-03-26 02:26:28,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47108, dest: /172.20.1.15:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117, duration(ns): 1147285
2025-03-26 02:26:28,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39724, dest: /172.20.1.17:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117, duration(ns): 533826
2025-03-26 02:26:28,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,595 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,595 INFO terminating
2025-03-26 02:26:28,599 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_
2025-03-26 02:26:28,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,599 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,599 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,599 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118 src: /172.20.1.14:37810 dest: /172.20.1.17:9866
2025-03-26 02:26:28,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118 src: /172.20.1.17:48048 dest: /172.20.1.15:9866
2025-03-26 02:26:28,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48048, dest: /172.20.1.15:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118, duration(ns): 589187
2025-03-26 02:26:28,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37810, dest: /172.20.1.17:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118, duration(ns): 1067209
2025-03-26 02:26:28,604 INFO terminating
2025-03-26 02:26:28,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_
2025-03-26 02:26:28,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,612 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,612 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,612 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119 src: /172.20.1.14:47120 dest: /172.20.1.15:9866
2025-03-26 02:26:28,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119 src: /172.20.1.15:39738 dest: /172.20.1.17:9866
2025-03-26 02:26:28,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39738, dest: /172.20.1.17:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119, duration(ns): 567625
2025-03-26 02:26:28,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47120, dest: /172.20.1.15:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119, duration(ns): 916216
2025-03-26 02:26:28,616 INFO terminating
2025-03-26 02:26:28,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_
2025-03-26 02:26:28,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,624 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,624 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,624 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120 src: /172.20.1.14:47134 dest: /172.20.1.15:9866
2025-03-26 02:26:28,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120 src: /172.20.1.15:39750 dest: /172.20.1.17:9866
2025-03-26 02:26:28,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47134, dest: /172.20.1.15:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120, duration(ns): 1041330
2025-03-26 02:26:28,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39750, dest: /172.20.1.17:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120, duration(ns): 556352
2025-03-26 02:26:28,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,627 INFO terminating
2025-03-26 02:26:28,629 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,632 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_
2025-03-26 02:26:28,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,632 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,632 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,632 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741945_1121 src: /172.20.1.14:47146 dest: /172.20.1.15:9866
2025-03-26 02:26:28,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741945_1121 src: /172.20.1.15:39762 dest: /172.20.1.17:9866
2025-03-26 02:26:28,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39762, dest: /172.20.1.17:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741945_1121, duration(ns): 1424077
2025-03-26 02:26:28,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741945_1121, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,639 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47146, dest: /172.20.1.15:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741945_1121, duration(ns): 2183404
2025-03-26 02:26:28,639 INFO terminating
2025-03-26 02:26:28,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,647 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,647 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,647 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:26:28,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741946_1122 src: /172.20.1.14:37812 dest: /172.20.1.17:9866
2025-03-26 02:26:28,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741946_1122 src: /172.20.1.17:48062 dest: /172.20.1.15:9866
2025-03-26 02:26:28,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37812, dest: /172.20.1.17:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741946_1122, duration(ns): 844293
2025-03-26 02:26:28,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48062, dest: /172.20.1.15:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741946_1122, duration(ns): 625261
2025-03-26 02:26:28,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741946_1122, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,653 INFO terminating
2025-03-26 02:26:28,654 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,658 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/als_example.py._COPYING_
2025-03-26 02:26:28,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,658 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,658 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,658 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123 src: /172.20.1.14:47152 dest: /172.20.1.15:9866
2025-03-26 02:26:28,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123 src: /172.20.1.15:39764 dest: /172.20.1.17:9866
2025-03-26 02:26:28,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47152, dest: /172.20.1.15:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123, duration(ns): 830604
2025-03-26 02:26:28,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39764, dest: /172.20.1.17:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123, duration(ns): 520257
2025-03-26 02:26:28,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,661 INFO terminating
2025-03-26 02:26:28,662 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/als_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_
2025-03-26 02:26:28,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,665 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,665 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,665 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124 src: /172.20.1.14:37820 dest: /172.20.1.17:9866
2025-03-26 02:26:28,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124 src: /172.20.1.17:48076 dest: /172.20.1.15:9866
2025-03-26 02:26:28,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37820, dest: /172.20.1.17:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124, duration(ns): 1123522
2025-03-26 02:26:28,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48076, dest: /172.20.1.15:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124, duration(ns): 660918
2025-03-26 02:26:28,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,669 INFO terminating
2025-03-26 02:26:28,671 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_
2025-03-26 02:26:28,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,682 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,682 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,682 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125 src: /172.20.1.14:47158 dest: /172.20.1.15:9866
2025-03-26 02:26:28,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125 src: /172.20.1.15:39778 dest: /172.20.1.17:9866
2025-03-26 02:26:28,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39778, dest: /172.20.1.17:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125, duration(ns): 813959
2025-03-26 02:26:28,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,687 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47158, dest: /172.20.1.15:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125, duration(ns): 1558351
2025-03-26 02:26:28,687 INFO terminating
2025-03-26 02:26:28,691 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_
2025-03-26 02:26:28,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,691 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,691 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,691 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126 src: /172.20.1.14:37828 dest: /172.20.1.17:9866
2025-03-26 02:26:28,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126 src: /172.20.1.17:48092 dest: /172.20.1.15:9866
2025-03-26 02:26:28,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37828, dest: /172.20.1.17:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126, duration(ns): 990949
2025-03-26 02:26:28,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48092, dest: /172.20.1.15:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126, duration(ns): 805785
2025-03-26 02:26:28,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,696 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,696 INFO terminating
2025-03-26 02:26:28,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_
2025-03-26 02:26:28,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,700 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,700 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,700 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741951_1127 src: /172.20.1.14:37832 dest: /172.20.1.17:9866
2025-03-26 02:26:28,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741951_1127 src: /172.20.1.17:48104 dest: /172.20.1.15:9866
2025-03-26 02:26:28,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48104, dest: /172.20.1.15:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741951_1127, duration(ns): 571977
2025-03-26 02:26:28,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741951_1127, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,705 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37832, dest: /172.20.1.17:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741951_1127, duration(ns): 903502
2025-03-26 02:26:28,705 INFO terminating
2025-03-26 02:26:28,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_
2025-03-26 02:26:28,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,710 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,710 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,710 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741952_1128 src: /172.20.1.14:47170 dest: /172.20.1.15:9866
2025-03-26 02:26:28,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741952_1128 src: /172.20.1.15:39782 dest: /172.20.1.17:9866
2025-03-26 02:26:28,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47170, dest: /172.20.1.15:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741952_1128, duration(ns): 1844746
2025-03-26 02:26:28,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39782, dest: /172.20.1.17:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741952_1128, duration(ns): 945370
2025-03-26 02:26:28,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741952_1128, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,715 INFO terminating
2025-03-26 02:26:28,716 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_
2025-03-26 02:26:28,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,720 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,720 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,720 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129 src: /172.20.1.14:37838 dest: /172.20.1.17:9866
2025-03-26 02:26:28,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129 src: /172.20.1.17:48110 dest: /172.20.1.15:9866
2025-03-26 02:26:28,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48110, dest: /172.20.1.15:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129, duration(ns): 698254
2025-03-26 02:26:28,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,725 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:28,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37838, dest: /172.20.1.17:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129, duration(ns): 981019
2025-03-26 02:26:28,725 INFO terminating
2025-03-26 02:26:28,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_
2025-03-26 02:26:28,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,734 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,734 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,734 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130 src: /172.20.1.14:37848 dest: /172.20.1.17:9866
2025-03-26 02:26:28,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130 src: /172.20.1.17:48122 dest: /172.20.1.15:9866
2025-03-26 02:26:28,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37848, dest: /172.20.1.17:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130, duration(ns): 1663109
2025-03-26 02:26:28,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48122, dest: /172.20.1.15:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130, duration(ns): 910618
2025-03-26 02:26:28,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,739 INFO terminating
2025-03-26 02:26:28,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741954_1130 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_
2025-03-26 02:26:29,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_
2025-03-26 02:26:29,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,146 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,146 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,146 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131 src: /172.20.1.14:37852 dest: /172.20.1.17:9866
2025-03-26 02:26:29,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131 src: /172.20.1.17:48136 dest: /172.20.1.15:9866
2025-03-26 02:26:29,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48136, dest: /172.20.1.15:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131, duration(ns): 959454
2025-03-26 02:26:29,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,151 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37852, dest: /172.20.1.17:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131, duration(ns): 1090219
2025-03-26 02:26:29,151 INFO terminating
2025-03-26 02:26:29,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_
2025-03-26 02:26:29,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,156 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,156 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,156 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132 src: /172.20.1.14:47174 dest: /172.20.1.15:9866
2025-03-26 02:26:29,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132 src: /172.20.1.15:39796 dest: /172.20.1.17:9866
2025-03-26 02:26:29,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47174, dest: /172.20.1.15:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132, duration(ns): 1190859
2025-03-26 02:26:29,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39796, dest: /172.20.1.17:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132, duration(ns): 734142
2025-03-26 02:26:29,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,161 INFO terminating
2025-03-26 02:26:29,162 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,166 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_
2025-03-26 02:26:29,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,166 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,166 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,166 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741957_1133 src: /172.20.1.14:47182 dest: /172.20.1.15:9866
2025-03-26 02:26:29,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741957_1133 src: /172.20.1.15:39798 dest: /172.20.1.17:9866
2025-03-26 02:26:29,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39798, dest: /172.20.1.17:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741957_1133, duration(ns): 21780815
2025-03-26 02:26:29,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741957_1133, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47182, dest: /172.20.1.15:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741957_1133, duration(ns): 22305336
2025-03-26 02:26:29,192 INFO terminating
2025-03-26 02:26:29,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_
2025-03-26 02:26:29,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,198 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,198 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,198 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741958_1134 src: /172.20.1.14:37856 dest: /172.20.1.17:9866
2025-03-26 02:26:29,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741958_1134 src: /172.20.1.17:48146 dest: /172.20.1.15:9866
2025-03-26 02:26:29,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48146, dest: /172.20.1.15:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741958_1134, duration(ns): 1374224
2025-03-26 02:26:29,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741958_1134, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37856, dest: /172.20.1.17:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741958_1134, duration(ns): 2268895
2025-03-26 02:26:29,205 INFO terminating
2025-03-26 02:26:29,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_
2025-03-26 02:26:29,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,212 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,212 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,212 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135 src: /172.20.1.14:47184 dest: /172.20.1.15:9866
2025-03-26 02:26:29,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135 src: /172.20.1.15:39806 dest: /172.20.1.17:9866
2025-03-26 02:26:29,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39806, dest: /172.20.1.17:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135, duration(ns): 1071830
2025-03-26 02:26:29,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,218 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47184, dest: /172.20.1.15:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135, duration(ns): 1550090
2025-03-26 02:26:29,218 INFO terminating
2025-03-26 02:26:29,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:26:29,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,223 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,223 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,223 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741960_1136 src: /172.20.1.14:37862 dest: /172.20.1.17:9866
2025-03-26 02:26:29,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741960_1136 src: /172.20.1.17:48156 dest: /172.20.1.15:9866
2025-03-26 02:26:29,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48156, dest: /172.20.1.15:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741960_1136, duration(ns): 954352
2025-03-26 02:26:29,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741960_1136, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37862, dest: /172.20.1.17:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741960_1136, duration(ns): 992758
2025-03-26 02:26:29,228 INFO terminating
2025-03-26 02:26:29,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_
2025-03-26 02:26:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,233 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,233 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,233 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137 src: /172.20.1.14:47200 dest: /172.20.1.15:9866
2025-03-26 02:26:29,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137 src: /172.20.1.15:39820 dest: /172.20.1.17:9866
2025-03-26 02:26:29,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39820, dest: /172.20.1.17:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137, duration(ns): 790008
2025-03-26 02:26:29,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47200, dest: /172.20.1.15:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137, duration(ns): 1171455
2025-03-26 02:26:29,238 INFO terminating
2025-03-26 02:26:29,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,243 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_
2025-03-26 02:26:29,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,243 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,243 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,243 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741962_1138 src: /172.20.1.14:37868 dest: /172.20.1.17:9866
2025-03-26 02:26:29,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741962_1138 src: /172.20.1.17:48158 dest: /172.20.1.15:9866
2025-03-26 02:26:29,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37868, dest: /172.20.1.17:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741962_1138, duration(ns): 981110
2025-03-26 02:26:29,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48158, dest: /172.20.1.15:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741962_1138, duration(ns): 749196
2025-03-26 02:26:29,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741962_1138, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,248 INFO terminating
2025-03-26 02:26:29,249 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,253 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,254 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_
2025-03-26 02:26:29,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,254 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,254 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,254 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741963_1139 src: /172.20.1.14:47202 dest: /172.20.1.15:9866
2025-03-26 02:26:29,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741963_1139 src: /172.20.1.15:39832 dest: /172.20.1.17:9866
2025-03-26 02:26:29,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39832, dest: /172.20.1.17:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741963_1139, duration(ns): 879555
2025-03-26 02:26:29,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741963_1139, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47202, dest: /172.20.1.15:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741963_1139, duration(ns): 1222113
2025-03-26 02:26:29,263 INFO terminating
2025-03-26 02:26:29,264 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,268 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,268 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_
2025-03-26 02:26:29,269 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741964_1140 src: /172.20.1.14:47214 dest: /172.20.1.15:9866
2025-03-26 02:26:29,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741964_1140 src: /172.20.1.15:39840 dest: /172.20.1.17:9866
2025-03-26 02:26:29,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39840, dest: /172.20.1.17:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741964_1140, duration(ns): 607407
2025-03-26 02:26:29,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741964_1140, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47214, dest: /172.20.1.15:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741964_1140, duration(ns): 920676
2025-03-26 02:26:29,273 INFO terminating
2025-03-26 02:26:29,274 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_
2025-03-26 02:26:29,278 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,278 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,278 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,278 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,278 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,278 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741965_1141 src: /172.20.1.14:47220 dest: /172.20.1.15:9866
2025-03-26 02:26:29,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741965_1141 src: /172.20.1.15:39842 dest: /172.20.1.17:9866
2025-03-26 02:26:29,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47220, dest: /172.20.1.15:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741965_1141, duration(ns): 927434
2025-03-26 02:26:29,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39842, dest: /172.20.1.17:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741965_1141, duration(ns): 674198
2025-03-26 02:26:29,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741965_1141, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,282 INFO terminating
2025-03-26 02:26:29,283 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_
2025-03-26 02:26:29,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,287 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,287 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,287 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741966_1142 src: /172.20.1.14:37872 dest: /172.20.1.17:9866
2025-03-26 02:26:29,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741966_1142 src: /172.20.1.17:48170 dest: /172.20.1.15:9866
2025-03-26 02:26:29,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37872, dest: /172.20.1.17:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741966_1142, duration(ns): 868203
2025-03-26 02:26:29,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48170, dest: /172.20.1.15:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741966_1142, duration(ns): 657280
2025-03-26 02:26:29,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741966_1142, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,291 INFO terminating
2025-03-26 02:26:29,293 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,302 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/__init__,py._COPYING_
2025-03-26 02:26:29,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,302 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,302 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,302 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741967_1143 src: /172.20.1.14:37888 dest: /172.20.1.17:9866
2025-03-26 02:26:29,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741967_1143 src: /172.20.1.17:48180 dest: /172.20.1.15:9866
2025-03-26 02:26:29,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48180, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741967_1143, duration(ns): 610978
2025-03-26 02:26:29,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741967_1143, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37888, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741967_1143, duration(ns): 838172
2025-03-26 02:26:29,306 INFO terminating
2025-03-26 02:26:29,308 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,312 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,312 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,312 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_
2025-03-26 02:26:29,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741968_1144 src: /172.20.1.14:47232 dest: /172.20.1.15:9866
2025-03-26 02:26:29,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741968_1144 src: /172.20.1.15:39848 dest: /172.20.1.17:9866
2025-03-26 02:26:29,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39848, dest: /172.20.1.17:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741968_1144, duration(ns): 741404
2025-03-26 02:26:29,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47232, dest: /172.20.1.15:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741968_1144, duration(ns): 1155683
2025-03-26 02:26:29,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741968_1144, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,318 INFO terminating
2025-03-26 02:26:29,319 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,324 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_
2025-03-26 02:26:29,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741969_1145 src: /172.20.1.14:37902 dest: /172.20.1.17:9866
2025-03-26 02:26:29,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741969_1145 src: /172.20.1.17:48194 dest: /172.20.1.15:9866
2025-03-26 02:26:29,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48194, dest: /172.20.1.15:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741969_1145, duration(ns): 743883
2025-03-26 02:26:29,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741969_1145, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,333 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37902, dest: /172.20.1.17:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741969_1145, duration(ns): 1377830
2025-03-26 02:26:29,333 INFO terminating
2025-03-26 02:26:29,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_
2025-03-26 02:26:29,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,342 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,342 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,342 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741970_1146 src: /172.20.1.14:47238 dest: /172.20.1.15:9866
2025-03-26 02:26:29,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741970_1146 src: /172.20.1.15:39860 dest: /172.20.1.17:9866
2025-03-26 02:26:29,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47238, dest: /172.20.1.15:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741970_1146, duration(ns): 997276
2025-03-26 02:26:29,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39860, dest: /172.20.1.17:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741970_1146, duration(ns): 659093
2025-03-26 02:26:29,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741970_1146, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,346 INFO terminating
2025-03-26 02:26:29,347 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_
2025-03-26 02:26:29,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,355 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,355 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,355 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741971_1147 src: /172.20.1.14:47242 dest: /172.20.1.15:9866
2025-03-26 02:26:29,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741971_1147 src: /172.20.1.15:39874 dest: /172.20.1.17:9866
2025-03-26 02:26:29,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39874, dest: /172.20.1.17:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741971_1147, duration(ns): 630706
2025-03-26 02:26:29,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741971_1147, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,363 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47242, dest: /172.20.1.15:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741971_1147, duration(ns): 2276090
2025-03-26 02:26:29,363 INFO terminating
2025-03-26 02:26:29,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_
2025-03-26 02:26:29,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,368 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,368 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,368 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741972_1148 src: /172.20.1.14:47252 dest: /172.20.1.15:9866
2025-03-26 02:26:29,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741972_1148 src: /172.20.1.15:39882 dest: /172.20.1.17:9866
2025-03-26 02:26:29,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47252, dest: /172.20.1.15:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741972_1148, duration(ns): 1989163
2025-03-26 02:26:29,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39882, dest: /172.20.1.17:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741972_1148, duration(ns): 442447
2025-03-26 02:26:29,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741972_1148, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,373 INFO terminating
2025-03-26 02:26:29,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_
2025-03-26 02:26:29,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,379 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,379 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,379 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741973_1149 src: /172.20.1.14:37904 dest: /172.20.1.17:9866
2025-03-26 02:26:29,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741973_1149 src: /172.20.1.17:48210 dest: /172.20.1.15:9866
2025-03-26 02:26:29,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37904, dest: /172.20.1.17:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741973_1149, duration(ns): 1177369
2025-03-26 02:26:29,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48210, dest: /172.20.1.15:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741973_1149, duration(ns): 912771
2025-03-26 02:26:29,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741973_1149, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,383 INFO terminating
2025-03-26 02:26:29,384 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_
2025-03-26 02:26:29,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,390 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,390 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,390 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741974_1150 src: /172.20.1.14:47258 dest: /172.20.1.15:9866
2025-03-26 02:26:29,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741974_1150 src: /172.20.1.15:39890 dest: /172.20.1.17:9866
2025-03-26 02:26:29,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47258, dest: /172.20.1.15:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741974_1150, duration(ns): 925202
2025-03-26 02:26:29,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39890, dest: /172.20.1.17:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741974_1150, duration(ns): 543195
2025-03-26 02:26:29,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741974_1150, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,394 INFO terminating
2025-03-26 02:26:29,395 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,399 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_
2025-03-26 02:26:29,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,399 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,399 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,399 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741975_1151 src: /172.20.1.14:47264 dest: /172.20.1.15:9866
2025-03-26 02:26:29,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741975_1151 src: /172.20.1.15:39904 dest: /172.20.1.17:9866
2025-03-26 02:26:29,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47264, dest: /172.20.1.15:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741975_1151, duration(ns): 915473
2025-03-26 02:26:29,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39904, dest: /172.20.1.17:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741975_1151, duration(ns): 554765
2025-03-26 02:26:29,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741975_1151, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,403 INFO terminating
2025-03-26 02:26:29,404 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/pca_example.py._COPYING_
2025-03-26 02:26:29,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,408 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741976_1152 src: /172.20.1.14:37908 dest: /172.20.1.17:9866
2025-03-26 02:26:29,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741976_1152 src: /172.20.1.17:48218 dest: /172.20.1.15:9866
2025-03-26 02:26:29,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48218, dest: /172.20.1.15:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741976_1152, duration(ns): 812737
2025-03-26 02:26:29,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37908, dest: /172.20.1.17:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741976_1152, duration(ns): 1095762
2025-03-26 02:26:29,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741976_1152, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,413 INFO terminating
2025-03-26 02:26:29,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pca_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,420 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_
2025-03-26 02:26:29,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,420 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,420 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,420 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741977_1153 src: /172.20.1.14:37918 dest: /172.20.1.17:9866
2025-03-26 02:26:29,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741977_1153 src: /172.20.1.17:48226 dest: /172.20.1.15:9866
2025-03-26 02:26:29,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48226, dest: /172.20.1.15:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741977_1153, duration(ns): 3215042
2025-03-26 02:26:29,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741977_1153, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37918, dest: /172.20.1.17:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741977_1153, duration(ns): 3486380
2025-03-26 02:26:29,428 INFO terminating
2025-03-26 02:26:29,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/lda_example.py._COPYING_
2025-03-26 02:26:29,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,437 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,437 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,437 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741978_1154 src: /172.20.1.14:37924 dest: /172.20.1.17:9866
2025-03-26 02:26:29,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741978_1154 src: /172.20.1.17:48234 dest: /172.20.1.15:9866
2025-03-26 02:26:29,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48234, dest: /172.20.1.15:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741978_1154, duration(ns): 1191925
2025-03-26 02:26:29,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741978_1154, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/lda_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37924, dest: /172.20.1.17:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741978_1154, duration(ns): 1518618
2025-03-26 02:26:29,443 INFO terminating
2025-03-26 02:26:29,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_
2025-03-26 02:26:29,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,451 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741979_1155 src: /172.20.1.14:47280 dest: /172.20.1.15:9866
2025-03-26 02:26:29,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741979_1155 src: /172.20.1.15:39916 dest: /172.20.1.17:9866
2025-03-26 02:26:29,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39916, dest: /172.20.1.17:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741979_1155, duration(ns): 1358426
2025-03-26 02:26:29,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741979_1155, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47280, dest: /172.20.1.15:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741979_1155, duration(ns): 1726957
2025-03-26 02:26:29,457 INFO terminating
2025-03-26 02:26:29,459 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_
2025-03-26 02:26:29,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,465 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741980_1156 src: /172.20.1.14:47282 dest: /172.20.1.15:9866
2025-03-26 02:26:29,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741980_1156 src: /172.20.1.15:39930 dest: /172.20.1.17:9866
2025-03-26 02:26:29,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39930, dest: /172.20.1.17:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741980_1156, duration(ns): 614955
2025-03-26 02:26:29,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741980_1156, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47282, dest: /172.20.1.15:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741980_1156, duration(ns): 1150743
2025-03-26 02:26:29,470 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741980_1156 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_
2025-03-26 02:26:29,470 INFO terminating
2025-03-26 02:26:29,871 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,877 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_
2025-03-26 02:26:29,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,877 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,877 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,877 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741981_1157 src: /172.20.1.14:37926 dest: /172.20.1.17:9866
2025-03-26 02:26:29,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741981_1157 src: /172.20.1.17:48240 dest: /172.20.1.15:9866
2025-03-26 02:26:29,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48240, dest: /172.20.1.15:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741981_1157, duration(ns): 1427569
2025-03-26 02:26:29,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741981_1157, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37926, dest: /172.20.1.17:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741981_1157, duration(ns): 1653433
2025-03-26 02:26:29,885 INFO terminating
2025-03-26 02:26:29,886 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_
2025-03-26 02:26:29,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,893 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,893 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,893 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741982_1158 src: /172.20.1.14:37942 dest: /172.20.1.17:9866
2025-03-26 02:26:29,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741982_1158 src: /172.20.1.17:48250 dest: /172.20.1.15:9866
2025-03-26 02:26:29,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48250, dest: /172.20.1.15:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741982_1158, duration(ns): 1181456
2025-03-26 02:26:29,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741982_1158, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37942, dest: /172.20.1.17:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741982_1158, duration(ns): 1574435
2025-03-26 02:26:29,899 INFO terminating
2025-03-26 02:26:29,902 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_
2025-03-26 02:26:29,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,907 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,907 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,907 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741983_1159 src: /172.20.1.14:37954 dest: /172.20.1.17:9866
2025-03-26 02:26:29,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741983_1159 src: /172.20.1.17:48252 dest: /172.20.1.15:9866
2025-03-26 02:26:29,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48252, dest: /172.20.1.15:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741983_1159, duration(ns): 956979
2025-03-26 02:26:29,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37954, dest: /172.20.1.17:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741983_1159, duration(ns): 1137860
2025-03-26 02:26:29,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741983_1159, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,912 INFO terminating
2025-03-26 02:26:29,913 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_
2025-03-26 02:26:29,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,921 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,921 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,921 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741984_1160 src: /172.20.1.14:47296 dest: /172.20.1.15:9866
2025-03-26 02:26:29,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741984_1160 src: /172.20.1.15:39938 dest: /172.20.1.17:9866
2025-03-26 02:26:29,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39938, dest: /172.20.1.17:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741984_1160, duration(ns): 723876
2025-03-26 02:26:29,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741984_1160, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47296, dest: /172.20.1.15:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741984_1160, duration(ns): 1919360
2025-03-26 02:26:29,931 INFO terminating
2025-03-26 02:26:29,932 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_
2025-03-26 02:26:29,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,940 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,940 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,940 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741985_1161 src: /172.20.1.14:37956 dest: /172.20.1.17:9866
2025-03-26 02:26:29,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741985_1161 src: /172.20.1.17:48268 dest: /172.20.1.15:9866
2025-03-26 02:26:29,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37956, dest: /172.20.1.17:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741985_1161, duration(ns): 877138
2025-03-26 02:26:29,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48268, dest: /172.20.1.15:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741985_1161, duration(ns): 810893
2025-03-26 02:26:29,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741985_1161, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,944 INFO terminating
2025-03-26 02:26:29,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/dct_example.py._COPYING_
2025-03-26 02:26:29,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,949 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,949 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,949 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741986_1162 src: /172.20.1.14:37970 dest: /172.20.1.17:9866
2025-03-26 02:26:29,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741986_1162 src: /172.20.1.17:48280 dest: /172.20.1.15:9866
2025-03-26 02:26:29,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37970, dest: /172.20.1.17:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741986_1162, duration(ns): 926286
2025-03-26 02:26:29,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48280, dest: /172.20.1.15:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741986_1162, duration(ns): 740673
2025-03-26 02:26:29,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741986_1162, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,953 INFO terminating
2025-03-26 02:26:29,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dct_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_
2025-03-26 02:26:29,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,959 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,959 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,959 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741987_1163 src: /172.20.1.14:37986 dest: /172.20.1.17:9866
2025-03-26 02:26:29,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741987_1163 src: /172.20.1.17:48292 dest: /172.20.1.15:9866
2025-03-26 02:26:29,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48292, dest: /172.20.1.15:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741987_1163, duration(ns): 837180
2025-03-26 02:26:29,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741987_1163, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37986, dest: /172.20.1.17:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741987_1163, duration(ns): 1068300
2025-03-26 02:26:29,964 INFO terminating
2025-03-26 02:26:29,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:26:29,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,968 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,968 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,968 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741988_1164 src: /172.20.1.14:47312 dest: /172.20.1.15:9866
2025-03-26 02:26:29,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741988_1164 src: /172.20.1.15:39940 dest: /172.20.1.17:9866
2025-03-26 02:26:29,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47312, dest: /172.20.1.15:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741988_1164, duration(ns): 1054965
2025-03-26 02:26:29,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39940, dest: /172.20.1.17:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741988_1164, duration(ns): 640205
2025-03-26 02:26:29,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741988_1164, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,972 INFO terminating
2025-03-26 02:26:29,973 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,979 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_
2025-03-26 02:26:29,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,979 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,979 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,979 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741989_1165 src: /172.20.1.14:47314 dest: /172.20.1.15:9866
2025-03-26 02:26:29,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741989_1165 src: /172.20.1.15:39956 dest: /172.20.1.17:9866
2025-03-26 02:26:29,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39956, dest: /172.20.1.17:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741989_1165, duration(ns): 727431
2025-03-26 02:26:29,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741989_1165, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,984 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47314, dest: /172.20.1.15:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741989_1165, duration(ns): 1046441
2025-03-26 02:26:29,984 INFO terminating
2025-03-26 02:26:29,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_
2025-03-26 02:26:29,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,988 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,988 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,988 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741990_1166 src: /172.20.1.14:37992 dest: /172.20.1.17:9866
2025-03-26 02:26:29,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741990_1166 src: /172.20.1.17:48304 dest: /172.20.1.15:9866
2025-03-26 02:26:29,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37992, dest: /172.20.1.17:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741990_1166, duration(ns): 797533
2025-03-26 02:26:29,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48304, dest: /172.20.1.15:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741990_1166, duration(ns): 596829
2025-03-26 02:26:29,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741990_1166, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,992 INFO terminating
2025-03-26 02:26:29,993 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:29,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_
2025-03-26 02:26:29,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,996 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:29,996 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:29,996 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:29,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741991_1167 src: /172.20.1.14:47318 dest: /172.20.1.15:9866
2025-03-26 02:26:29,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741991_1167 src: /172.20.1.15:39964 dest: /172.20.1.17:9866
2025-03-26 02:26:30,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47318, dest: /172.20.1.15:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741991_1167, duration(ns): 1369283
2025-03-26 02:26:30,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39964, dest: /172.20.1.17:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741991_1167, duration(ns): 932019
2025-03-26 02:26:30,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741991_1167, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,000 INFO terminating
2025-03-26 02:26:30,001 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/als.py._COPYING_
2025-03-26 02:26:30,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,005 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,005 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,005 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741992_1168 src: /172.20.1.14:37998 dest: /172.20.1.17:9866
2025-03-26 02:26:30,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741992_1168 src: /172.20.1.17:48308 dest: /172.20.1.15:9866
2025-03-26 02:26:30,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37998, dest: /172.20.1.17:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741992_1168, duration(ns): 797259
2025-03-26 02:26:30,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48308, dest: /172.20.1.15:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741992_1168, duration(ns): 527075
2025-03-26 02:26:30,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741992_1168, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,008 INFO terminating
2025-03-26 02:26:30,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741992_1168 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/als.py._COPYING_
2025-03-26 02:26:30,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,224 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,224 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,224 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,224 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,225 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,226 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,226 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,226 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/als.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,418 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/hive.py._COPYING_
2025-03-26 02:26:30,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,418 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,418 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,418 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741993_1169 src: /172.20.1.14:47324 dest: /172.20.1.15:9866
2025-03-26 02:26:30,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741993_1169 src: /172.20.1.15:39968 dest: /172.20.1.17:9866
2025-03-26 02:26:30,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47324, dest: /172.20.1.15:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741993_1169, duration(ns): 1143116
2025-03-26 02:26:30,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39968, dest: /172.20.1.17:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741993_1169, duration(ns): 712094
2025-03-26 02:26:30,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741993_1169, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,422 INFO terminating
2025-03-26 02:26:30,423 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/hive.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1170, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/__init__.py._COPYING_
2025-03-26 02:26:30,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,427 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,427 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,427 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741994_1170 src: /172.20.1.14:38008 dest: /172.20.1.17:9866
2025-03-26 02:26:30,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741994_1170 src: /172.20.1.17:48310 dest: /172.20.1.15:9866
2025-03-26 02:26:30,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48310, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741994_1170, duration(ns): 670282
2025-03-26 02:26:30,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741994_1170, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,431 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38008, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741994_1170, duration(ns): 875848
2025-03-26 02:26:30,431 INFO terminating
2025-03-26 02:26:30,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1171, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/datasource.py._COPYING_
2025-03-26 02:26:30,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,436 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741995_1171 src: /172.20.1.14:38010 dest: /172.20.1.17:9866
2025-03-26 02:26:30,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741995_1171 src: /172.20.1.17:48324 dest: /172.20.1.15:9866
2025-03-26 02:26:30,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48324, dest: /172.20.1.15:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741995_1171, duration(ns): 925129
2025-03-26 02:26:30,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741995_1171, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,441 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/datasource.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38010, dest: /172.20.1.17:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741995_1171, duration(ns): 1458911
2025-03-26 02:26:30,441 INFO terminating
2025-03-26 02:26:30,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1172, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/basic.py._COPYING_
2025-03-26 02:26:30,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,445 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,445 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,445 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741996_1172 src: /172.20.1.14:47326 dest: /172.20.1.15:9866
2025-03-26 02:26:30,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741996_1172 src: /172.20.1.15:39974 dest: /172.20.1.17:9866
2025-03-26 02:26:30,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39974, dest: /172.20.1.17:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741996_1172, duration(ns): 594157
2025-03-26 02:26:30,449 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/basic.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47326, dest: /172.20.1.15:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741996_1172, duration(ns): 1215539
2025-03-26 02:26:30,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741996_1172, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,449 INFO terminating
2025-03-26 02:26:30,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1173, replicas=172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/arrow.py._COPYING_
2025-03-26 02:26:30,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,453 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741997_1173 src: /172.20.1.14:38012 dest: /172.20.1.17:9866
2025-03-26 02:26:30,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741997_1173 src: /172.20.1.17:48336 dest: /172.20.1.15:9866
2025-03-26 02:26:30,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38012, dest: /172.20.1.17:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741997_1173, duration(ns): 766399
2025-03-26 02:26:30,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48336, dest: /172.20.1.15:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741997_1173, duration(ns): 618017
2025-03-26 02:26:30,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741997_1173, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,457 INFO terminating
2025-03-26 02:26:30,460 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/arrow.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1174, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_
2025-03-26 02:26:30,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,469 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741998_1174 src: /172.20.1.14:47332 dest: /172.20.1.15:9866
2025-03-26 02:26:30,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741998_1174 src: /172.20.1.15:39988 dest: /172.20.1.17:9866
2025-03-26 02:26:30,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47332, dest: /172.20.1.15:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741998_1174, duration(ns): 981056
2025-03-26 02:26:30,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39988, dest: /172.20.1.17:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741998_1174, duration(ns): 735067
2025-03-26 02:26:30,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741998_1174, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,473 INFO terminating
2025-03-26 02:26:30,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1175, replicas=172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_
2025-03-26 02:26:30,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,478 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,478 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,478 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741999_1175 src: /172.20.1.14:47348 dest: /172.20.1.15:9866
2025-03-26 02:26:30,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741999_1175 src: /172.20.1.15:40004 dest: /172.20.1.17:9866
2025-03-26 02:26:30,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47348, dest: /172.20.1.15:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741999_1175, duration(ns): 2663808
2025-03-26 02:26:30,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40004, dest: /172.20.1.17:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073741999_1175, duration(ns): 2320296
2025-03-26 02:26:30,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073741999_1175, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,483 INFO terminating
2025-03-26 02:26:30,484 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1176, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_
2025-03-26 02:26:30,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742000_1176 src: /172.20.1.14:38020 dest: /172.20.1.17:9866
2025-03-26 02:26:30,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742000_1176 src: /172.20.1.17:48338 dest: /172.20.1.15:9866
2025-03-26 02:26:30,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742000_1176 src: /172.20.1.15:59048 dest: /172.20.1.16:9866
2025-03-26 02:26:30,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59048, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742000_1176, duration(ns): 3686577
2025-03-26 02:26:30,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742000_1176, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38020, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742000_1176, duration(ns): 5404316
2025-03-26 02:26:30,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48338, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742000_1176, duration(ns): 5153947
2025-03-26 02:26:30,500 INFO terminating
2025-03-26 02:26:30,500 INFO terminating
2025-03-26 02:26:30,501 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1177, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_
2025-03-26 02:26:30,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,505 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,505 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,505 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742001_1177 src: /172.20.1.14:47350 dest: /172.20.1.15:9866
2025-03-26 02:26:30,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742001_1177 src: /172.20.1.15:59060 dest: /172.20.1.16:9866
2025-03-26 02:26:30,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59060, dest: /172.20.1.16:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742001_1177, duration(ns): 7067540
2025-03-26 02:26:30,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742001_1177, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,516 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47350, dest: /172.20.1.15:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742001_1177, duration(ns): 7625773
2025-03-26 02:26:30,516 INFO terminating
2025-03-26 02:26:30,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1178, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_
2025-03-26 02:26:30,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,525 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742002_1178 src: /172.20.1.14:47352 dest: /172.20.1.15:9866
2025-03-26 02:26:30,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742002_1178 src: /172.20.1.15:59074 dest: /172.20.1.16:9866
2025-03-26 02:26:30,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47352, dest: /172.20.1.15:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742002_1178, duration(ns): 3170602
2025-03-26 02:26:30,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59074, dest: /172.20.1.16:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742002_1178, duration(ns): 2047115
2025-03-26 02:26:30,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742002_1178, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,532 INFO terminating
2025-03-26 02:26:30,534 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1179, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_
2025-03-26 02:26:30,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,549 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742003_1179 src: /172.20.1.14:51470 dest: /172.20.1.16:9866
2025-03-26 02:26:30,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742003_1179 src: /172.20.1.16:40550 dest: /172.20.1.15:9866
2025-03-26 02:26:30,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51470, dest: /172.20.1.16:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742003_1179, duration(ns): 1497878
2025-03-26 02:26:30,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40550, dest: /172.20.1.15:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742003_1179, duration(ns): 1466572
2025-03-26 02:26:30,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742003_1179, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,555 INFO terminating
2025-03-26 02:26:30,556 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1180, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_
2025-03-26 02:26:30,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,561 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,561 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,561 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742004_1180 src: /172.20.1.14:47360 dest: /172.20.1.15:9866
2025-03-26 02:26:30,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742004_1180 src: /172.20.1.15:59076 dest: /172.20.1.16:9866
2025-03-26 02:26:30,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59076, dest: /172.20.1.16:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742004_1180, duration(ns): 2527173
2025-03-26 02:26:30,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742004_1180, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47360, dest: /172.20.1.15:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742004_1180, duration(ns): 3101494
2025-03-26 02:26:30,568 INFO terminating
2025-03-26 02:26:30,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,573 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,573 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1181, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/__init__.py._COPYING_
2025-03-26 02:26:30,574 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742005_1181 src: /172.20.1.14:51474 dest: /172.20.1.16:9866
2025-03-26 02:26:30,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742005_1181 src: /172.20.1.16:40558 dest: /172.20.1.15:9866
2025-03-26 02:26:30,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51474, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742005_1181, duration(ns): 3567275
2025-03-26 02:26:30,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40558, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742005_1181, duration(ns): 1299447
2025-03-26 02:26:30,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742005_1181, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,582 INFO terminating
2025-03-26 02:26:30,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1182, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_
2025-03-26 02:26:30,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,588 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,588 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,588 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742006_1182 src: /172.20.1.14:51486 dest: /172.20.1.16:9866
2025-03-26 02:26:30,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742006_1182 src: /172.20.1.16:40564 dest: /172.20.1.15:9866
2025-03-26 02:26:30,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40564, dest: /172.20.1.15:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742006_1182, duration(ns): 1079979
2025-03-26 02:26:30,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742006_1182, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51486, dest: /172.20.1.16:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742006_1182, duration(ns): 1084231
2025-03-26 02:26:30,594 INFO terminating
2025-03-26 02:26:30,595 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1183, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_
2025-03-26 02:26:30,603 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,603 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,603 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742007_1183 src: /172.20.1.14:51494 dest: /172.20.1.16:9866
2025-03-26 02:26:30,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742007_1183 src: /172.20.1.16:40572 dest: /172.20.1.15:9866
2025-03-26 02:26:30,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40572, dest: /172.20.1.15:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742007_1183, duration(ns): 6931327
2025-03-26 02:26:30,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51494, dest: /172.20.1.16:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742007_1183, duration(ns): 7078507
2025-03-26 02:26:30,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742007_1183, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,616 INFO terminating
2025-03-26 02:26:30,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1184, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_
2025-03-26 02:26:30,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,621 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,621 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,621 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742008_1184 src: /172.20.1.14:51510 dest: /172.20.1.16:9866
2025-03-26 02:26:30,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742008_1184 src: /172.20.1.16:40574 dest: /172.20.1.15:9866
2025-03-26 02:26:30,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51510, dest: /172.20.1.16:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742008_1184, duration(ns): 8867246
2025-03-26 02:26:30,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40574, dest: /172.20.1.15:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742008_1184, duration(ns): 8735989
2025-03-26 02:26:30,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742008_1184, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,634 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,634 INFO terminating
2025-03-26 02:26:30,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1185, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_
2025-03-26 02:26:30,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,638 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,638 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,638 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742009_1185 src: /172.20.1.14:47370 dest: /172.20.1.15:9866
2025-03-26 02:26:30,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742009_1185 src: /172.20.1.15:59082 dest: /172.20.1.16:9866
2025-03-26 02:26:30,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59082, dest: /172.20.1.16:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742009_1185, duration(ns): 1464803
2025-03-26 02:26:30,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742009_1185, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47370, dest: /172.20.1.15:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742009_1185, duration(ns): 1945836
2025-03-26 02:26:30,643 INFO terminating
2025-03-26 02:26:30,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1186, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_
2025-03-26 02:26:30,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,647 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,647 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,647 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742010_1186 src: /172.20.1.14:47384 dest: /172.20.1.15:9866
2025-03-26 02:26:30,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742010_1186 src: /172.20.1.15:59084 dest: /172.20.1.16:9866
2025-03-26 02:26:30,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59084, dest: /172.20.1.16:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742010_1186, duration(ns): 627263
2025-03-26 02:26:30,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47384, dest: /172.20.1.15:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742010_1186, duration(ns): 1334724
2025-03-26 02:26:30,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742010_1186, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,652 INFO terminating
2025-03-26 02:26:30,653 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,664 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1187, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/data-manipulation.R._COPYING_
2025-03-26 02:26:30,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,665 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,665 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,665 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742011_1187 src: /172.20.1.14:47386 dest: /172.20.1.15:9866
2025-03-26 02:26:30,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742011_1187 src: /172.20.1.15:59098 dest: /172.20.1.16:9866
2025-03-26 02:26:30,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47386, dest: /172.20.1.15:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742011_1187, duration(ns): 3336593
2025-03-26 02:26:30,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59098, dest: /172.20.1.16:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742011_1187, duration(ns): 2969933
2025-03-26 02:26:30,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742011_1187, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,671 INFO terminating
2025-03-26 02:26:30,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/data-manipulation.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,678 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1188, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_
2025-03-26 02:26:30,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,678 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,678 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,678 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742012_1188 src: /172.20.1.14:51522 dest: /172.20.1.16:9866
2025-03-26 02:26:30,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742012_1188 src: /172.20.1.16:40590 dest: /172.20.1.15:9866
2025-03-26 02:26:30,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51522, dest: /172.20.1.16:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742012_1188, duration(ns): 1028741
2025-03-26 02:26:30,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40590, dest: /172.20.1.15:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742012_1188, duration(ns): 845440
2025-03-26 02:26:30,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742012_1188, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,684 INFO terminating
2025-03-26 02:26:30,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,688 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,688 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1189, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/als.R._COPYING_
2025-03-26 02:26:30,689 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742013_1189 src: /172.20.1.14:51532 dest: /172.20.1.16:9866
2025-03-26 02:26:30,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742013_1189 src: /172.20.1.16:40598 dest: /172.20.1.15:9866
2025-03-26 02:26:30,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51532, dest: /172.20.1.16:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742013_1189, duration(ns): 5724241
2025-03-26 02:26:30,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40598, dest: /172.20.1.15:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742013_1189, duration(ns): 5403784
2025-03-26 02:26:30,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742013_1189, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,697 INFO terminating
2025-03-26 02:26:30,698 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/als.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1190, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/ml.R._COPYING_
2025-03-26 02:26:30,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,705 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,705 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,705 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742014_1190 src: /172.20.1.14:51544 dest: /172.20.1.16:9866
2025-03-26 02:26:30,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742014_1190 src: /172.20.1.16:40606 dest: /172.20.1.15:9866
2025-03-26 02:26:30,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40606, dest: /172.20.1.15:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742014_1190, duration(ns): 2531077
2025-03-26 02:26:30,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742014_1190, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,712 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/ml.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51544, dest: /172.20.1.16:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742014_1190, duration(ns): 3071385
2025-03-26 02:26:30,712 INFO terminating
2025-03-26 02:26:30,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1191, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_
2025-03-26 02:26:30,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,720 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,720 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,720 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742015_1191 src: /172.20.1.14:51548 dest: /172.20.1.16:9866
2025-03-26 02:26:30,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742015_1191 src: /172.20.1.16:40618 dest: /172.20.1.15:9866
2025-03-26 02:26:30,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40618, dest: /172.20.1.15:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742015_1191, duration(ns): 973616
2025-03-26 02:26:30,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742015_1191, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51548, dest: /172.20.1.16:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742015_1191, duration(ns): 1202117
2025-03-26 02:26:30,725 INFO terminating
2025-03-26 02:26:30,727 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1192, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_
2025-03-26 02:26:30,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,731 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,731 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,731 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742016_1192 src: /172.20.1.14:47392 dest: /172.20.1.15:9866
2025-03-26 02:26:30,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742016_1192 src: /172.20.1.15:59102 dest: /172.20.1.16:9866
2025-03-26 02:26:30,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59102, dest: /172.20.1.16:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742016_1192, duration(ns): 873024
2025-03-26 02:26:30,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742016_1192, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47392, dest: /172.20.1.15:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742016_1192, duration(ns): 1308614
2025-03-26 02:26:30,738 INFO terminating
2025-03-26 02:26:30,739 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1193, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_
2025-03-26 02:26:30,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,747 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,747 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,747 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742017_1193 src: /172.20.1.14:51556 dest: /172.20.1.16:9866
2025-03-26 02:26:30,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742017_1193 src: /172.20.1.16:40634 dest: /172.20.1.15:9866
2025-03-26 02:26:30,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51556, dest: /172.20.1.16:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742017_1193, duration(ns): 1014829
2025-03-26 02:26:30,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40634, dest: /172.20.1.15:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742017_1193, duration(ns): 815133
2025-03-26 02:26:30,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742017_1193, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,751 INFO terminating
2025-03-26 02:26:30,752 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,756 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,756 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,756 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,757 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1194, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_
2025-03-26 02:26:30,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742018_1194 src: /172.20.1.14:47404 dest: /172.20.1.15:9866
2025-03-26 02:26:30,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742018_1194 src: /172.20.1.15:59118 dest: /172.20.1.16:9866
2025-03-26 02:26:30,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59118, dest: /172.20.1.16:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742018_1194, duration(ns): 9965935
2025-03-26 02:26:30,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742018_1194, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47404, dest: /172.20.1.15:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742018_1194, duration(ns): 10874596
2025-03-26 02:26:30,771 INFO terminating
2025-03-26 02:26:30,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1195, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_
2025-03-26 02:26:30,775 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,775 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,775 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,775 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,775 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,775 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742019_1195 src: /172.20.1.14:47412 dest: /172.20.1.15:9866
2025-03-26 02:26:30,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742019_1195 src: /172.20.1.15:59134 dest: /172.20.1.16:9866
2025-03-26 02:26:30,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59134, dest: /172.20.1.16:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742019_1195, duration(ns): 430185
2025-03-26 02:26:30,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742019_1195, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,779 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47412, dest: /172.20.1.15:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742019_1195, duration(ns): 1018457
2025-03-26 02:26:30,779 INFO terminating
2025-03-26 02:26:30,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1196, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/lda.R._COPYING_
2025-03-26 02:26:30,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,787 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,787 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,787 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742020_1196 src: /172.20.1.14:51558 dest: /172.20.1.16:9866
2025-03-26 02:26:30,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742020_1196 src: /172.20.1.16:40638 dest: /172.20.1.15:9866
2025-03-26 02:26:30,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40638, dest: /172.20.1.15:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742020_1196, duration(ns): 825897
2025-03-26 02:26:30,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742020_1196, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lda.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:30,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51558, dest: /172.20.1.16:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742020_1196, duration(ns): 1000639
2025-03-26 02:26:30,792 INFO terminating
2025-03-26 02:26:30,796 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1197, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/survreg.R._COPYING_
2025-03-26 02:26:30,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:30,796 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:30,796 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:30,796 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:30,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742021_1197 src: /172.20.1.14:47416 dest: /172.20.1.15:9866
2025-03-26 02:26:30,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742021_1197 src: /172.20.1.15:59136 dest: /172.20.1.16:9866
2025-03-26 02:26:30,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59136, dest: /172.20.1.16:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742021_1197, duration(ns): 853413
2025-03-26 02:26:30,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47416, dest: /172.20.1.15:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742021_1197, duration(ns): 1607424
2025-03-26 02:26:30,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742021_1197, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:30,801 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742021_1197 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/r/ml/survreg.R._COPYING_
2025-03-26 02:26:30,801 INFO terminating
2025-03-26 02:26:31,203 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/survreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,215 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,215 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,215 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1198, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_
2025-03-26 02:26:31,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742022_1198 src: /172.20.1.14:51568 dest: /172.20.1.16:9866
2025-03-26 02:26:31,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742022_1198 src: /172.20.1.16:40652 dest: /172.20.1.15:9866
2025-03-26 02:26:31,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40652, dest: /172.20.1.15:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742022_1198, duration(ns): 1266532
2025-03-26 02:26:31,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742022_1198, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51568, dest: /172.20.1.16:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742022_1198, duration(ns): 1660805
2025-03-26 02:26:31,226 INFO terminating
2025-03-26 02:26:31,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1199, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/isoreg.R._COPYING_
2025-03-26 02:26:31,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,236 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,236 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,236 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742023_1199 src: /172.20.1.14:51570 dest: /172.20.1.16:9866
2025-03-26 02:26:31,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742023_1199 src: /172.20.1.16:40666 dest: /172.20.1.15:9866
2025-03-26 02:26:31,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40666, dest: /172.20.1.15:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742023_1199, duration(ns): 1581747
2025-03-26 02:26:31,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742023_1199, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,242 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/isoreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51570, dest: /172.20.1.16:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742023_1199, duration(ns): 1654672
2025-03-26 02:26:31,242 INFO terminating
2025-03-26 02:26:31,246 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1200, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_
2025-03-26 02:26:31,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,246 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,246 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,246 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742024_1200 src: /172.20.1.14:51586 dest: /172.20.1.16:9866
2025-03-26 02:26:31,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742024_1200 src: /172.20.1.16:40672 dest: /172.20.1.15:9866
2025-03-26 02:26:31,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40672, dest: /172.20.1.15:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742024_1200, duration(ns): 849143
2025-03-26 02:26:31,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51586, dest: /172.20.1.16:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742024_1200, duration(ns): 893657
2025-03-26 02:26:31,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742024_1200, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,250 INFO terminating
2025-03-26 02:26:31,254 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1201, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/mlp.R._COPYING_
2025-03-26 02:26:31,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,254 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,254 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,254 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742025_1201 src: /172.20.1.14:47428 dest: /172.20.1.15:9866
2025-03-26 02:26:31,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742025_1201 src: /172.20.1.15:59152 dest: /172.20.1.16:9866
2025-03-26 02:26:31,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47428, dest: /172.20.1.15:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742025_1201, duration(ns): 4102541
2025-03-26 02:26:31,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59152, dest: /172.20.1.16:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742025_1201, duration(ns): 436514
2025-03-26 02:26:31,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742025_1201, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,261 INFO terminating
2025-03-26 02:26:31,262 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/mlp.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1202, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/fpm.R._COPYING_
2025-03-26 02:26:31,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,265 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,265 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,265 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742026_1202 src: /172.20.1.14:47444 dest: /172.20.1.15:9866
2025-03-26 02:26:31,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742026_1202 src: /172.20.1.15:59162 dest: /172.20.1.16:9866
2025-03-26 02:26:31,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47444, dest: /172.20.1.15:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742026_1202, duration(ns): 1107861
2025-03-26 02:26:31,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59162, dest: /172.20.1.16:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742026_1202, duration(ns): 707225
2025-03-26 02:26:31,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742026_1202, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,269 INFO terminating
2025-03-26 02:26:31,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fpm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,273 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,273 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,273 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1203, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/glm.R._COPYING_
2025-03-26 02:26:31,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742027_1203 src: /172.20.1.14:51588 dest: /172.20.1.16:9866
2025-03-26 02:26:31,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742027_1203 src: /172.20.1.16:40678 dest: /172.20.1.15:9866
2025-03-26 02:26:31,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40678, dest: /172.20.1.15:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742027_1203, duration(ns): 812105
2025-03-26 02:26:31,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742027_1203, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51588, dest: /172.20.1.16:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742027_1203, duration(ns): 989816
2025-03-26 02:26:31,278 INFO terminating
2025-03-26 02:26:31,279 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/glm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,282 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1204, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/randomForest.R._COPYING_
2025-03-26 02:26:31,282 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,282 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,282 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,282 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,282 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,282 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742028_1204 src: /172.20.1.14:51594 dest: /172.20.1.16:9866
2025-03-26 02:26:31,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742028_1204 src: /172.20.1.16:40680 dest: /172.20.1.15:9866
2025-03-26 02:26:31,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40680, dest: /172.20.1.15:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742028_1204, duration(ns): 857673
2025-03-26 02:26:31,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742028_1204, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51594, dest: /172.20.1.16:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742028_1204, duration(ns): 1127967
2025-03-26 02:26:31,287 INFO terminating
2025-03-26 02:26:31,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/randomForest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,292 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,292 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,292 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1205, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_
2025-03-26 02:26:31,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742029_1205 src: /172.20.1.14:51598 dest: /172.20.1.16:9866
2025-03-26 02:26:31,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742029_1205 src: /172.20.1.16:40696 dest: /172.20.1.15:9866
2025-03-26 02:26:31,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51598, dest: /172.20.1.16:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742029_1205, duration(ns): 1293928
2025-03-26 02:26:31,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40696, dest: /172.20.1.15:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742029_1205, duration(ns): 1125729
2025-03-26 02:26:31,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742029_1205, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,297 INFO terminating
2025-03-26 02:26:31,298 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1206, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_
2025-03-26 02:26:31,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,303 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,303 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,303 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742030_1206 src: /172.20.1.14:51614 dest: /172.20.1.16:9866
2025-03-26 02:26:31,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742030_1206 src: /172.20.1.16:40702 dest: /172.20.1.15:9866
2025-03-26 02:26:31,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51614, dest: /172.20.1.16:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742030_1206, duration(ns): 899365
2025-03-26 02:26:31,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40702, dest: /172.20.1.15:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742030_1206, duration(ns): 849689
2025-03-26 02:26:31,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742030_1206, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,308 INFO terminating
2025-03-26 02:26:31,309 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,312 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,312 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,312 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1207, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/gbt.R._COPYING_
2025-03-26 02:26:31,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742031_1207 src: /172.20.1.14:51624 dest: /172.20.1.16:9866
2025-03-26 02:26:31,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742031_1207 src: /172.20.1.16:40716 dest: /172.20.1.15:9866
2025-03-26 02:26:31,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51624, dest: /172.20.1.16:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742031_1207, duration(ns): 854291
2025-03-26 02:26:31,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40716, dest: /172.20.1.15:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742031_1207, duration(ns): 689628
2025-03-26 02:26:31,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742031_1207, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,317 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gbt.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,317 INFO terminating
2025-03-26 02:26:31,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1208, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_
2025-03-26 02:26:31,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,321 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742032_1208 src: /172.20.1.14:47454 dest: /172.20.1.15:9866
2025-03-26 02:26:31,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742032_1208 src: /172.20.1.15:59178 dest: /172.20.1.16:9866
2025-03-26 02:26:31,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47454, dest: /172.20.1.15:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742032_1208, duration(ns): 1504437
2025-03-26 02:26:31,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59178, dest: /172.20.1.16:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742032_1208, duration(ns): 778777
2025-03-26 02:26:31,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742032_1208, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,325 INFO terminating
2025-03-26 02:26:31,326 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,329 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,329 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1209, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/kmeans.R._COPYING_
2025-03-26 02:26:31,330 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742033_1209 src: /172.20.1.14:51636 dest: /172.20.1.16:9866
2025-03-26 02:26:31,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742033_1209 src: /172.20.1.16:40732 dest: /172.20.1.15:9866
2025-03-26 02:26:31,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40732, dest: /172.20.1.15:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742033_1209, duration(ns): 680626
2025-03-26 02:26:31,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742033_1209, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51636, dest: /172.20.1.16:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742033_1209, duration(ns): 941107
2025-03-26 02:26:31,334 INFO terminating
2025-03-26 02:26:31,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1210, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/kstest.R._COPYING_
2025-03-26 02:26:31,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,337 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,337 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,337 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742034_1210 src: /172.20.1.14:47458 dest: /172.20.1.15:9866
2025-03-26 02:26:31,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742034_1210 src: /172.20.1.15:59186 dest: /172.20.1.16:9866
2025-03-26 02:26:31,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47458, dest: /172.20.1.15:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742034_1210, duration(ns): 1947217
2025-03-26 02:26:31,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59186, dest: /172.20.1.16:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742034_1210, duration(ns): 619536
2025-03-26 02:26:31,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742034_1210, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,342 INFO terminating
2025-03-26 02:26:31,343 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kstest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1211, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/logit.R._COPYING_
2025-03-26 02:26:31,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,346 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,346 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,346 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742035_1211 src: /172.20.1.14:51652 dest: /172.20.1.16:9866
2025-03-26 02:26:31,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742035_1211 src: /172.20.1.16:40742 dest: /172.20.1.15:9866
2025-03-26 02:26:31,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51652, dest: /172.20.1.16:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742035_1211, duration(ns): 1044341
2025-03-26 02:26:31,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40742, dest: /172.20.1.15:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742035_1211, duration(ns): 696716
2025-03-26 02:26:31,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742035_1211, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,351 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/logit.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,351 INFO terminating
2025-03-26 02:26:31,356 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1212, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/dataframe.R._COPYING_
2025-03-26 02:26:31,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,356 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,356 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,356 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742036_1212 src: /172.20.1.14:51658 dest: /172.20.1.16:9866
2025-03-26 02:26:31,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742036_1212 src: /172.20.1.16:40758 dest: /172.20.1.15:9866
2025-03-26 02:26:31,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51658, dest: /172.20.1.16:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742036_1212, duration(ns): 3303022
2025-03-26 02:26:31,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40758, dest: /172.20.1.15:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742036_1212, duration(ns): 688784
2025-03-26 02:26:31,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742036_1212, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,363 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/dataframe.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,363 INFO terminating
2025-03-26 02:26:31,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1213, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_
2025-03-26 02:26:31,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,368 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,368 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,368 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742037_1213 src: /172.20.1.14:51672 dest: /172.20.1.16:9866
2025-03-26 02:26:31,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742037_1213 src: /172.20.1.16:40766 dest: /172.20.1.15:9866
2025-03-26 02:26:31,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51672, dest: /172.20.1.16:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742037_1213, duration(ns): 1004370
2025-03-26 02:26:31,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40766, dest: /172.20.1.15:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742037_1213, duration(ns): 760874
2025-03-26 02:26:31,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742037_1213, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,372 INFO terminating
2025-03-26 02:26:31,373 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1214, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/kv1.txt._COPYING_
2025-03-26 02:26:31,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,378 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,378 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,378 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742038_1214 src: /172.20.1.14:47468 dest: /172.20.1.15:9866
2025-03-26 02:26:31,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742038_1214 src: /172.20.1.15:59202 dest: /172.20.1.16:9866
2025-03-26 02:26:31,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47468, dest: /172.20.1.15:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742038_1214, duration(ns): 1161613
2025-03-26 02:26:31,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59202, dest: /172.20.1.16:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742038_1214, duration(ns): 749812
2025-03-26 02:26:31,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742038_1214, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,382 INFO terminating
2025-03-26 02:26:31,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/kv1.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1215, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_
2025-03-26 02:26:31,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,389 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,389 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,389 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742039_1215 src: /172.20.1.14:47472 dest: /172.20.1.15:9866
2025-03-26 02:26:31,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742039_1215 src: /172.20.1.15:59214 dest: /172.20.1.16:9866
2025-03-26 02:26:31,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47472, dest: /172.20.1.15:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742039_1215, duration(ns): 937590
2025-03-26 02:26:31,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59214, dest: /172.20.1.16:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742039_1215, duration(ns): 531402
2025-03-26 02:26:31,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742039_1215, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,393 INFO terminating
2025-03-26 02:26:31,397 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1216, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/dir1/file3.json._COPYING_
2025-03-26 02:26:31,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,401 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,401 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,401 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742040_1216 src: /172.20.1.14:51688 dest: /172.20.1.16:9866
2025-03-26 02:26:31,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742040_1216 src: /172.20.1.16:40782 dest: /172.20.1.15:9866
2025-03-26 02:26:31,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51688, dest: /172.20.1.16:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742040_1216, duration(ns): 775195
2025-03-26 02:26:31,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40782, dest: /172.20.1.15:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742040_1216, duration(ns): 585943
2025-03-26 02:26:31,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742040_1216, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,405 INFO terminating
2025-03-26 02:26:31,406 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file3.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1217, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_
2025-03-26 02:26:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,411 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,411 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,411 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742041_1217 src: /172.20.1.14:47476 dest: /172.20.1.15:9866
2025-03-26 02:26:31,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742041_1217 src: /172.20.1.15:59216 dest: /172.20.1.16:9866
2025-03-26 02:26:31,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47476, dest: /172.20.1.15:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742041_1217, duration(ns): 3326545
2025-03-26 02:26:31,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59216, dest: /172.20.1.16:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742041_1217, duration(ns): 2881282
2025-03-26 02:26:31,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742041_1217, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,417 INFO terminating
2025-03-26 02:26:31,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1218, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/user.avsc._COPYING_
2025-03-26 02:26:31,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,422 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742042_1218 src: /172.20.1.14:51700 dest: /172.20.1.16:9866
2025-03-26 02:26:31,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742042_1218 src: /172.20.1.16:40796 dest: /172.20.1.15:9866
2025-03-26 02:26:31,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51700, dest: /172.20.1.16:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742042_1218, duration(ns): 791493
2025-03-26 02:26:31,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40796, dest: /172.20.1.15:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742042_1218, duration(ns): 613166
2025-03-26 02:26:31,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742042_1218, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,426 INFO terminating
2025-03-26 02:26:31,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1219, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/people.csv._COPYING_
2025-03-26 02:26:31,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,431 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,431 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,431 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742043_1219 src: /172.20.1.14:47492 dest: /172.20.1.15:9866
2025-03-26 02:26:31,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742043_1219 src: /172.20.1.15:59224 dest: /172.20.1.16:9866
2025-03-26 02:26:31,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59224, dest: /172.20.1.16:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742043_1219, duration(ns): 483348
2025-03-26 02:26:31,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742043_1219, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47492, dest: /172.20.1.15:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742043_1219, duration(ns): 1139655
2025-03-26 02:26:31,435 INFO terminating
2025-03-26 02:26:31,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,441 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,441 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,441 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1220, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/full_user.avsc._COPYING_
2025-03-26 02:26:31,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742044_1220 src: /172.20.1.14:47496 dest: /172.20.1.15:9866
2025-03-26 02:26:31,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742044_1220 src: /172.20.1.15:59228 dest: /172.20.1.16:9866
2025-03-26 02:26:31,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47496, dest: /172.20.1.15:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742044_1220, duration(ns): 1087182
2025-03-26 02:26:31,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59228, dest: /172.20.1.16:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742044_1220, duration(ns): 650478
2025-03-26 02:26:31,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742044_1220, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,446 INFO terminating
2025-03-26 02:26:31,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/full_user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1221, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/users.avro._COPYING_
2025-03-26 02:26:31,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,451 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742045_1221 src: /172.20.1.14:51712 dest: /172.20.1.16:9866
2025-03-26 02:26:31,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742045_1221 src: /172.20.1.16:40808 dest: /172.20.1.15:9866
2025-03-26 02:26:31,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51712, dest: /172.20.1.16:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742045_1221, duration(ns): 1846830
2025-03-26 02:26:31,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40808, dest: /172.20.1.15:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742045_1221, duration(ns): 506580
2025-03-26 02:26:31,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742045_1221, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,456 INFO terminating
2025-03-26 02:26:31,457 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.avro._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,462 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,462 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,462 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1222, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_
2025-03-26 02:26:31,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742046_1222 src: /172.20.1.14:47500 dest: /172.20.1.15:9866
2025-03-26 02:26:31,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742046_1222 src: /172.20.1.15:59244 dest: /172.20.1.16:9866
2025-03-26 02:26:31,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59244, dest: /172.20.1.16:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742046_1222, duration(ns): 463534
2025-03-26 02:26:31,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742046_1222, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47500, dest: /172.20.1.15:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742046_1222, duration(ns): 1275322
2025-03-26 02:26:31,467 INFO terminating
2025-03-26 02:26:31,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1223, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_
2025-03-26 02:26:31,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,472 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,472 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,472 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742047_1223 src: /172.20.1.14:51714 dest: /172.20.1.16:9866
2025-03-26 02:26:31,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742047_1223 src: /172.20.1.16:40810 dest: /172.20.1.15:9866
2025-03-26 02:26:31,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40810, dest: /172.20.1.15:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742047_1223, duration(ns): 688231
2025-03-26 02:26:31,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742047_1223, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51714, dest: /172.20.1.16:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742047_1223, duration(ns): 552182
2025-03-26 02:26:31,476 INFO terminating
2025-03-26 02:26:31,477 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1224, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/users.parquet._COPYING_
2025-03-26 02:26:31,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,480 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742048_1224 src: /172.20.1.14:51720 dest: /172.20.1.16:9866
2025-03-26 02:26:31,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742048_1224 src: /172.20.1.16:40822 dest: /172.20.1.15:9866
2025-03-26 02:26:31,484 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51720, dest: /172.20.1.16:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742048_1224, duration(ns): 1066779
2025-03-26 02:26:31,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40822, dest: /172.20.1.15:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742048_1224, duration(ns): 571069
2025-03-26 02:26:31,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742048_1224, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,484 INFO terminating
2025-03-26 02:26:31,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1225, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/users.orc._COPYING_
2025-03-26 02:26:31,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,488 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,488 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,488 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742049_1225 src: /172.20.1.14:51734 dest: /172.20.1.16:9866
2025-03-26 02:26:31,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742049_1225 src: /172.20.1.16:40836 dest: /172.20.1.15:9866
2025-03-26 02:26:31,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51734, dest: /172.20.1.16:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742049_1225, duration(ns): 907853
2025-03-26 02:26:31,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40836, dest: /172.20.1.15:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742049_1225, duration(ns): 672294
2025-03-26 02:26:31,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742049_1225, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,492 INFO terminating
2025-03-26 02:26:31,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.orc._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,496 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1226, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/people.txt._COPYING_
2025-03-26 02:26:31,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,496 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742050_1226 src: /172.20.1.14:51742 dest: /172.20.1.16:9866
2025-03-26 02:26:31,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742050_1226 src: /172.20.1.16:40846 dest: /172.20.1.15:9866
2025-03-26 02:26:31,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51742, dest: /172.20.1.16:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742050_1226, duration(ns): 784163
2025-03-26 02:26:31,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40846, dest: /172.20.1.15:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742050_1226, duration(ns): 573040
2025-03-26 02:26:31,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742050_1226, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,500 INFO terminating
2025-03-26 02:26:31,501 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1227, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/people.json._COPYING_
2025-03-26 02:26:31,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,504 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,504 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,504 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742051_1227 src: /172.20.1.14:51758 dest: /172.20.1.16:9866
2025-03-26 02:26:31,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742051_1227 src: /172.20.1.16:40860 dest: /172.20.1.15:9866
2025-03-26 02:26:31,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40860, dest: /172.20.1.15:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742051_1227, duration(ns): 533568
2025-03-26 02:26:31,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742051_1227, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51758, dest: /172.20.1.16:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742051_1227, duration(ns): 557181
2025-03-26 02:26:31,508 INFO terminating
2025-03-26 02:26:31,509 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1228, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/employees.json._COPYING_
2025-03-26 02:26:31,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,517 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742052_1228 src: /172.20.1.14:47506 dest: /172.20.1.15:9866
2025-03-26 02:26:31,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742052_1228 src: /172.20.1.15:59254 dest: /172.20.1.16:9866
2025-03-26 02:26:31,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47506, dest: /172.20.1.15:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742052_1228, duration(ns): 1081709
2025-03-26 02:26:31,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59254, dest: /172.20.1.16:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742052_1228, duration(ns): 520595
2025-03-26 02:26:31,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742052_1228, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,521 INFO terminating
2025-03-26 02:26:31,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/employees.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1229, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_
2025-03-26 02:26:31,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,538 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,538 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,538 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742053_1229 src: /172.20.1.14:47510 dest: /172.20.1.15:9866
2025-03-26 02:26:31,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742053_1229 src: /172.20.1.15:59270 dest: /172.20.1.16:9866
2025-03-26 02:26:31,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47510, dest: /172.20.1.15:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742053_1229, duration(ns): 1144914
2025-03-26 02:26:31,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59270, dest: /172.20.1.16:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742053_1229, duration(ns): 722018
2025-03-26 02:26:31,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742053_1229, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,542 INFO terminating
2025-03-26 02:26:31,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1230, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_
2025-03-26 02:26:31,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,549 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742054_1230 src: /172.20.1.14:47520 dest: /172.20.1.15:9866
2025-03-26 02:26:31,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742054_1230 src: /172.20.1.15:59274 dest: /172.20.1.16:9866
2025-03-26 02:26:31,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47520, dest: /172.20.1.15:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742054_1230, duration(ns): 1760323
2025-03-26 02:26:31,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59274, dest: /172.20.1.16:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742054_1230, duration(ns): 1154943
2025-03-26 02:26:31,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742054_1230, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,553 INFO terminating
2025-03-26 02:26:31,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1231, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_
2025-03-26 02:26:31,557 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,557 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,557 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,557 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,557 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,557 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742055_1231 src: /172.20.1.14:47532 dest: /172.20.1.15:9866
2025-03-26 02:26:31,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742055_1231 src: /172.20.1.15:59284 dest: /172.20.1.16:9866
2025-03-26 02:26:31,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59284, dest: /172.20.1.16:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742055_1231, duration(ns): 557058
2025-03-26 02:26:31,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47532, dest: /172.20.1.15:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742055_1231, duration(ns): 1205197
2025-03-26 02:26:31,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742055_1231, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,561 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742055_1231 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_
2025-03-26 02:26:31,561 INFO terminating
2025-03-26 02:26:31,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:31,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:31,973 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:31,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:31,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:31,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1232, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_
2025-03-26 02:26:31,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742056_1232 src: /172.20.1.14:47544 dest: /172.20.1.15:9866
2025-03-26 02:26:31,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742056_1232 src: /172.20.1.15:59296 dest: /172.20.1.16:9866
2025-03-26 02:26:31,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59296, dest: /172.20.1.16:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742056_1232, duration(ns): 4486631
2025-03-26 02:26:31,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742056_1232, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:31,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47544, dest: /172.20.1.15:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742056_1232, duration(ns): 6161008
2025-03-26 02:26:31,989 INFO terminating
2025-03-26 02:26:31,991 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,001 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,001 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,001 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,002 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1233, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_
2025-03-26 02:26:32,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742057_1233 src: /172.20.1.14:47552 dest: /172.20.1.15:9866
2025-03-26 02:26:32,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742057_1233 src: /172.20.1.15:59304 dest: /172.20.1.16:9866
2025-03-26 02:26:32,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47552, dest: /172.20.1.15:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742057_1233, duration(ns): 1942213
2025-03-26 02:26:32,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59304, dest: /172.20.1.16:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742057_1233, duration(ns): 920515
2025-03-26 02:26:32,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742057_1233, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,011 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,011 INFO terminating
2025-03-26 02:26:32,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1234, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_
2025-03-26 02:26:32,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,016 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,016 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,016 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742058_1234 src: /172.20.1.14:51770 dest: /172.20.1.16:9866
2025-03-26 02:26:32,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742058_1234 src: /172.20.1.16:40864 dest: /172.20.1.15:9866
2025-03-26 02:26:32,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40864, dest: /172.20.1.15:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742058_1234, duration(ns): 678444
2025-03-26 02:26:32,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742058_1234, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51770, dest: /172.20.1.16:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742058_1234, duration(ns): 859494
2025-03-26 02:26:32,021 INFO terminating
2025-03-26 02:26:32,024 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1235, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_
2025-03-26 02:26:32,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,024 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,024 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,024 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742059_1235 src: /172.20.1.14:47564 dest: /172.20.1.15:9866
2025-03-26 02:26:32,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742059_1235 src: /172.20.1.15:59320 dest: /172.20.1.16:9866
2025-03-26 02:26:32,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47564, dest: /172.20.1.15:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742059_1235, duration(ns): 878477
2025-03-26 02:26:32,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59320, dest: /172.20.1.16:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742059_1235, duration(ns): 447235
2025-03-26 02:26:32,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742059_1235, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,028 INFO terminating
2025-03-26 02:26:32,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1236, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_
2025-03-26 02:26:32,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,038 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742060_1236 src: /172.20.1.14:47578 dest: /172.20.1.15:9866
2025-03-26 02:26:32,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742060_1236 src: /172.20.1.15:59332 dest: /172.20.1.16:9866
2025-03-26 02:26:32,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47578, dest: /172.20.1.15:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742060_1236, duration(ns): 964862
2025-03-26 02:26:32,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59332, dest: /172.20.1.16:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742060_1236, duration(ns): 476370
2025-03-26 02:26:32,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742060_1236, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,042 INFO terminating
2025-03-26 02:26:32,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1237, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_
2025-03-26 02:26:32,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,051 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,051 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,051 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742061_1237 src: /172.20.1.14:51774 dest: /172.20.1.16:9866
2025-03-26 02:26:32,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742061_1237 src: /172.20.1.16:40872 dest: /172.20.1.15:9866
2025-03-26 02:26:32,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40872, dest: /172.20.1.15:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742061_1237, duration(ns): 675211
2025-03-26 02:26:32,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742061_1237, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51774, dest: /172.20.1.16:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742061_1237, duration(ns): 698471
2025-03-26 02:26:32,057 INFO terminating
2025-03-26 02:26:32,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1238, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_
2025-03-26 02:26:32,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,064 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,064 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,064 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742062_1238 src: /172.20.1.14:51780 dest: /172.20.1.16:9866
2025-03-26 02:26:32,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742062_1238 src: /172.20.1.16:40874 dest: /172.20.1.15:9866
2025-03-26 02:26:32,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40874, dest: /172.20.1.15:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742062_1238, duration(ns): 763845
2025-03-26 02:26:32,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51780, dest: /172.20.1.16:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742062_1238, duration(ns): 1098154
2025-03-26 02:26:32,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742062_1238, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,068 INFO terminating
2025-03-26 02:26:32,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,072 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1239, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_
2025-03-26 02:26:32,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,072 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,072 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,072 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742063_1239 src: /172.20.1.14:47584 dest: /172.20.1.15:9866
2025-03-26 02:26:32,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742063_1239 src: /172.20.1.15:59334 dest: /172.20.1.16:9866
2025-03-26 02:26:32,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59334, dest: /172.20.1.16:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742063_1239, duration(ns): 2066202
2025-03-26 02:26:32,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742063_1239, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47584, dest: /172.20.1.15:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742063_1239, duration(ns): 2506660
2025-03-26 02:26:32,078 INFO terminating
2025-03-26 02:26:32,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1240, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_
2025-03-26 02:26:32,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,081 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,081 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,081 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742064_1240 src: /172.20.1.14:47596 dest: /172.20.1.15:9866
2025-03-26 02:26:32,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742064_1240 src: /172.20.1.15:59344 dest: /172.20.1.16:9866
2025-03-26 02:26:32,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47596, dest: /172.20.1.15:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742064_1240, duration(ns): 1045336
2025-03-26 02:26:32,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59344, dest: /172.20.1.16:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742064_1240, duration(ns): 500101
2025-03-26 02:26:32,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742064_1240, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,085 INFO terminating
2025-03-26 02:26:32,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1241, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_
2025-03-26 02:26:32,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,089 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,089 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,089 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742065_1241 src: /172.20.1.14:47612 dest: /172.20.1.15:9866
2025-03-26 02:26:32,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742065_1241 src: /172.20.1.15:59352 dest: /172.20.1.16:9866
2025-03-26 02:26:32,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47612, dest: /172.20.1.15:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742065_1241, duration(ns): 922259
2025-03-26 02:26:32,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59352, dest: /172.20.1.16:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742065_1241, duration(ns): 529677
2025-03-26 02:26:32,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742065_1241, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,093 INFO terminating
2025-03-26 02:26:32,094 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1242, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_
2025-03-26 02:26:32,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,097 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,097 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,097 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742066_1242 src: /172.20.1.14:47628 dest: /172.20.1.15:9866
2025-03-26 02:26:32,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742066_1242 src: /172.20.1.15:59356 dest: /172.20.1.16:9866
2025-03-26 02:26:32,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59356, dest: /172.20.1.16:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742066_1242, duration(ns): 551389
2025-03-26 02:26:32,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742066_1242, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47628, dest: /172.20.1.15:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742066_1242, duration(ns): 1352854
2025-03-26 02:26:32,102 INFO terminating
2025-03-26 02:26:32,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1243, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_
2025-03-26 02:26:32,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,112 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,112 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,112 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742067_1243 src: /172.20.1.14:47636 dest: /172.20.1.15:9866
2025-03-26 02:26:32,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742067_1243 src: /172.20.1.15:59364 dest: /172.20.1.16:9866
2025-03-26 02:26:32,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59364, dest: /172.20.1.16:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742067_1243, duration(ns): 3557346
2025-03-26 02:26:32,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742067_1243, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,120 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47636, dest: /172.20.1.15:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742067_1243, duration(ns): 4244109
2025-03-26 02:26:32,120 INFO terminating
2025-03-26 02:26:32,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1244, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_
2025-03-26 02:26:32,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,124 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,124 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,124 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742068_1244 src: /172.20.1.14:47650 dest: /172.20.1.15:9866
2025-03-26 02:26:32,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742068_1244 src: /172.20.1.15:59378 dest: /172.20.1.16:9866
2025-03-26 02:26:32,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47650, dest: /172.20.1.15:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742068_1244, duration(ns): 3829349
2025-03-26 02:26:32,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59378, dest: /172.20.1.16:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742068_1244, duration(ns): 3447145
2025-03-26 02:26:32,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742068_1244, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,131 INFO terminating
2025-03-26 02:26:32,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1245, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_
2025-03-26 02:26:32,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,136 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742069_1245 src: /172.20.1.14:51796 dest: /172.20.1.16:9866
2025-03-26 02:26:32,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742069_1245 src: /172.20.1.16:40886 dest: /172.20.1.15:9866
2025-03-26 02:26:32,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51796, dest: /172.20.1.16:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742069_1245, duration(ns): 756688
2025-03-26 02:26:32,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40886, dest: /172.20.1.15:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742069_1245, duration(ns): 589858
2025-03-26 02:26:32,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742069_1245, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,140 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,140 INFO terminating
2025-03-26 02:26:32,144 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1246, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_
2025-03-26 02:26:32,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,144 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,144 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,144 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742070_1246 src: /172.20.1.14:51812 dest: /172.20.1.16:9866
2025-03-26 02:26:32,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742070_1246 src: /172.20.1.16:40902 dest: /172.20.1.15:9866
2025-03-26 02:26:32,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51812, dest: /172.20.1.16:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742070_1246, duration(ns): 6042344
2025-03-26 02:26:32,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40902, dest: /172.20.1.15:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742070_1246, duration(ns): 3771493
2025-03-26 02:26:32,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742070_1246, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,153 INFO terminating
2025-03-26 02:26:32,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1247, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_
2025-03-26 02:26:32,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,159 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,159 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,159 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742071_1247 src: /172.20.1.14:47652 dest: /172.20.1.15:9866
2025-03-26 02:26:32,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742071_1247 src: /172.20.1.15:59394 dest: /172.20.1.16:9866
2025-03-26 02:26:32,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59394, dest: /172.20.1.16:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742071_1247, duration(ns): 590743
2025-03-26 02:26:32,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47652, dest: /172.20.1.15:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742071_1247, duration(ns): 980305
2025-03-26 02:26:32,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742071_1247, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,163 INFO terminating
2025-03-26 02:26:32,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1248, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_
2025-03-26 02:26:32,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,168 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,168 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,168 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742072_1248 src: /172.20.1.14:51820 dest: /172.20.1.16:9866
2025-03-26 02:26:32,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742072_1248 src: /172.20.1.16:40914 dest: /172.20.1.15:9866
2025-03-26 02:26:32,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40914, dest: /172.20.1.15:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742072_1248, duration(ns): 23702745
2025-03-26 02:26:32,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742072_1248, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51820, dest: /172.20.1.16:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742072_1248, duration(ns): 24809935
2025-03-26 02:26:32,196 INFO terminating
2025-03-26 02:26:32,197 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1249, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_
2025-03-26 02:26:32,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,201 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,201 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,201 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742073_1249 src: /172.20.1.14:47656 dest: /172.20.1.15:9866
2025-03-26 02:26:32,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742073_1249 src: /172.20.1.15:59410 dest: /172.20.1.16:9866
2025-03-26 02:26:32,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47656, dest: /172.20.1.15:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742073_1249, duration(ns): 1304086
2025-03-26 02:26:32,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59410, dest: /172.20.1.16:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742073_1249, duration(ns): 940138
2025-03-26 02:26:32,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742073_1249, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,219 INFO terminating
2025-03-26 02:26:32,220 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1250, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_
2025-03-26 02:26:32,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,223 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,223 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,223 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742074_1250 src: /172.20.1.14:47666 dest: /172.20.1.15:9866
2025-03-26 02:26:32,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742074_1250 src: /172.20.1.15:59426 dest: /172.20.1.16:9866
2025-03-26 02:26:32,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47666, dest: /172.20.1.15:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742074_1250, duration(ns): 1195071
2025-03-26 02:26:32,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59426, dest: /172.20.1.16:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742074_1250, duration(ns): 735145
2025-03-26 02:26:32,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742074_1250, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,227 INFO terminating
2025-03-26 02:26:32,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1251, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_
2025-03-26 02:26:32,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,234 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,234 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,234 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742075_1251 src: /172.20.1.14:47680 dest: /172.20.1.15:9866
2025-03-26 02:26:32,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742075_1251 src: /172.20.1.15:59432 dest: /172.20.1.16:9866
2025-03-26 02:26:32,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47680, dest: /172.20.1.15:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742075_1251, duration(ns): 1299509
2025-03-26 02:26:32,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59432, dest: /172.20.1.16:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742075_1251, duration(ns): 833900
2025-03-26 02:26:32,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742075_1251, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,238 INFO terminating
2025-03-26 02:26:32,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,245 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,245 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,245 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,246 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1252, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_
2025-03-26 02:26:32,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742076_1252 src: /172.20.1.14:51836 dest: /172.20.1.16:9866
2025-03-26 02:26:32,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742076_1252 src: /172.20.1.16:40924 dest: /172.20.1.15:9866
2025-03-26 02:26:32,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51836, dest: /172.20.1.16:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742076_1252, duration(ns): 1065564
2025-03-26 02:26:32,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40924, dest: /172.20.1.15:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742076_1252, duration(ns): 1087842
2025-03-26 02:26:32,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742076_1252, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,250 INFO terminating
2025-03-26 02:26:32,251 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1253, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_
2025-03-26 02:26:32,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,256 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,256 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,256 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742077_1253 src: /172.20.1.14:51840 dest: /172.20.1.16:9866
2025-03-26 02:26:32,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742077_1253 src: /172.20.1.16:40938 dest: /172.20.1.15:9866
2025-03-26 02:26:32,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40938, dest: /172.20.1.15:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742077_1253, duration(ns): 1154877
2025-03-26 02:26:32,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742077_1253, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51840, dest: /172.20.1.16:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742077_1253, duration(ns): 1261456
2025-03-26 02:26:32,264 INFO terminating
2025-03-26 02:26:32,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1254, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_
2025-03-26 02:26:32,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,273 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,273 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,273 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742078_1254 src: /172.20.1.14:51852 dest: /172.20.1.16:9866
2025-03-26 02:26:32,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742078_1254 src: /172.20.1.16:40952 dest: /172.20.1.15:9866
2025-03-26 02:26:32,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40952, dest: /172.20.1.15:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742078_1254, duration(ns): 1183082
2025-03-26 02:26:32,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742078_1254, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51852, dest: /172.20.1.16:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742078_1254, duration(ns): 1593617
2025-03-26 02:26:32,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,285 INFO terminating
2025-03-26 02:26:32,289 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1255, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_
2025-03-26 02:26:32,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,289 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,289 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,289 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742079_1255 src: /172.20.1.14:51864 dest: /172.20.1.16:9866
2025-03-26 02:26:32,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742079_1255 src: /172.20.1.16:40962 dest: /172.20.1.15:9866
2025-03-26 02:26:32,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40962, dest: /172.20.1.15:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742079_1255, duration(ns): 620154
2025-03-26 02:26:32,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742079_1255, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,293 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51864, dest: /172.20.1.16:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742079_1255, duration(ns): 724156
2025-03-26 02:26:32,293 INFO terminating
2025-03-26 02:26:32,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1256, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_
2025-03-26 02:26:32,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,298 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,298 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,298 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742080_1256 src: /172.20.1.14:51878 dest: /172.20.1.16:9866
2025-03-26 02:26:32,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742080_1256 src: /172.20.1.16:40968 dest: /172.20.1.15:9866
2025-03-26 02:26:32,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51878, dest: /172.20.1.16:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742080_1256, duration(ns): 1289597
2025-03-26 02:26:32,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40968, dest: /172.20.1.15:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742080_1256, duration(ns): 559887
2025-03-26 02:26:32,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742080_1256, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,302 INFO terminating
2025-03-26 02:26:32,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1257, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:26:32,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,307 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,307 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,307 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742081_1257 src: /172.20.1.14:47694 dest: /172.20.1.15:9866
2025-03-26 02:26:32,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742081_1257 src: /172.20.1.15:59436 dest: /172.20.1.16:9866
2025-03-26 02:26:32,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47694, dest: /172.20.1.15:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742081_1257, duration(ns): 835191
2025-03-26 02:26:32,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59436, dest: /172.20.1.16:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742081_1257, duration(ns): 480890
2025-03-26 02:26:32,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742081_1257, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,310 INFO terminating
2025-03-26 02:26:32,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,314 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1258, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:26:32,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,314 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,314 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,314 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742082_1258 src: /172.20.1.14:47696 dest: /172.20.1.15:9866
2025-03-26 02:26:32,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742082_1258 src: /172.20.1.15:59452 dest: /172.20.1.16:9866
2025-03-26 02:26:32,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47696, dest: /172.20.1.15:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742082_1258, duration(ns): 963149
2025-03-26 02:26:32,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59452, dest: /172.20.1.16:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742082_1258, duration(ns): 578301
2025-03-26 02:26:32,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742082_1258, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,317 INFO terminating
2025-03-26 02:26:32,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742082_1258 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:26:32,723 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1259, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_
2025-03-26 02:26:32,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,729 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,729 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,729 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742083_1259 src: /172.20.1.14:51882 dest: /172.20.1.16:9866
2025-03-26 02:26:32,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742083_1259 src: /172.20.1.16:40984 dest: /172.20.1.15:9866
2025-03-26 02:26:32,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40984, dest: /172.20.1.15:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742083_1259, duration(ns): 1042959
2025-03-26 02:26:32,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742083_1259, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51882, dest: /172.20.1.16:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742083_1259, duration(ns): 1242399
2025-03-26 02:26:32,734 INFO terminating
2025-03-26 02:26:32,735 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,739 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1260, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_
2025-03-26 02:26:32,740 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,740 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742084_1260 src: /172.20.1.14:47700 dest: /172.20.1.15:9866
2025-03-26 02:26:32,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742084_1260 src: /172.20.1.15:59458 dest: /172.20.1.16:9866
2025-03-26 02:26:32,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59458, dest: /172.20.1.16:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742084_1260, duration(ns): 767364
2025-03-26 02:26:32,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742084_1260, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47700, dest: /172.20.1.15:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742084_1260, duration(ns): 1495233
2025-03-26 02:26:32,745 INFO terminating
2025-03-26 02:26:32,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1261, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_
2025-03-26 02:26:32,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,750 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,750 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,750 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742085_1261 src: /172.20.1.14:47714 dest: /172.20.1.15:9866
2025-03-26 02:26:32,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742085_1261 src: /172.20.1.15:59470 dest: /172.20.1.16:9866
2025-03-26 02:26:32,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59470, dest: /172.20.1.16:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742085_1261, duration(ns): 689250
2025-03-26 02:26:32,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47714, dest: /172.20.1.15:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742085_1261, duration(ns): 1432122
2025-03-26 02:26:32,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742085_1261, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,755 INFO terminating
2025-03-26 02:26:32,760 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1262, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_
2025-03-26 02:26:32,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,760 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,760 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,760 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742086_1262 src: /172.20.1.14:51892 dest: /172.20.1.16:9866
2025-03-26 02:26:32,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742086_1262 src: /172.20.1.16:40992 dest: /172.20.1.15:9866
2025-03-26 02:26:32,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:40992, dest: /172.20.1.15:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742086_1262, duration(ns): 844124
2025-03-26 02:26:32,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742086_1262, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51892, dest: /172.20.1.16:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742086_1262, duration(ns): 907636
2025-03-26 02:26:32,765 INFO terminating
2025-03-26 02:26:32,768 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1263, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_
2025-03-26 02:26:32,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,774 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,774 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,774 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742087_1263 src: /172.20.1.14:51908 dest: /172.20.1.16:9866
2025-03-26 02:26:32,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742087_1263 src: /172.20.1.16:41000 dest: /172.20.1.15:9866
2025-03-26 02:26:32,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51908, dest: /172.20.1.16:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742087_1263, duration(ns): 1566197
2025-03-26 02:26:32,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41000, dest: /172.20.1.15:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742087_1263, duration(ns): 1502877
2025-03-26 02:26:32,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742087_1263, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,780 INFO terminating
2025-03-26 02:26:32,783 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1264, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_
2025-03-26 02:26:32,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,783 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,783 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,783 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742088_1264 src: /172.20.1.14:51910 dest: /172.20.1.16:9866
2025-03-26 02:26:32,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742088_1264 src: /172.20.1.16:41014 dest: /172.20.1.15:9866
2025-03-26 02:26:32,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41014, dest: /172.20.1.15:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742088_1264, duration(ns): 654036
2025-03-26 02:26:32,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742088_1264, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51910, dest: /172.20.1.16:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742088_1264, duration(ns): 780083
2025-03-26 02:26:32,792 INFO terminating
2025-03-26 02:26:32,793 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,796 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1265, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_
2025-03-26 02:26:32,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,796 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,796 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,796 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742089_1265 src: /172.20.1.14:51918 dest: /172.20.1.16:9866
2025-03-26 02:26:32,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742089_1265 src: /172.20.1.16:41022 dest: /172.20.1.15:9866
2025-03-26 02:26:32,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51918, dest: /172.20.1.16:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742089_1265, duration(ns): 486758
2025-03-26 02:26:32,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41022, dest: /172.20.1.15:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742089_1265, duration(ns): 528581
2025-03-26 02:26:32,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742089_1265, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,801 INFO terminating
2025-03-26 02:26:32,802 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1266, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_
2025-03-26 02:26:32,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,806 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,806 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,806 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742090_1266 src: /172.20.1.14:47724 dest: /172.20.1.15:9866
2025-03-26 02:26:32,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742090_1266 src: /172.20.1.15:59484 dest: /172.20.1.16:9866
2025-03-26 02:26:32,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47724, dest: /172.20.1.15:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742090_1266, duration(ns): 810398
2025-03-26 02:26:32,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59484, dest: /172.20.1.16:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742090_1266, duration(ns): 478931
2025-03-26 02:26:32,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742090_1266, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,809 INFO terminating
2025-03-26 02:26:32,810 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,815 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1267, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_
2025-03-26 02:26:32,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,815 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,815 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,815 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742091_1267 src: /172.20.1.14:51932 dest: /172.20.1.16:9866
2025-03-26 02:26:32,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742091_1267 src: /172.20.1.16:41026 dest: /172.20.1.15:9866
2025-03-26 02:26:32,818 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51932, dest: /172.20.1.16:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742091_1267, duration(ns): 671712
2025-03-26 02:26:32,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41026, dest: /172.20.1.15:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742091_1267, duration(ns): 566820
2025-03-26 02:26:32,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742091_1267, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,818 INFO terminating
2025-03-26 02:26:32,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1268, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_
2025-03-26 02:26:32,826 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,826 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,826 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,826 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,826 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,826 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742092_1268 src: /172.20.1.14:47734 dest: /172.20.1.15:9866
2025-03-26 02:26:32,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742092_1268 src: /172.20.1.15:59500 dest: /172.20.1.16:9866
2025-03-26 02:26:32,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59500, dest: /172.20.1.16:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742092_1268, duration(ns): 521716
2025-03-26 02:26:32,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742092_1268, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,833 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47734, dest: /172.20.1.15:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742092_1268, duration(ns): 849787
2025-03-26 02:26:32,833 INFO terminating
2025-03-26 02:26:32,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1269, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_
2025-03-26 02:26:32,855 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,855 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,855 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742093_1269 src: /172.20.1.14:47742 dest: /172.20.1.15:9866
2025-03-26 02:26:32,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742093_1269 src: /172.20.1.15:59510 dest: /172.20.1.16:9866
2025-03-26 02:26:32,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47742, dest: /172.20.1.15:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742093_1269, duration(ns): 1568192
2025-03-26 02:26:32,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59510, dest: /172.20.1.16:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742093_1269, duration(ns): 1179569
2025-03-26 02:26:32,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742093_1269, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,859 INFO terminating
2025-03-26 02:26:32,860 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1270, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_
2025-03-26 02:26:32,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,863 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,863 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,863 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742094_1270 src: /172.20.1.14:47754 dest: /172.20.1.15:9866
2025-03-26 02:26:32,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742094_1270 src: /172.20.1.15:59518 dest: /172.20.1.16:9866
2025-03-26 02:26:32,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47754, dest: /172.20.1.15:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742094_1270, duration(ns): 1114679
2025-03-26 02:26:32,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59518, dest: /172.20.1.16:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742094_1270, duration(ns): 815231
2025-03-26 02:26:32,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742094_1270, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,867 INFO terminating
2025-03-26 02:26:32,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1271, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_
2025-03-26 02:26:32,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,871 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,871 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,871 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742095_1271 src: /172.20.1.14:51942 dest: /172.20.1.16:9866
2025-03-26 02:26:32,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742095_1271 src: /172.20.1.16:41038 dest: /172.20.1.15:9866
2025-03-26 02:26:32,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41038, dest: /172.20.1.15:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742095_1271, duration(ns): 479510
2025-03-26 02:26:32,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742095_1271, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51942, dest: /172.20.1.16:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742095_1271, duration(ns): 505829
2025-03-26 02:26:32,875 INFO terminating
2025-03-26 02:26:32,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1272, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_
2025-03-26 02:26:32,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,878 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,878 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,878 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742096_1272 src: /172.20.1.14:47766 dest: /172.20.1.15:9866
2025-03-26 02:26:32,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742096_1272 src: /172.20.1.15:59526 dest: /172.20.1.16:9866
2025-03-26 02:26:32,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59526, dest: /172.20.1.16:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742096_1272, duration(ns): 422339
2025-03-26 02:26:32,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742096_1272, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,882 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47766, dest: /172.20.1.15:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742096_1272, duration(ns): 717186
2025-03-26 02:26:32,882 INFO terminating
2025-03-26 02:26:32,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1273, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_
2025-03-26 02:26:32,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,888 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,888 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,888 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742097_1273 src: /172.20.1.14:51952 dest: /172.20.1.16:9866
2025-03-26 02:26:32,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742097_1273 src: /172.20.1.16:41042 dest: /172.20.1.15:9866
2025-03-26 02:26:32,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41042, dest: /172.20.1.15:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742097_1273, duration(ns): 827658
2025-03-26 02:26:32,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742097_1273, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,892 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51952, dest: /172.20.1.16:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742097_1273, duration(ns): 915543
2025-03-26 02:26:32,892 INFO terminating
2025-03-26 02:26:32,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1274, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_
2025-03-26 02:26:32,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,895 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,895 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,895 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742098_1274 src: /172.20.1.14:51966 dest: /172.20.1.16:9866
2025-03-26 02:26:32,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742098_1274 src: /172.20.1.16:41048 dest: /172.20.1.15:9866
2025-03-26 02:26:32,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51966, dest: /172.20.1.16:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742098_1274, duration(ns): 574310
2025-03-26 02:26:32,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41048, dest: /172.20.1.15:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742098_1274, duration(ns): 425832
2025-03-26 02:26:32,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742098_1274, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,898 INFO terminating
2025-03-26 02:26:32,899 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,902 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1275, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:26:32,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,902 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,902 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,902 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742099_1275 src: /172.20.1.14:47776 dest: /172.20.1.15:9866
2025-03-26 02:26:32,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742099_1275 src: /172.20.1.15:59538 dest: /172.20.1.16:9866
2025-03-26 02:26:32,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47776, dest: /172.20.1.15:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742099_1275, duration(ns): 739076
2025-03-26 02:26:32,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59538, dest: /172.20.1.16:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742099_1275, duration(ns): 393369
2025-03-26 02:26:32,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742099_1275, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,906 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,906 INFO terminating
2025-03-26 02:26:32,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1276, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_
2025-03-26 02:26:32,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,913 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,913 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,913 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742100_1276 src: /172.20.1.14:47784 dest: /172.20.1.15:9866
2025-03-26 02:26:32,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742100_1276 src: /172.20.1.15:59540 dest: /172.20.1.16:9866
2025-03-26 02:26:32,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47784, dest: /172.20.1.15:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742100_1276, duration(ns): 719940
2025-03-26 02:26:32,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59540, dest: /172.20.1.16:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742100_1276, duration(ns): 391303
2025-03-26 02:26:32,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742100_1276, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,916 INFO terminating
2025-03-26 02:26:32,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1277, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:26:32,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,926 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,926 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,926 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742101_1277 src: /172.20.1.14:51974 dest: /172.20.1.16:9866
2025-03-26 02:26:32,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742101_1277 src: /172.20.1.16:41056 dest: /172.20.1.15:9866
2025-03-26 02:26:32,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41056, dest: /172.20.1.15:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742101_1277, duration(ns): 521871
2025-03-26 02:26:32,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742101_1277, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51974, dest: /172.20.1.16:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742101_1277, duration(ns): 652793
2025-03-26 02:26:32,930 INFO terminating
2025-03-26 02:26:32,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1278, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_
2025-03-26 02:26:32,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,933 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,933 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,933 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742102_1278 src: /172.20.1.14:51986 dest: /172.20.1.16:9866
2025-03-26 02:26:32,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742102_1278 src: /172.20.1.16:41066 dest: /172.20.1.15:9866
2025-03-26 02:26:32,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41066, dest: /172.20.1.15:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742102_1278, duration(ns): 431918
2025-03-26 02:26:32,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742102_1278, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51986, dest: /172.20.1.16:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742102_1278, duration(ns): 569628
2025-03-26 02:26:32,938 INFO terminating
2025-03-26 02:26:32,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1279, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:26:32,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,941 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,941 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,941 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742103_1279 src: /172.20.1.14:51996 dest: /172.20.1.16:9866
2025-03-26 02:26:32,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742103_1279 src: /172.20.1.16:41070 dest: /172.20.1.15:9866
2025-03-26 02:26:32,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:51996, dest: /172.20.1.16:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742103_1279, duration(ns): 682117
2025-03-26 02:26:32,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41070, dest: /172.20.1.15:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742103_1279, duration(ns): 465147
2025-03-26 02:26:32,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742103_1279, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,945 INFO terminating
2025-03-26 02:26:32,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1280, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_
2025-03-26 02:26:32,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,949 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,949 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,949 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742104_1280 src: /172.20.1.14:52012 dest: /172.20.1.16:9866
2025-03-26 02:26:32,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742104_1280 src: /172.20.1.16:41084 dest: /172.20.1.15:9866
2025-03-26 02:26:32,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52012, dest: /172.20.1.16:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742104_1280, duration(ns): 681439
2025-03-26 02:26:32,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41084, dest: /172.20.1.15:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742104_1280, duration(ns): 534814
2025-03-26 02:26:32,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742104_1280, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,952 INFO terminating
2025-03-26 02:26:32,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1281, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_
2025-03-26 02:26:32,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,956 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,956 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,956 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742105_1281 src: /172.20.1.14:52024 dest: /172.20.1.16:9866
2025-03-26 02:26:32,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742105_1281 src: /172.20.1.16:41090 dest: /172.20.1.15:9866
2025-03-26 02:26:32,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41090, dest: /172.20.1.15:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742105_1281, duration(ns): 810416
2025-03-26 02:26:32,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742105_1281, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,960 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52024, dest: /172.20.1.16:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742105_1281, duration(ns): 953772
2025-03-26 02:26:32,960 INFO terminating
2025-03-26 02:26:32,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,963 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,963 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,963 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1282, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_
2025-03-26 02:26:32,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742106_1282 src: /172.20.1.14:47788 dest: /172.20.1.15:9866
2025-03-26 02:26:32,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742106_1282 src: /172.20.1.15:59546 dest: /172.20.1.16:9866
2025-03-26 02:26:32,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59546, dest: /172.20.1.16:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742106_1282, duration(ns): 395377
2025-03-26 02:26:32,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742106_1282, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47788, dest: /172.20.1.15:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742106_1282, duration(ns): 744376
2025-03-26 02:26:32,967 INFO terminating
2025-03-26 02:26:32,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1283, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_
2025-03-26 02:26:32,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,971 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,971 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,971 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742107_1283 src: /172.20.1.14:52040 dest: /172.20.1.16:9866
2025-03-26 02:26:32,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742107_1283 src: /172.20.1.16:41100 dest: /172.20.1.15:9866
2025-03-26 02:26:32,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41100, dest: /172.20.1.15:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742107_1283, duration(ns): 483300
2025-03-26 02:26:32,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742107_1283, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52040, dest: /172.20.1.16:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742107_1283, duration(ns): 752984
2025-03-26 02:26:32,977 INFO terminating
2025-03-26 02:26:32,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,981 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,981 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,981 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1284, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_
2025-03-26 02:26:32,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742108_1284 src: /172.20.1.14:47796 dest: /172.20.1.15:9866
2025-03-26 02:26:32,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742108_1284 src: /172.20.1.15:59554 dest: /172.20.1.16:9866
2025-03-26 02:26:32,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59554, dest: /172.20.1.16:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742108_1284, duration(ns): 430095
2025-03-26 02:26:32,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47796, dest: /172.20.1.15:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742108_1284, duration(ns): 864671
2025-03-26 02:26:32,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742108_1284, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,985 INFO terminating
2025-03-26 02:26:32,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1285, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_
2025-03-26 02:26:32,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,988 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,988 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,988 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742109_1285 src: /172.20.1.14:52052 dest: /172.20.1.16:9866
2025-03-26 02:26:32,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742109_1285 src: /172.20.1.16:41106 dest: /172.20.1.15:9866
2025-03-26 02:26:32,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41106, dest: /172.20.1.15:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742109_1285, duration(ns): 442095
2025-03-26 02:26:32,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52052, dest: /172.20.1.16:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742109_1285, duration(ns): 891794
2025-03-26 02:26:32,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742109_1285, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,992 INFO terminating
2025-03-26 02:26:32,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1286, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_
2025-03-26 02:26:32,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,995 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:32,995 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:32,995 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:32,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742110_1286 src: /172.20.1.14:47812 dest: /172.20.1.15:9866
2025-03-26 02:26:32,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742110_1286 src: /172.20.1.15:59564 dest: /172.20.1.16:9866
2025-03-26 02:26:32,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59564, dest: /172.20.1.16:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742110_1286, duration(ns): 407924
2025-03-26 02:26:32,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742110_1286, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:32,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:32,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47812, dest: /172.20.1.15:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742110_1286, duration(ns): 726657
2025-03-26 02:26:32,999 INFO terminating
2025-03-26 02:26:33,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1287, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_
2025-03-26 02:26:33,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,004 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,004 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,004 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742111_1287 src: /172.20.1.14:47820 dest: /172.20.1.15:9866
2025-03-26 02:26:33,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742111_1287 src: /172.20.1.15:59574 dest: /172.20.1.16:9866
2025-03-26 02:26:33,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59574, dest: /172.20.1.16:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742111_1287, duration(ns): 472774
2025-03-26 02:26:33,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742111_1287, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47820, dest: /172.20.1.15:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742111_1287, duration(ns): 791039
2025-03-26 02:26:33,008 INFO terminating
2025-03-26 02:26:33,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1288, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_
2025-03-26 02:26:33,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,012 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742112_1288 src: /172.20.1.14:52060 dest: /172.20.1.16:9866
2025-03-26 02:26:33,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742112_1288 src: /172.20.1.16:41118 dest: /172.20.1.15:9866
2025-03-26 02:26:33,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41118, dest: /172.20.1.15:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742112_1288, duration(ns): 459194
2025-03-26 02:26:33,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742112_1288, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,016 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52060, dest: /172.20.1.16:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742112_1288, duration(ns): 660600
2025-03-26 02:26:33,016 INFO terminating
2025-03-26 02:26:33,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,019 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,019 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1289, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:26:33,020 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742113_1289 src: /172.20.1.14:52066 dest: /172.20.1.16:9866
2025-03-26 02:26:33,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742113_1289 src: /172.20.1.16:41124 dest: /172.20.1.15:9866
2025-03-26 02:26:33,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41124, dest: /172.20.1.15:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742113_1289, duration(ns): 538231
2025-03-26 02:26:33,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742113_1289, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52066, dest: /172.20.1.16:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742113_1289, duration(ns): 683244
2025-03-26 02:26:33,023 INFO terminating
2025-03-26 02:26:33,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1290, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_
2025-03-26 02:26:33,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,026 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,026 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,026 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742114_1290 src: /172.20.1.14:52068 dest: /172.20.1.16:9866
2025-03-26 02:26:33,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742114_1290 src: /172.20.1.16:41128 dest: /172.20.1.15:9866
2025-03-26 02:26:33,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52068, dest: /172.20.1.16:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742114_1290, duration(ns): 435590
2025-03-26 02:26:33,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41128, dest: /172.20.1.15:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742114_1290, duration(ns): 500742
2025-03-26 02:26:33,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742114_1290, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,030 INFO terminating
2025-03-26 02:26:33,031 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,036 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1291, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_
2025-03-26 02:26:33,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,036 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742115_1291 src: /172.20.1.14:52080 dest: /172.20.1.16:9866
2025-03-26 02:26:33,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742115_1291 src: /172.20.1.16:41140 dest: /172.20.1.15:9866
2025-03-26 02:26:33,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52080, dest: /172.20.1.16:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742115_1291, duration(ns): 524546
2025-03-26 02:26:33,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41140, dest: /172.20.1.15:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742115_1291, duration(ns): 527669
2025-03-26 02:26:33,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742115_1291, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,040 INFO terminating
2025-03-26 02:26:33,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,044 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1292, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:26:33,045 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,045 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742116_1292 src: /172.20.1.14:47830 dest: /172.20.1.15:9866
2025-03-26 02:26:33,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742116_1292 src: /172.20.1.15:59576 dest: /172.20.1.16:9866
2025-03-26 02:26:33,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47830, dest: /172.20.1.15:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742116_1292, duration(ns): 985407
2025-03-26 02:26:33,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59576, dest: /172.20.1.16:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742116_1292, duration(ns): 475883
2025-03-26 02:26:33,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742116_1292, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,061 INFO terminating
2025-03-26 02:26:33,062 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1293, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_
2025-03-26 02:26:33,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,066 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,066 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,066 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742117_1293 src: /172.20.1.14:47832 dest: /172.20.1.15:9866
2025-03-26 02:26:33,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742117_1293 src: /172.20.1.15:59592 dest: /172.20.1.16:9866
2025-03-26 02:26:33,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47832, dest: /172.20.1.15:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742117_1293, duration(ns): 822476
2025-03-26 02:26:33,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59592, dest: /172.20.1.16:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742117_1293, duration(ns): 410824
2025-03-26 02:26:33,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742117_1293, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,070 INFO terminating
2025-03-26 02:26:33,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,073 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,073 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1294, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_
2025-03-26 02:26:33,074 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742118_1294 src: /172.20.1.14:52086 dest: /172.20.1.16:9866
2025-03-26 02:26:33,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742118_1294 src: /172.20.1.16:41150 dest: /172.20.1.15:9866
2025-03-26 02:26:33,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52086, dest: /172.20.1.16:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742118_1294, duration(ns): 623135
2025-03-26 02:26:33,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41150, dest: /172.20.1.15:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742118_1294, duration(ns): 484854
2025-03-26 02:26:33,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742118_1294, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,077 INFO terminating
2025-03-26 02:26:33,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1295, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_
2025-03-26 02:26:33,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,082 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,082 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,082 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742119_1295 src: /172.20.1.14:52088 dest: /172.20.1.16:9866
2025-03-26 02:26:33,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742119_1295 src: /172.20.1.16:41158 dest: /172.20.1.15:9866
2025-03-26 02:26:33,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52088, dest: /172.20.1.16:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742119_1295, duration(ns): 1082203
2025-03-26 02:26:33,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41158, dest: /172.20.1.15:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742119_1295, duration(ns): 528872
2025-03-26 02:26:33,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742119_1295, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,086 INFO terminating
2025-03-26 02:26:33,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1296, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_
2025-03-26 02:26:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,091 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,091 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,091 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742120_1296 src: /172.20.1.14:47838 dest: /172.20.1.15:9866
2025-03-26 02:26:33,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742120_1296 src: /172.20.1.15:59600 dest: /172.20.1.16:9866
2025-03-26 02:26:33,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59600, dest: /172.20.1.16:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742120_1296, duration(ns): 515501
2025-03-26 02:26:33,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742120_1296, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47838, dest: /172.20.1.15:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742120_1296, duration(ns): 843273
2025-03-26 02:26:33,095 INFO terminating
2025-03-26 02:26:33,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1297, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_
2025-03-26 02:26:33,098 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,098 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,098 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,098 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,098 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,098 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742121_1297 src: /172.20.1.14:47848 dest: /172.20.1.15:9866
2025-03-26 02:26:33,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742121_1297 src: /172.20.1.15:59608 dest: /172.20.1.16:9866
2025-03-26 02:26:33,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59608, dest: /172.20.1.16:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742121_1297, duration(ns): 407956
2025-03-26 02:26:33,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742121_1297, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47848, dest: /172.20.1.15:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742121_1297, duration(ns): 714089
2025-03-26 02:26:33,102 INFO terminating
2025-03-26 02:26:33,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1298, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_
2025-03-26 02:26:33,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,105 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,105 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,105 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742122_1298 src: /172.20.1.14:52104 dest: /172.20.1.16:9866
2025-03-26 02:26:33,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742122_1298 src: /172.20.1.16:41162 dest: /172.20.1.15:9866
2025-03-26 02:26:33,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52104, dest: /172.20.1.16:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742122_1298, duration(ns): 1253648
2025-03-26 02:26:33,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41162, dest: /172.20.1.15:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742122_1298, duration(ns): 1291935
2025-03-26 02:26:33,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742122_1298, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,109 INFO terminating
2025-03-26 02:26:33,110 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1299, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_
2025-03-26 02:26:33,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,117 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,117 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,117 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742123_1299 src: /172.20.1.14:52116 dest: /172.20.1.16:9866
2025-03-26 02:26:33,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742123_1299 src: /172.20.1.16:41166 dest: /172.20.1.15:9866
2025-03-26 02:26:33,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52116, dest: /172.20.1.16:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742123_1299, duration(ns): 576338
2025-03-26 02:26:33,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41166, dest: /172.20.1.15:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742123_1299, duration(ns): 475460
2025-03-26 02:26:33,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742123_1299, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,121 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,121 INFO terminating
2025-03-26 02:26:33,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,125 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1300, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_
2025-03-26 02:26:33,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,125 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,125 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,125 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742124_1300 src: /172.20.1.14:52126 dest: /172.20.1.16:9866
2025-03-26 02:26:33,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742124_1300 src: /172.20.1.16:41182 dest: /172.20.1.15:9866
2025-03-26 02:26:33,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41182, dest: /172.20.1.15:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742124_1300, duration(ns): 457804
2025-03-26 02:26:33,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742124_1300, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52126, dest: /172.20.1.16:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742124_1300, duration(ns): 625849
2025-03-26 02:26:33,129 INFO terminating
2025-03-26 02:26:33,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1301, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_
2025-03-26 02:26:33,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,136 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742125_1301 src: /172.20.1.14:47864 dest: /172.20.1.15:9866
2025-03-26 02:26:33,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742125_1301 src: /172.20.1.15:59620 dest: /172.20.1.16:9866
2025-03-26 02:26:33,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47864, dest: /172.20.1.15:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742125_1301, duration(ns): 2284422
2025-03-26 02:26:33,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59620, dest: /172.20.1.16:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742125_1301, duration(ns): 1982894
2025-03-26 02:26:33,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742125_1301, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,141 INFO terminating
2025-03-26 02:26:33,142 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1302, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_
2025-03-26 02:26:33,145 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,145 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,145 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,145 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,145 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,145 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742126_1302 src: /172.20.1.14:52128 dest: /172.20.1.16:9866
2025-03-26 02:26:33,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742126_1302 src: /172.20.1.16:41184 dest: /172.20.1.15:9866
2025-03-26 02:26:33,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52128, dest: /172.20.1.16:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742126_1302, duration(ns): 3269541
2025-03-26 02:26:33,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41184, dest: /172.20.1.15:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742126_1302, duration(ns): 440674
2025-03-26 02:26:33,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742126_1302, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,151 INFO terminating
2025-03-26 02:26:33,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1303, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_
2025-03-26 02:26:33,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,155 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,155 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,155 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742127_1303 src: /172.20.1.14:47870 dest: /172.20.1.15:9866
2025-03-26 02:26:33,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742127_1303 src: /172.20.1.15:59624 dest: /172.20.1.16:9866
2025-03-26 02:26:33,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47870, dest: /172.20.1.15:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742127_1303, duration(ns): 760694
2025-03-26 02:26:33,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59624, dest: /172.20.1.16:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742127_1303, duration(ns): 450278
2025-03-26 02:26:33,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742127_1303, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,159 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,159 INFO terminating
2025-03-26 02:26:33,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,162 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,162 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,162 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1304, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_
2025-03-26 02:26:33,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742128_1304 src: /172.20.1.14:47882 dest: /172.20.1.15:9866
2025-03-26 02:26:33,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742128_1304 src: /172.20.1.15:59628 dest: /172.20.1.16:9866
2025-03-26 02:26:33,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47882, dest: /172.20.1.15:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742128_1304, duration(ns): 1014745
2025-03-26 02:26:33,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59628, dest: /172.20.1.16:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742128_1304, duration(ns): 674319
2025-03-26 02:26:33,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742128_1304, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,166 INFO terminating
2025-03-26 02:26:33,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,169 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,169 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,169 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,170 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1305, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_
2025-03-26 02:26:33,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742129_1305 src: /172.20.1.14:47892 dest: /172.20.1.15:9866
2025-03-26 02:26:33,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742129_1305 src: /172.20.1.15:59642 dest: /172.20.1.16:9866
2025-03-26 02:26:33,173 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47892, dest: /172.20.1.15:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742129_1305, duration(ns): 743320
2025-03-26 02:26:33,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59642, dest: /172.20.1.16:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742129_1305, duration(ns): 378960
2025-03-26 02:26:33,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742129_1305, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,173 INFO terminating
2025-03-26 02:26:33,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1306, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_
2025-03-26 02:26:33,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,177 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,177 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,177 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742130_1306 src: /172.20.1.14:47900 dest: /172.20.1.15:9866
2025-03-26 02:26:33,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742130_1306 src: /172.20.1.15:59654 dest: /172.20.1.16:9866
2025-03-26 02:26:33,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59654, dest: /172.20.1.16:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742130_1306, duration(ns): 510163
2025-03-26 02:26:33,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47900, dest: /172.20.1.15:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742130_1306, duration(ns): 812604
2025-03-26 02:26:33,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742130_1306, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,185 INFO terminating
2025-03-26 02:26:33,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1307, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_
2025-03-26 02:26:33,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,189 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,189 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,189 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742131_1307 src: /172.20.1.14:47908 dest: /172.20.1.15:9866
2025-03-26 02:26:33,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742131_1307 src: /172.20.1.15:59658 dest: /172.20.1.16:9866
2025-03-26 02:26:33,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47908, dest: /172.20.1.15:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742131_1307, duration(ns): 1113325
2025-03-26 02:26:33,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59658, dest: /172.20.1.16:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742131_1307, duration(ns): 452873
2025-03-26 02:26:33,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742131_1307, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,192 INFO terminating
2025-03-26 02:26:33,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1308, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_
2025-03-26 02:26:33,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,196 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,196 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,196 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742132_1308 src: /172.20.1.14:47912 dest: /172.20.1.15:9866
2025-03-26 02:26:33,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742132_1308 src: /172.20.1.15:59672 dest: /172.20.1.16:9866
2025-03-26 02:26:33,200 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47912, dest: /172.20.1.15:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742132_1308, duration(ns): 1107756
2025-03-26 02:26:33,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59672, dest: /172.20.1.16:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742132_1308, duration(ns): 384972
2025-03-26 02:26:33,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742132_1308, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,200 INFO terminating
2025-03-26 02:26:33,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1309, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_
2025-03-26 02:26:33,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,204 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,204 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,204 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742133_1309 src: /172.20.1.14:47918 dest: /172.20.1.15:9866
2025-03-26 02:26:33,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742133_1309 src: /172.20.1.15:59674 dest: /172.20.1.16:9866
2025-03-26 02:26:33,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59674, dest: /172.20.1.16:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742133_1309, duration(ns): 421579
2025-03-26 02:26:33,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742133_1309, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47918, dest: /172.20.1.15:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742133_1309, duration(ns): 756737
2025-03-26 02:26:33,208 INFO terminating
2025-03-26 02:26:33,210 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,214 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1310, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:26:33,214 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,214 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,214 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,214 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,214 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742134_1310 src: /172.20.1.14:52140 dest: /172.20.1.16:9866
2025-03-26 02:26:33,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742134_1310 src: /172.20.1.16:41200 dest: /172.20.1.15:9866
2025-03-26 02:26:33,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52140, dest: /172.20.1.16:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742134_1310, duration(ns): 589035
2025-03-26 02:26:33,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41200, dest: /172.20.1.15:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742134_1310, duration(ns): 445055
2025-03-26 02:26:33,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742134_1310, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,217 INFO terminating
2025-03-26 02:26:33,218 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,220 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,220 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1311, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_
2025-03-26 02:26:33,221 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742135_1311 src: /172.20.1.14:47920 dest: /172.20.1.15:9866
2025-03-26 02:26:33,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742135_1311 src: /172.20.1.15:59676 dest: /172.20.1.16:9866
2025-03-26 02:26:33,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47920, dest: /172.20.1.15:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742135_1311, duration(ns): 734172
2025-03-26 02:26:33,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59676, dest: /172.20.1.16:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742135_1311, duration(ns): 430425
2025-03-26 02:26:33,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742135_1311, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,224 INFO terminating
2025-03-26 02:26:33,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,229 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1312, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_
2025-03-26 02:26:33,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,229 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,229 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,229 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742136_1312 src: /172.20.1.14:47934 dest: /172.20.1.15:9866
2025-03-26 02:26:33,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742136_1312 src: /172.20.1.15:59692 dest: /172.20.1.16:9866
2025-03-26 02:26:33,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59692, dest: /172.20.1.16:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742136_1312, duration(ns): 507029
2025-03-26 02:26:33,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742136_1312, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,233 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47934, dest: /172.20.1.15:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742136_1312, duration(ns): 831063
2025-03-26 02:26:33,233 INFO terminating
2025-03-26 02:26:33,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1313, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_
2025-03-26 02:26:33,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,237 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,237 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,237 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742137_1313 src: /172.20.1.14:52142 dest: /172.20.1.16:9866
2025-03-26 02:26:33,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742137_1313 src: /172.20.1.16:41210 dest: /172.20.1.15:9866
2025-03-26 02:26:33,241 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52142, dest: /172.20.1.16:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742137_1313, duration(ns): 665370
2025-03-26 02:26:33,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41210, dest: /172.20.1.15:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742137_1313, duration(ns): 487745
2025-03-26 02:26:33,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742137_1313, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,241 INFO terminating
2025-03-26 02:26:33,245 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1314, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_
2025-03-26 02:26:33,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,245 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,245 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,245 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742138_1314 src: /172.20.1.14:52150 dest: /172.20.1.16:9866
2025-03-26 02:26:33,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742138_1314 src: /172.20.1.16:41220 dest: /172.20.1.15:9866
2025-03-26 02:26:33,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52150, dest: /172.20.1.16:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742138_1314, duration(ns): 619358
2025-03-26 02:26:33,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41220, dest: /172.20.1.15:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742138_1314, duration(ns): 477359
2025-03-26 02:26:33,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742138_1314, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,248 INFO terminating
2025-03-26 02:26:33,249 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1315, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_
2025-03-26 02:26:33,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,260 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,260 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,260 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742139_1315 src: /172.20.1.14:47940 dest: /172.20.1.15:9866
2025-03-26 02:26:33,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742139_1315 src: /172.20.1.15:59698 dest: /172.20.1.16:9866
2025-03-26 02:26:33,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47940, dest: /172.20.1.15:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742139_1315, duration(ns): 872183
2025-03-26 02:26:33,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59698, dest: /172.20.1.16:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742139_1315, duration(ns): 556659
2025-03-26 02:26:33,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742139_1315, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,264 INFO terminating
2025-03-26 02:26:33,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1316, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_
2025-03-26 02:26:33,274 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,274 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,274 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742140_1316 src: /172.20.1.14:52164 dest: /172.20.1.16:9866
2025-03-26 02:26:33,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742140_1316 src: /172.20.1.16:41232 dest: /172.20.1.15:9866
2025-03-26 02:26:33,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41232, dest: /172.20.1.15:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742140_1316, duration(ns): 587531
2025-03-26 02:26:33,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52164, dest: /172.20.1.16:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742140_1316, duration(ns): 738022
2025-03-26 02:26:33,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742140_1316, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,278 INFO terminating
2025-03-26 02:26:33,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,286 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1317, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_
2025-03-26 02:26:33,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,286 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,286 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,286 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742141_1317 src: /172.20.1.14:52174 dest: /172.20.1.16:9866
2025-03-26 02:26:33,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742141_1317 src: /172.20.1.16:41248 dest: /172.20.1.15:9866
2025-03-26 02:26:33,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52174, dest: /172.20.1.16:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742141_1317, duration(ns): 3120763
2025-03-26 02:26:33,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41248, dest: /172.20.1.15:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742141_1317, duration(ns): 2945553
2025-03-26 02:26:33,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742141_1317, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,292 INFO terminating
2025-03-26 02:26:33,293 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,296 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1318, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_
2025-03-26 02:26:33,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,296 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,296 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,296 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742142_1318 src: /172.20.1.14:52176 dest: /172.20.1.16:9866
2025-03-26 02:26:33,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742142_1318 src: /172.20.1.16:41254 dest: /172.20.1.15:9866
2025-03-26 02:26:33,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41254, dest: /172.20.1.15:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742142_1318, duration(ns): 502827
2025-03-26 02:26:33,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742142_1318, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52176, dest: /172.20.1.16:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742142_1318, duration(ns): 664364
2025-03-26 02:26:33,301 INFO terminating
2025-03-26 02:26:33,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1319, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_
2025-03-26 02:26:33,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,304 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,304 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,304 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742143_1319 src: /172.20.1.14:52180 dest: /172.20.1.16:9866
2025-03-26 02:26:33,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742143_1319 src: /172.20.1.16:41260 dest: /172.20.1.15:9866
2025-03-26 02:26:33,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41260, dest: /172.20.1.15:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742143_1319, duration(ns): 545670
2025-03-26 02:26:33,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742143_1319, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,308 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52180, dest: /172.20.1.16:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742143_1319, duration(ns): 706944
2025-03-26 02:26:33,308 INFO terminating
2025-03-26 02:26:33,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1320, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_
2025-03-26 02:26:33,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,311 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:33,311 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:33,311 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:33,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742144_1320 src: /172.20.1.14:52196 dest: /172.20.1.16:9866
2025-03-26 02:26:33,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742144_1320 src: /172.20.1.16:41262 dest: /172.20.1.15:9866
2025-03-26 02:26:33,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41262, dest: /172.20.1.15:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742144_1320, duration(ns): 438851
2025-03-26 02:26:33,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742144_1320, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52196, dest: /172.20.1.16:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742144_1320, duration(ns): 618148
2025-03-26 02:26:33,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742144_1320 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_
2025-03-26 02:26:33,316 INFO terminating
2025-03-26 02:26:33,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045 to 172.20.1.16:9866
2025-03-26 02:26:33,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047 to 172.20.1.16:9866
2025-03-26 02:26:33,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045 src: /172.20.1.17:51398 dest: /172.20.1.16:9866
2025-03-26 02:26:33,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047 src: /172.20.1.17:51410 dest: /172.20.1.16:9866
2025-03-26 02:26:33,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045 (numBytes=2368) to /172.20.1.16:9866
2025-03-26 02:26:33,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741869_1045 src: /172.20.1.17:51398 dest: /172.20.1.16:9866 of size 2368
2025-03-26 02:26:33,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047 (numBytes=3307) to /172.20.1.16:9866
2025-03-26 02:26:33,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741871_1047 src: /172.20.1.17:51410 dest: /172.20.1.16:9866 of size 3307
2025-03-26 02:26:33,717 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_
2025-03-26 02:26:33,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742145_1321 src: /172.20.1.14:47946 dest: /172.20.1.15:9866
2025-03-26 02:26:33,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742145_1321 src: /172.20.1.15:59712 dest: /172.20.1.16:9866
2025-03-26 02:26:33,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742145_1321 src: /172.20.1.16:57732 dest: /172.20.1.17:9866
2025-03-26 02:26:33,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57732, dest: /172.20.1.17:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742145_1321, duration(ns): 4381101
2025-03-26 02:26:33,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742145_1321, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59712, dest: /172.20.1.16:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742145_1321, duration(ns): 5768308
2025-03-26 02:26:33,741 INFO terminating
2025-03-26 02:26:33,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47946, dest: /172.20.1.15:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742145_1321, duration(ns): 8230361
2025-03-26 02:26:33,743 INFO terminating
2025-03-26 02:26:33,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:26:33,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742146_1322 src: /172.20.1.14:52198 dest: /172.20.1.16:9866
2025-03-26 02:26:33,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742146_1322 src: /172.20.1.16:41270 dest: /172.20.1.15:9866
2025-03-26 02:26:33,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742146_1322 src: /172.20.1.15:40018 dest: /172.20.1.17:9866
2025-03-26 02:26:33,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40018, dest: /172.20.1.17:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742146_1322, duration(ns): 3642111
2025-03-26 02:26:33,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41270, dest: /172.20.1.15:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742146_1322, duration(ns): 5123031
2025-03-26 02:26:33,768 INFO terminating
2025-03-26 02:26:33,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52198, dest: /172.20.1.16:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742146_1322, duration(ns): 4976990
2025-03-26 02:26:33,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742146_1322, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,770 INFO terminating
2025-03-26 02:26:33,772 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,781 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:26:33,782 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742147_1323 src: /172.20.1.14:52208 dest: /172.20.1.16:9866
2025-03-26 02:26:33,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742147_1323 src: /172.20.1.15:40020 dest: /172.20.1.17:9866
2025-03-26 02:26:33,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742147_1323 src: /172.20.1.16:41272 dest: /172.20.1.15:9866
2025-03-26 02:26:33,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40020, dest: /172.20.1.17:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742147_1323, duration(ns): 1123538
2025-03-26 02:26:33,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742147_1323, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41272, dest: /172.20.1.15:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742147_1323, duration(ns): 1489866
2025-03-26 02:26:33,788 INFO terminating
2025-03-26 02:26:33,789 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52208, dest: /172.20.1.16:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742147_1323, duration(ns): 1655642
2025-03-26 02:26:33,789 INFO terminating
2025-03-26 02:26:33,800 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_
2025-03-26 02:26:33,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742148_1324 src: /172.20.1.14:38022 dest: /172.20.1.17:9866
2025-03-26 02:26:33,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742148_1324 src: /172.20.1.17:51424 dest: /172.20.1.16:9866
2025-03-26 02:26:33,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742148_1324 src: /172.20.1.16:41280 dest: /172.20.1.15:9866
2025-03-26 02:26:33,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41280, dest: /172.20.1.15:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742148_1324, duration(ns): 1129859
2025-03-26 02:26:33,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742148_1324, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51424, dest: /172.20.1.16:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742148_1324, duration(ns): 1626407
2025-03-26 02:26:33,806 INFO terminating
2025-03-26 02:26:33,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38022, dest: /172.20.1.17:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742148_1324, duration(ns): 2219688
2025-03-26 02:26:33,807 INFO terminating
2025-03-26 02:26:33,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,813 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_
2025-03-26 02:26:33,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742149_1325 src: /172.20.1.14:52216 dest: /172.20.1.16:9866
2025-03-26 02:26:33,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742149_1325 src: /172.20.1.16:57746 dest: /172.20.1.17:9866
2025-03-26 02:26:33,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742149_1325 src: /172.20.1.17:48344 dest: /172.20.1.15:9866
2025-03-26 02:26:33,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48344, dest: /172.20.1.15:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742149_1325, duration(ns): 1008802
2025-03-26 02:26:33,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57746, dest: /172.20.1.17:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742149_1325, duration(ns): 1070113
2025-03-26 02:26:33,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742149_1325, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,818 INFO terminating
2025-03-26 02:26:33,819 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52216, dest: /172.20.1.16:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742149_1325, duration(ns): 1440053
2025-03-26 02:26:33,819 INFO terminating
2025-03-26 02:26:33,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_
2025-03-26 02:26:33,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742150_1326 src: /172.20.1.14:52230 dest: /172.20.1.16:9866
2025-03-26 02:26:33,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742150_1326 src: /172.20.1.16:57758 dest: /172.20.1.17:9866
2025-03-26 02:26:33,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742150_1326 src: /172.20.1.17:48346 dest: /172.20.1.15:9866
2025-03-26 02:26:33,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57758, dest: /172.20.1.17:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742150_1326, duration(ns): 1211755
2025-03-26 02:26:33,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48346, dest: /172.20.1.15:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742150_1326, duration(ns): 958992
2025-03-26 02:26:33,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742150_1326, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,830 INFO terminating
2025-03-26 02:26:33,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52230, dest: /172.20.1.16:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742150_1326, duration(ns): 1993727
2025-03-26 02:26:33,831 INFO terminating
2025-03-26 02:26:33,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_
2025-03-26 02:26:33,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742151_1327 src: /172.20.1.14:38032 dest: /172.20.1.17:9866
2025-03-26 02:26:33,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742151_1327 src: /172.20.1.16:41292 dest: /172.20.1.15:9866
2025-03-26 02:26:33,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742151_1327 src: /172.20.1.17:51432 dest: /172.20.1.16:9866
2025-03-26 02:26:33,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41292, dest: /172.20.1.15:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742151_1327, duration(ns): 1035131
2025-03-26 02:26:33,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742151_1327, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51432, dest: /172.20.1.16:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742151_1327, duration(ns): 1197299
2025-03-26 02:26:33,843 INFO terminating
2025-03-26 02:26:33,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38032, dest: /172.20.1.17:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742151_1327, duration(ns): 5489809
2025-03-26 02:26:33,844 INFO terminating
2025-03-26 02:26:33,845 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_
2025-03-26 02:26:33,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742152_1328 src: /172.20.1.14:52232 dest: /172.20.1.16:9866
2025-03-26 02:26:33,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742152_1328 src: /172.20.1.16:41300 dest: /172.20.1.15:9866
2025-03-26 02:26:33,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742152_1328 src: /172.20.1.15:40030 dest: /172.20.1.17:9866
2025-03-26 02:26:33,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40030, dest: /172.20.1.17:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742152_1328, duration(ns): 1046866
2025-03-26 02:26:33,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41300, dest: /172.20.1.15:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742152_1328, duration(ns): 1440870
2025-03-26 02:26:33,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742152_1328, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,861 INFO terminating
2025-03-26 02:26:33,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52232, dest: /172.20.1.16:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742152_1328, duration(ns): 1266766
2025-03-26 02:26:33,864 INFO terminating
2025-03-26 02:26:33,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_
2025-03-26 02:26:33,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742153_1329 src: /172.20.1.14:47958 dest: /172.20.1.15:9866
2025-03-26 02:26:33,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742153_1329 src: /172.20.1.15:59720 dest: /172.20.1.16:9866
2025-03-26 02:26:33,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742153_1329 src: /172.20.1.16:57772 dest: /172.20.1.17:9866
2025-03-26 02:26:33,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57772, dest: /172.20.1.17:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742153_1329, duration(ns): 892790
2025-03-26 02:26:33,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47958, dest: /172.20.1.15:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742153_1329, duration(ns): 1834990
2025-03-26 02:26:33,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59720, dest: /172.20.1.16:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742153_1329, duration(ns): 1393425
2025-03-26 02:26:33,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742153_1329, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,875 INFO terminating
2025-03-26 02:26:33,875 INFO terminating
2025-03-26 02:26:33,876 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_
2025-03-26 02:26:33,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742154_1330 src: /172.20.1.14:38042 dest: /172.20.1.17:9866
2025-03-26 02:26:33,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742154_1330 src: /172.20.1.15:59734 dest: /172.20.1.16:9866
2025-03-26 02:26:33,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742154_1330 src: /172.20.1.17:48358 dest: /172.20.1.15:9866
2025-03-26 02:26:33,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59734, dest: /172.20.1.16:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742154_1330, duration(ns): 878183
2025-03-26 02:26:33,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48358, dest: /172.20.1.15:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742154_1330, duration(ns): 1213787
2025-03-26 02:26:33,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742154_1330, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,886 INFO terminating
2025-03-26 02:26:33,887 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38042, dest: /172.20.1.17:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742154_1330, duration(ns): 1391327
2025-03-26 02:26:33,887 INFO terminating
2025-03-26 02:26:33,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:26:33,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742155_1331 src: /172.20.1.14:47964 dest: /172.20.1.15:9866
2025-03-26 02:26:33,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742155_1331 src: /172.20.1.15:59744 dest: /172.20.1.16:9866
2025-03-26 02:26:33,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742155_1331 src: /172.20.1.16:57786 dest: /172.20.1.17:9866
2025-03-26 02:26:33,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47964, dest: /172.20.1.15:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742155_1331, duration(ns): 1797535
2025-03-26 02:26:33,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59744, dest: /172.20.1.16:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742155_1331, duration(ns): 1416687
2025-03-26 02:26:33,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57786, dest: /172.20.1.17:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742155_1331, duration(ns): 855770
2025-03-26 02:26:33,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742155_1331, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,896 INFO terminating
2025-03-26 02:26:33,896 INFO terminating
2025-03-26 02:26:33,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,900 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_
2025-03-26 02:26:33,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742156_1332 src: /172.20.1.14:52248 dest: /172.20.1.16:9866
2025-03-26 02:26:33,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742156_1332 src: /172.20.1.16:57792 dest: /172.20.1.17:9866
2025-03-26 02:26:33,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742156_1332 src: /172.20.1.17:48360 dest: /172.20.1.15:9866
2025-03-26 02:26:33,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48360, dest: /172.20.1.15:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742156_1332, duration(ns): 787293
2025-03-26 02:26:33,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742156_1332, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52248, dest: /172.20.1.16:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742156_1332, duration(ns): 1365285
2025-03-26 02:26:33,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57792, dest: /172.20.1.17:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742156_1332, duration(ns): 1019149
2025-03-26 02:26:33,906 INFO terminating
2025-03-26 02:26:33,906 INFO terminating
2025-03-26 02:26:33,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_
2025-03-26 02:26:33,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742157_1333 src: /172.20.1.14:52256 dest: /172.20.1.16:9866
2025-03-26 02:26:33,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742157_1333 src: /172.20.1.16:41310 dest: /172.20.1.15:9866
2025-03-26 02:26:33,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742157_1333 src: /172.20.1.15:40042 dest: /172.20.1.17:9866
2025-03-26 02:26:33,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40042, dest: /172.20.1.17:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742157_1333, duration(ns): 880714
2025-03-26 02:26:33,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742157_1333, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52256, dest: /172.20.1.16:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742157_1333, duration(ns): 1420584
2025-03-26 02:26:33,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41310, dest: /172.20.1.15:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742157_1333, duration(ns): 1269471
2025-03-26 02:26:33,932 INFO terminating
2025-03-26 02:26:33,932 INFO terminating
2025-03-26 02:26:33,933 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_
2025-03-26 02:26:33,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742158_1334 src: /172.20.1.14:38054 dest: /172.20.1.17:9866
2025-03-26 02:26:33,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742158_1334 src: /172.20.1.17:48368 dest: /172.20.1.15:9866
2025-03-26 02:26:33,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742158_1334 src: /172.20.1.15:59748 dest: /172.20.1.16:9866
2025-03-26 02:26:33,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59748, dest: /172.20.1.16:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742158_1334, duration(ns): 898522
2025-03-26 02:26:33,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48368, dest: /172.20.1.15:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742158_1334, duration(ns): 1323576
2025-03-26 02:26:33,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742158_1334, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,944 INFO terminating
2025-03-26 02:26:33,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38054, dest: /172.20.1.17:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742158_1334, duration(ns): 1434329
2025-03-26 02:26:33,945 INFO terminating
2025-03-26 02:26:33,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_
2025-03-26 02:26:33,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742159_1335 src: /172.20.1.14:47974 dest: /172.20.1.15:9866
2025-03-26 02:26:33,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742159_1335 src: /172.20.1.15:40058 dest: /172.20.1.17:9866
2025-03-26 02:26:33,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742159_1335 src: /172.20.1.17:51438 dest: /172.20.1.16:9866
2025-03-26 02:26:33,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47974, dest: /172.20.1.15:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742159_1335, duration(ns): 1724687
2025-03-26 02:26:33,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40058, dest: /172.20.1.17:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742159_1335, duration(ns): 1262660
2025-03-26 02:26:33,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51438, dest: /172.20.1.16:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742159_1335, duration(ns): 960178
2025-03-26 02:26:33,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742159_1335, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,956 INFO terminating
2025-03-26 02:26:33,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,957 INFO terminating
2025-03-26 02:26:33,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_
2025-03-26 02:26:33,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742160_1336 src: /172.20.1.14:52270 dest: /172.20.1.16:9866
2025-03-26 02:26:33,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742160_1336 src: /172.20.1.16:41320 dest: /172.20.1.15:9866
2025-03-26 02:26:33,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742160_1336 src: /172.20.1.15:40070 dest: /172.20.1.17:9866
2025-03-26 02:26:33,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40070, dest: /172.20.1.17:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742160_1336, duration(ns): 896598
2025-03-26 02:26:33,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41320, dest: /172.20.1.15:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742160_1336, duration(ns): 1311691
2025-03-26 02:26:33,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742160_1336, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,966 INFO terminating
2025-03-26 02:26:33,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52270, dest: /172.20.1.16:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742160_1336, duration(ns): 1538551
2025-03-26 02:26:33,967 INFO terminating
2025-03-26 02:26:33,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_
2025-03-26 02:26:33,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742161_1337 src: /172.20.1.14:38070 dest: /172.20.1.17:9866
2025-03-26 02:26:33,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742161_1337 src: /172.20.1.17:48378 dest: /172.20.1.15:9866
2025-03-26 02:26:33,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742161_1337 src: /172.20.1.15:59756 dest: /172.20.1.16:9866
2025-03-26 02:26:33,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38070, dest: /172.20.1.17:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742161_1337, duration(ns): 1439297
2025-03-26 02:26:33,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59756, dest: /172.20.1.16:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742161_1337, duration(ns): 885785
2025-03-26 02:26:33,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48378, dest: /172.20.1.15:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742161_1337, duration(ns): 1261771
2025-03-26 02:26:33,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742161_1337, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,977 INFO terminating
2025-03-26 02:26:33,977 INFO terminating
2025-03-26 02:26:33,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_
2025-03-26 02:26:33,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742162_1338 src: /172.20.1.14:47984 dest: /172.20.1.15:9866
2025-03-26 02:26:33,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742162_1338 src: /172.20.1.15:59772 dest: /172.20.1.16:9866
2025-03-26 02:26:33,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742162_1338 src: /172.20.1.16:57800 dest: /172.20.1.17:9866
2025-03-26 02:26:33,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59772, dest: /172.20.1.16:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742162_1338, duration(ns): 965245
2025-03-26 02:26:33,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57800, dest: /172.20.1.17:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742162_1338, duration(ns): 681895
2025-03-26 02:26:33,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742162_1338, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:33,986 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:33,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47984, dest: /172.20.1.15:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742162_1338, duration(ns): 1325926
2025-03-26 02:26:33,986 INFO terminating
2025-03-26 02:26:33,986 INFO terminating
2025-03-26 02:26:33,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_
2025-03-26 02:26:33,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:33,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742163_1339 src: /172.20.1.14:52282 dest: /172.20.1.16:9866
2025-03-26 02:26:33,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742163_1339 src: /172.20.1.16:57810 dest: /172.20.1.17:9866
2025-03-26 02:26:33,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742163_1339 src: /172.20.1.17:48380 dest: /172.20.1.15:9866
2025-03-26 02:26:33,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48380, dest: /172.20.1.15:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742163_1339, duration(ns): 886247
2025-03-26 02:26:34,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52282, dest: /172.20.1.16:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742163_1339, duration(ns): 1497151
2025-03-26 02:26:34,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57810, dest: /172.20.1.17:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742163_1339, duration(ns): 1128961
2025-03-26 02:26:34,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742163_1339, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,000 INFO terminating
2025-03-26 02:26:34,000 INFO terminating
2025-03-26 02:26:34,001 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_
2025-03-26 02:26:34,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742164_1340 src: /172.20.1.14:52290 dest: /172.20.1.16:9866
2025-03-26 02:26:34,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742164_1340 src: /172.20.1.16:57824 dest: /172.20.1.17:9866
2025-03-26 02:26:34,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742164_1340 src: /172.20.1.17:48394 dest: /172.20.1.15:9866
2025-03-26 02:26:34,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57824, dest: /172.20.1.17:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742164_1340, duration(ns): 901575
2025-03-26 02:26:34,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48394, dest: /172.20.1.15:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742164_1340, duration(ns): 750396
2025-03-26 02:26:34,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742164_1340, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,008 INFO terminating
2025-03-26 02:26:34,009 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52290, dest: /172.20.1.16:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742164_1340, duration(ns): 1226337
2025-03-26 02:26:34,009 INFO terminating
2025-03-26 02:26:34,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_
2025-03-26 02:26:34,013 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,013 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742165_1341 src: /172.20.1.14:52306 dest: /172.20.1.16:9866
2025-03-26 02:26:34,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742165_1341 src: /172.20.1.16:41332 dest: /172.20.1.15:9866
2025-03-26 02:26:34,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742165_1341 src: /172.20.1.15:40074 dest: /172.20.1.17:9866
2025-03-26 02:26:34,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40074, dest: /172.20.1.17:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742165_1341, duration(ns): 677400
2025-03-26 02:26:34,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52306, dest: /172.20.1.16:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742165_1341, duration(ns): 1177063
2025-03-26 02:26:34,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41332, dest: /172.20.1.15:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742165_1341, duration(ns): 997540
2025-03-26 02:26:34,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742165_1341, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,018 INFO terminating
2025-03-26 02:26:34,018 INFO terminating
2025-03-26 02:26:34,019 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_
2025-03-26 02:26:34,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742166_1342 src: /172.20.1.14:38078 dest: /172.20.1.17:9866
2025-03-26 02:26:34,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742166_1342 src: /172.20.1.15:59788 dest: /172.20.1.16:9866
2025-03-26 02:26:34,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742166_1342 src: /172.20.1.17:48396 dest: /172.20.1.15:9866
2025-03-26 02:26:34,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59788, dest: /172.20.1.16:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742166_1342, duration(ns): 760269
2025-03-26 02:26:34,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48396, dest: /172.20.1.15:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742166_1342, duration(ns): 1041281
2025-03-26 02:26:34,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742166_1342, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,026 INFO terminating
2025-03-26 02:26:34,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38078, dest: /172.20.1.17:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742166_1342, duration(ns): 1304164
2025-03-26 02:26:34,027 INFO terminating
2025-03-26 02:26:34,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_
2025-03-26 02:26:34,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742167_1343 src: /172.20.1.14:48000 dest: /172.20.1.15:9866
2025-03-26 02:26:34,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742167_1343 src: /172.20.1.15:59792 dest: /172.20.1.16:9866
2025-03-26 02:26:34,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742167_1343 src: /172.20.1.16:57838 dest: /172.20.1.17:9866
2025-03-26 02:26:34,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57838, dest: /172.20.1.17:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742167_1343, duration(ns): 713118
2025-03-26 02:26:34,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742167_1343, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,035 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48000, dest: /172.20.1.15:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742167_1343, duration(ns): 1379300
2025-03-26 02:26:34,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59792, dest: /172.20.1.16:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742167_1343, duration(ns): 1000875
2025-03-26 02:26:34,035 INFO terminating
2025-03-26 02:26:34,035 INFO terminating
2025-03-26 02:26:34,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_
2025-03-26 02:26:34,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742168_1344 src: /172.20.1.14:38086 dest: /172.20.1.17:9866
2025-03-26 02:26:34,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742168_1344 src: /172.20.1.17:48402 dest: /172.20.1.15:9866
2025-03-26 02:26:34,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742168_1344 src: /172.20.1.15:59806 dest: /172.20.1.16:9866
2025-03-26 02:26:34,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59806, dest: /172.20.1.16:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742168_1344, duration(ns): 893737
2025-03-26 02:26:34,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48402, dest: /172.20.1.15:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742168_1344, duration(ns): 1152659
2025-03-26 02:26:34,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742168_1344, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,043 INFO terminating
2025-03-26 02:26:34,044 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38086, dest: /172.20.1.17:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742168_1344, duration(ns): 1614284
2025-03-26 02:26:34,044 INFO terminating
2025-03-26 02:26:34,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_
2025-03-26 02:26:34,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742169_1345 src: /172.20.1.14:38096 dest: /172.20.1.17:9866
2025-03-26 02:26:34,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742169_1345 src: /172.20.1.15:59812 dest: /172.20.1.16:9866
2025-03-26 02:26:34,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742169_1345 src: /172.20.1.17:48410 dest: /172.20.1.15:9866
2025-03-26 02:26:34,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59812, dest: /172.20.1.16:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742169_1345, duration(ns): 1110178
2025-03-26 02:26:34,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742169_1345, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,053 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38096, dest: /172.20.1.17:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742169_1345, duration(ns): 1910375
2025-03-26 02:26:34,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48410, dest: /172.20.1.15:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742169_1345, duration(ns): 1431919
2025-03-26 02:26:34,053 INFO terminating
2025-03-26 02:26:34,053 INFO terminating
2025-03-26 02:26:34,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_
2025-03-26 02:26:34,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742170_1346 src: /172.20.1.14:48006 dest: /172.20.1.15:9866
2025-03-26 02:26:34,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742170_1346 src: /172.20.1.15:40076 dest: /172.20.1.17:9866
2025-03-26 02:26:34,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742170_1346 src: /172.20.1.17:51448 dest: /172.20.1.16:9866
2025-03-26 02:26:34,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51448, dest: /172.20.1.16:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742170_1346, duration(ns): 850976
2025-03-26 02:26:34,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742170_1346, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40076, dest: /172.20.1.17:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742170_1346, duration(ns): 1134675
2025-03-26 02:26:34,067 INFO terminating
2025-03-26 02:26:34,068 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48006, dest: /172.20.1.15:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742170_1346, duration(ns): 1633131
2025-03-26 02:26:34,068 INFO terminating
2025-03-26 02:26:34,072 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:26:34,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742171_1347 src: /172.20.1.14:38104 dest: /172.20.1.17:9866
2025-03-26 02:26:34,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742171_1347 src: /172.20.1.17:51464 dest: /172.20.1.16:9866
2025-03-26 02:26:34,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742171_1347 src: /172.20.1.16:41346 dest: /172.20.1.15:9866
2025-03-26 02:26:34,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41346, dest: /172.20.1.15:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742171_1347, duration(ns): 880817
2025-03-26 02:26:34,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38104, dest: /172.20.1.17:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742171_1347, duration(ns): 1822379
2025-03-26 02:26:34,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51464, dest: /172.20.1.16:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742171_1347, duration(ns): 1401042
2025-03-26 02:26:34,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742171_1347, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,078 INFO terminating
2025-03-26 02:26:34,078 INFO terminating
2025-03-26 02:26:34,080 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_
2025-03-26 02:26:34,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742172_1348 src: /172.20.1.14:52314 dest: /172.20.1.16:9866
2025-03-26 02:26:34,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742172_1348 src: /172.20.1.16:41360 dest: /172.20.1.15:9866
2025-03-26 02:26:34,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742172_1348 src: /172.20.1.15:40082 dest: /172.20.1.17:9866
2025-03-26 02:26:34,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40082, dest: /172.20.1.17:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742172_1348, duration(ns): 796306
2025-03-26 02:26:34,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742172_1348, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41360, dest: /172.20.1.15:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742172_1348, duration(ns): 1110972
2025-03-26 02:26:34,088 INFO terminating
2025-03-26 02:26:34,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52314, dest: /172.20.1.16:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742172_1348, duration(ns): 2191302
2025-03-26 02:26:34,089 INFO terminating
2025-03-26 02:26:34,090 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1349, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_
2025-03-26 02:26:34,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742173_1349 src: /172.20.1.14:48012 dest: /172.20.1.15:9866
2025-03-26 02:26:34,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742173_1349 src: /172.20.1.15:59826 dest: /172.20.1.16:9866
2025-03-26 02:26:34,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742173_1349 src: /172.20.1.16:57854 dest: /172.20.1.17:9866
2025-03-26 02:26:34,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57854, dest: /172.20.1.17:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742173_1349, duration(ns): 1034756
2025-03-26 02:26:34,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742173_1349, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59826, dest: /172.20.1.16:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742173_1349, duration(ns): 1390254
2025-03-26 02:26:34,099 INFO terminating
2025-03-26 02:26:34,100 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48012, dest: /172.20.1.15:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742173_1349, duration(ns): 1755429
2025-03-26 02:26:34,100 INFO terminating
2025-03-26 02:26:34,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1350, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:26:34,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742174_1350 src: /172.20.1.14:38106 dest: /172.20.1.17:9866
2025-03-26 02:26:34,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742174_1350 src: /172.20.1.17:48418 dest: /172.20.1.15:9866
2025-03-26 02:26:34,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742174_1350 src: /172.20.1.15:59840 dest: /172.20.1.16:9866
2025-03-26 02:26:34,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59840, dest: /172.20.1.16:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742174_1350, duration(ns): 819318
2025-03-26 02:26:34,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38106, dest: /172.20.1.17:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742174_1350, duration(ns): 1227612
2025-03-26 02:26:34,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48418, dest: /172.20.1.15:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742174_1350, duration(ns): 1156269
2025-03-26 02:26:34,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742174_1350, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,109 INFO terminating
2025-03-26 02:26:34,109 INFO terminating
2025-03-26 02:26:34,110 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1351, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:26:34,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742175_1351 src: /172.20.1.14:52316 dest: /172.20.1.16:9866
2025-03-26 02:26:34,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742175_1351 src: /172.20.1.16:57870 dest: /172.20.1.17:9866
2025-03-26 02:26:34,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742175_1351 src: /172.20.1.17:48424 dest: /172.20.1.15:9866
2025-03-26 02:26:34,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48424, dest: /172.20.1.15:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742175_1351, duration(ns): 1008438
2025-03-26 02:26:34,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742175_1351, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57870, dest: /172.20.1.17:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742175_1351, duration(ns): 1251721
2025-03-26 02:26:34,119 INFO terminating
2025-03-26 02:26:34,120 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52316, dest: /172.20.1.16:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742175_1351, duration(ns): 1593543
2025-03-26 02:26:34,120 INFO terminating
2025-03-26 02:26:34,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1352, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_
2025-03-26 02:26:34,123 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,123 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742176_1352 src: /172.20.1.14:38108 dest: /172.20.1.17:9866
2025-03-26 02:26:34,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742176_1352 src: /172.20.1.15:59854 dest: /172.20.1.16:9866
2025-03-26 02:26:34,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742176_1352 src: /172.20.1.17:48434 dest: /172.20.1.15:9866
2025-03-26 02:26:34,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59854, dest: /172.20.1.16:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742176_1352, duration(ns): 1274285
2025-03-26 02:26:34,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742176_1352, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38108, dest: /172.20.1.17:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742176_1352, duration(ns): 2616304
2025-03-26 02:26:34,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48434, dest: /172.20.1.15:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742176_1352, duration(ns): 1625153
2025-03-26 02:26:34,130 INFO terminating
2025-03-26 02:26:34,130 INFO terminating
2025-03-26 02:26:34,131 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1353, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_
2025-03-26 02:26:34,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742177_1353 src: /172.20.1.14:38118 dest: /172.20.1.17:9866
2025-03-26 02:26:34,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742177_1353 src: /172.20.1.17:51468 dest: /172.20.1.16:9866
2025-03-26 02:26:34,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742177_1353 src: /172.20.1.16:41374 dest: /172.20.1.15:9866
2025-03-26 02:26:34,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41374, dest: /172.20.1.15:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742177_1353, duration(ns): 811148
2025-03-26 02:26:34,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742177_1353, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38118, dest: /172.20.1.17:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742177_1353, duration(ns): 1957542
2025-03-26 02:26:34,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51468, dest: /172.20.1.16:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742177_1353, duration(ns): 1018595
2025-03-26 02:26:34,139 INFO terminating
2025-03-26 02:26:34,140 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,140 INFO terminating
2025-03-26 02:26:34,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1354, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_
2025-03-26 02:26:34,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742178_1354 src: /172.20.1.14:38132 dest: /172.20.1.17:9866
2025-03-26 02:26:34,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742178_1354 src: /172.20.1.17:51480 dest: /172.20.1.16:9866
2025-03-26 02:26:34,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742178_1354 src: /172.20.1.16:41390 dest: /172.20.1.15:9866
2025-03-26 02:26:34,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41390, dest: /172.20.1.15:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742178_1354, duration(ns): 971829
2025-03-26 02:26:34,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742178_1354, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51480, dest: /172.20.1.16:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742178_1354, duration(ns): 1408975
2025-03-26 02:26:34,150 INFO terminating
2025-03-26 02:26:34,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38132, dest: /172.20.1.17:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742178_1354, duration(ns): 2296132
2025-03-26 02:26:34,151 INFO terminating
2025-03-26 02:26:34,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,160 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1355, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_
2025-03-26 02:26:34,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742179_1355 src: /172.20.1.14:48018 dest: /172.20.1.15:9866
2025-03-26 02:26:34,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742179_1355 src: /172.20.1.15:40084 dest: /172.20.1.17:9866
2025-03-26 02:26:34,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742179_1355 src: /172.20.1.17:51496 dest: /172.20.1.16:9866
2025-03-26 02:26:34,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40084, dest: /172.20.1.17:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742179_1355, duration(ns): 1265912
2025-03-26 02:26:34,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51496, dest: /172.20.1.16:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742179_1355, duration(ns): 886332
2025-03-26 02:26:34,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742179_1355, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,166 INFO terminating
2025-03-26 02:26:34,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48018, dest: /172.20.1.15:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742179_1355, duration(ns): 1570797
2025-03-26 02:26:34,167 INFO terminating
2025-03-26 02:26:34,168 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1356, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_
2025-03-26 02:26:34,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742180_1356 src: /172.20.1.14:52332 dest: /172.20.1.16:9866
2025-03-26 02:26:34,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742180_1356 src: /172.20.1.16:57878 dest: /172.20.1.17:9866
2025-03-26 02:26:34,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742180_1356 src: /172.20.1.17:48444 dest: /172.20.1.15:9866
2025-03-26 02:26:34,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48444, dest: /172.20.1.15:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742180_1356, duration(ns): 970300
2025-03-26 02:26:34,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52332, dest: /172.20.1.16:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742180_1356, duration(ns): 1907129
2025-03-26 02:26:34,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57878, dest: /172.20.1.17:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742180_1356, duration(ns): 1543318
2025-03-26 02:26:34,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742180_1356, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,183 INFO terminating
2025-03-26 02:26:34,184 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,184 INFO terminating
2025-03-26 02:26:34,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1357, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_
2025-03-26 02:26:34,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742181_1357 src: /172.20.1.14:48020 dest: /172.20.1.15:9866
2025-03-26 02:26:34,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742181_1357 src: /172.20.1.15:40098 dest: /172.20.1.17:9866
2025-03-26 02:26:34,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742181_1357 src: /172.20.1.17:51510 dest: /172.20.1.16:9866
2025-03-26 02:26:34,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40098, dest: /172.20.1.17:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742181_1357, duration(ns): 2448788
2025-03-26 02:26:34,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51510, dest: /172.20.1.16:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742181_1357, duration(ns): 2086774
2025-03-26 02:26:34,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742181_1357, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,195 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48020, dest: /172.20.1.15:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742181_1357, duration(ns): 3222110
2025-03-26 02:26:34,195 INFO terminating
2025-03-26 02:26:34,195 INFO terminating
2025-03-26 02:26:34,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1358, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_
2025-03-26 02:26:34,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742182_1358 src: /172.20.1.14:52336 dest: /172.20.1.16:9866
2025-03-26 02:26:34,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742182_1358 src: /172.20.1.16:57894 dest: /172.20.1.17:9866
2025-03-26 02:26:34,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742182_1358 src: /172.20.1.17:48456 dest: /172.20.1.15:9866
2025-03-26 02:26:34,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57894, dest: /172.20.1.17:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742182_1358, duration(ns): 1440900
2025-03-26 02:26:34,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48456, dest: /172.20.1.15:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742182_1358, duration(ns): 952097
2025-03-26 02:26:34,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742182_1358, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,205 INFO terminating
2025-03-26 02:26:34,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52336, dest: /172.20.1.16:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742182_1358, duration(ns): 1886008
2025-03-26 02:26:34,206 INFO terminating
2025-03-26 02:26:34,210 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1359, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_
2025-03-26 02:26:34,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742183_1359 src: /172.20.1.14:52344 dest: /172.20.1.16:9866
2025-03-26 02:26:34,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742183_1359 src: /172.20.1.16:57910 dest: /172.20.1.17:9866
2025-03-26 02:26:34,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742183_1359 src: /172.20.1.17:48472 dest: /172.20.1.15:9866
2025-03-26 02:26:34,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48472, dest: /172.20.1.15:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742183_1359, duration(ns): 1003007
2025-03-26 02:26:34,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742183_1359, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57910, dest: /172.20.1.17:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742183_1359, duration(ns): 1521269
2025-03-26 02:26:34,219 INFO terminating
2025-03-26 02:26:34,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52344, dest: /172.20.1.16:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742183_1359, duration(ns): 3728719
2025-03-26 02:26:34,220 INFO terminating
2025-03-26 02:26:34,221 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,225 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1360, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_
2025-03-26 02:26:34,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742184_1360 src: /172.20.1.14:38136 dest: /172.20.1.17:9866
2025-03-26 02:26:34,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742184_1360 src: /172.20.1.17:48488 dest: /172.20.1.15:9866
2025-03-26 02:26:34,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742184_1360 src: /172.20.1.15:59858 dest: /172.20.1.16:9866
2025-03-26 02:26:34,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59858, dest: /172.20.1.16:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742184_1360, duration(ns): 1091184
2025-03-26 02:26:34,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48488, dest: /172.20.1.15:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742184_1360, duration(ns): 1397149
2025-03-26 02:26:34,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742184_1360, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,235 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38136, dest: /172.20.1.17:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742184_1360, duration(ns): 1945902
2025-03-26 02:26:34,235 INFO terminating
2025-03-26 02:26:34,235 INFO terminating
2025-03-26 02:26:34,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1361, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_
2025-03-26 02:26:34,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742185_1361 src: /172.20.1.14:48028 dest: /172.20.1.15:9866
2025-03-26 02:26:34,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742185_1361 src: /172.20.1.15:59862 dest: /172.20.1.16:9866
2025-03-26 02:26:34,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742185_1361 src: /172.20.1.16:57920 dest: /172.20.1.17:9866
2025-03-26 02:26:34,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59862, dest: /172.20.1.16:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742185_1361, duration(ns): 1172313
2025-03-26 02:26:34,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57920, dest: /172.20.1.17:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742185_1361, duration(ns): 869266
2025-03-26 02:26:34,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742185_1361, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,244 INFO terminating
2025-03-26 02:26:34,245 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48028, dest: /172.20.1.15:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742185_1361, duration(ns): 1574901
2025-03-26 02:26:34,245 INFO terminating
2025-03-26 02:26:34,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1362, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:26:34,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742186_1362 src: /172.20.1.14:48042 dest: /172.20.1.15:9866
2025-03-26 02:26:34,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742186_1362 src: /172.20.1.15:40108 dest: /172.20.1.17:9866
2025-03-26 02:26:34,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742186_1362 src: /172.20.1.17:51522 dest: /172.20.1.16:9866
2025-03-26 02:26:34,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40108, dest: /172.20.1.17:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742186_1362, duration(ns): 1184466
2025-03-26 02:26:34,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51522, dest: /172.20.1.16:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742186_1362, duration(ns): 871475
2025-03-26 02:26:34,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742186_1362, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48042, dest: /172.20.1.15:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742186_1362, duration(ns): 1473314
2025-03-26 02:26:34,257 INFO terminating
2025-03-26 02:26:34,257 INFO terminating
2025-03-26 02:26:34,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,261 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1363, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_
2025-03-26 02:26:34,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742187_1363 src: /172.20.1.14:38140 dest: /172.20.1.17:9866
2025-03-26 02:26:34,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742187_1363 src: /172.20.1.17:48500 dest: /172.20.1.15:9866
2025-03-26 02:26:34,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742187_1363 src: /172.20.1.15:59876 dest: /172.20.1.16:9866
2025-03-26 02:26:34,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59876, dest: /172.20.1.16:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742187_1363, duration(ns): 887404
2025-03-26 02:26:34,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742187_1363, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38140, dest: /172.20.1.17:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742187_1363, duration(ns): 2396055
2025-03-26 02:26:34,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48500, dest: /172.20.1.15:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742187_1363, duration(ns): 1219809
2025-03-26 02:26:34,268 INFO terminating
2025-03-26 02:26:34,268 INFO terminating
2025-03-26 02:26:34,269 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1364, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_
2025-03-26 02:26:34,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742188_1364 src: /172.20.1.14:52358 dest: /172.20.1.16:9866
2025-03-26 02:26:34,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742188_1364 src: /172.20.1.16:57928 dest: /172.20.1.17:9866
2025-03-26 02:26:34,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742188_1364 src: /172.20.1.17:48512 dest: /172.20.1.15:9866
2025-03-26 02:26:34,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57928, dest: /172.20.1.17:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742188_1364, duration(ns): 1240076
2025-03-26 02:26:34,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48512, dest: /172.20.1.15:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742188_1364, duration(ns): 820898
2025-03-26 02:26:34,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742188_1364, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,277 INFO terminating
2025-03-26 02:26:34,278 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52358, dest: /172.20.1.16:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742188_1364, duration(ns): 1616491
2025-03-26 02:26:34,278 INFO terminating
2025-03-26 02:26:34,281 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1365, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:26:34,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742189_1365 src: /172.20.1.14:48056 dest: /172.20.1.15:9866
2025-03-26 02:26:34,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742189_1365 src: /172.20.1.15:59884 dest: /172.20.1.16:9866
2025-03-26 02:26:34,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742189_1365 src: /172.20.1.16:57938 dest: /172.20.1.17:9866
2025-03-26 02:26:34,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57938, dest: /172.20.1.17:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742189_1365, duration(ns): 933625
2025-03-26 02:26:34,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742189_1365, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59884, dest: /172.20.1.16:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742189_1365, duration(ns): 1280871
2025-03-26 02:26:34,290 INFO terminating
2025-03-26 02:26:34,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48056, dest: /172.20.1.15:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742189_1365, duration(ns): 4377382
2025-03-26 02:26:34,291 INFO terminating
2025-03-26 02:26:34,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1366, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_
2025-03-26 02:26:34,294 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,294 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742190_1366 src: /172.20.1.14:38150 dest: /172.20.1.17:9866
2025-03-26 02:26:34,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742190_1366 src: /172.20.1.17:51534 dest: /172.20.1.16:9866
2025-03-26 02:26:34,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742190_1366 src: /172.20.1.16:41402 dest: /172.20.1.15:9866
2025-03-26 02:26:34,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41402, dest: /172.20.1.15:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742190_1366, duration(ns): 859615
2025-03-26 02:26:34,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742190_1366, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38150, dest: /172.20.1.17:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742190_1366, duration(ns): 2099378
2025-03-26 02:26:34,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51534, dest: /172.20.1.16:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742190_1366, duration(ns): 1342198
2025-03-26 02:26:34,300 INFO terminating
2025-03-26 02:26:34,300 INFO terminating
2025-03-26 02:26:34,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,309 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1367, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_
2025-03-26 02:26:34,309 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,309 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742191_1367 src: /172.20.1.14:48062 dest: /172.20.1.15:9866
2025-03-26 02:26:34,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742191_1367 src: /172.20.1.15:40112 dest: /172.20.1.17:9866
2025-03-26 02:26:34,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742191_1367 src: /172.20.1.17:51550 dest: /172.20.1.16:9866
2025-03-26 02:26:34,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51550, dest: /172.20.1.16:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742191_1367, duration(ns): 763985
2025-03-26 02:26:34,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742191_1367, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48062, dest: /172.20.1.15:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742191_1367, duration(ns): 2035174
2025-03-26 02:26:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40112, dest: /172.20.1.17:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742191_1367, duration(ns): 1512508
2025-03-26 02:26:34,315 INFO terminating
2025-03-26 02:26:34,315 INFO terminating
2025-03-26 02:26:34,316 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1368, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_
2025-03-26 02:26:34,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742192_1368 src: /172.20.1.14:38154 dest: /172.20.1.17:9866
2025-03-26 02:26:34,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742192_1368 src: /172.20.1.17:51564 dest: /172.20.1.16:9866
2025-03-26 02:26:34,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742192_1368 src: /172.20.1.16:41418 dest: /172.20.1.15:9866
2025-03-26 02:26:34,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41418, dest: /172.20.1.15:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742192_1368, duration(ns): 747500
2025-03-26 02:26:34,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51564, dest: /172.20.1.16:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742192_1368, duration(ns): 1136296
2025-03-26 02:26:34,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742192_1368, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,325 INFO terminating
2025-03-26 02:26:34,326 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38154, dest: /172.20.1.17:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742192_1368, duration(ns): 1543200
2025-03-26 02:26:34,326 INFO terminating
2025-03-26 02:26:34,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1369, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_
2025-03-26 02:26:34,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742193_1369 src: /172.20.1.14:48070 dest: /172.20.1.15:9866
2025-03-26 02:26:34,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742193_1369 src: /172.20.1.15:40126 dest: /172.20.1.17:9866
2025-03-26 02:26:34,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742193_1369 src: /172.20.1.17:51570 dest: /172.20.1.16:9866
2025-03-26 02:26:34,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51570, dest: /172.20.1.16:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742193_1369, duration(ns): 669692
2025-03-26 02:26:34,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742193_1369, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48070, dest: /172.20.1.15:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742193_1369, duration(ns): 3449004
2025-03-26 02:26:34,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40126, dest: /172.20.1.17:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742193_1369, duration(ns): 1012085
2025-03-26 02:26:34,336 INFO terminating
2025-03-26 02:26:34,336 INFO terminating
2025-03-26 02:26:34,337 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,340 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1370, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_
2025-03-26 02:26:34,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742194_1370 src: /172.20.1.14:48080 dest: /172.20.1.15:9866
2025-03-26 02:26:34,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742194_1370 src: /172.20.1.15:40128 dest: /172.20.1.17:9866
2025-03-26 02:26:34,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742194_1370 src: /172.20.1.17:51584 dest: /172.20.1.16:9866
2025-03-26 02:26:34,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51584, dest: /172.20.1.16:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742194_1370, duration(ns): 699967
2025-03-26 02:26:34,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742194_1370, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48080, dest: /172.20.1.15:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742194_1370, duration(ns): 1814332
2025-03-26 02:26:34,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40128, dest: /172.20.1.17:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742194_1370, duration(ns): 1010690
2025-03-26 02:26:34,345 INFO terminating
2025-03-26 02:26:34,345 INFO terminating
2025-03-26 02:26:34,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1371, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_
2025-03-26 02:26:34,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742195_1371 src: /172.20.1.14:48082 dest: /172.20.1.15:9866
2025-03-26 02:26:34,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742195_1371 src: /172.20.1.15:40142 dest: /172.20.1.17:9866
2025-03-26 02:26:34,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742195_1371 src: /172.20.1.17:51596 dest: /172.20.1.16:9866
2025-03-26 02:26:34,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51596, dest: /172.20.1.16:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742195_1371, duration(ns): 892313
2025-03-26 02:26:34,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742195_1371, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48082, dest: /172.20.1.15:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742195_1371, duration(ns): 1630388
2025-03-26 02:26:34,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40142, dest: /172.20.1.17:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742195_1371, duration(ns): 1168821
2025-03-26 02:26:34,353 INFO terminating
2025-03-26 02:26:34,353 INFO terminating
2025-03-26 02:26:34,354 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1372, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_
2025-03-26 02:26:34,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742196_1372 src: /172.20.1.14:52362 dest: /172.20.1.16:9866
2025-03-26 02:26:34,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742196_1372 src: /172.20.1.15:40152 dest: /172.20.1.17:9866
2025-03-26 02:26:34,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742196_1372 src: /172.20.1.16:41426 dest: /172.20.1.15:9866
2025-03-26 02:26:34,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40152, dest: /172.20.1.17:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742196_1372, duration(ns): 567944
2025-03-26 02:26:34,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742196_1372, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41426, dest: /172.20.1.15:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742196_1372, duration(ns): 6425773
2025-03-26 02:26:34,367 INFO terminating
2025-03-26 02:26:34,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52362, dest: /172.20.1.16:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742196_1372, duration(ns): 6686316
2025-03-26 02:26:34,368 INFO terminating
2025-03-26 02:26:34,371 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1373, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_
2025-03-26 02:26:34,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742197_1373 src: /172.20.1.14:38164 dest: /172.20.1.17:9866
2025-03-26 02:26:34,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742197_1373 src: /172.20.1.17:51612 dest: /172.20.1.16:9866
2025-03-26 02:26:34,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742197_1373 src: /172.20.1.16:41436 dest: /172.20.1.15:9866
2025-03-26 02:26:34,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41436, dest: /172.20.1.15:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742197_1373, duration(ns): 833751
2025-03-26 02:26:34,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742197_1373, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38164, dest: /172.20.1.17:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742197_1373, duration(ns): 1347766
2025-03-26 02:26:34,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51612, dest: /172.20.1.16:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742197_1373, duration(ns): 1010125
2025-03-26 02:26:34,376 INFO terminating
2025-03-26 02:26:34,376 INFO terminating
2025-03-26 02:26:34,377 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1374, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_
2025-03-26 02:26:34,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742198_1374 src: /172.20.1.14:52368 dest: /172.20.1.16:9866
2025-03-26 02:26:34,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742198_1374 src: /172.20.1.16:57950 dest: /172.20.1.17:9866
2025-03-26 02:26:34,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742198_1374 src: /172.20.1.17:48520 dest: /172.20.1.15:9866
2025-03-26 02:26:34,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57950, dest: /172.20.1.17:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742198_1374, duration(ns): 917283
2025-03-26 02:26:34,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48520, dest: /172.20.1.15:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742198_1374, duration(ns): 768710
2025-03-26 02:26:34,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742198_1374, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,387 INFO terminating
2025-03-26 02:26:34,388 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52368, dest: /172.20.1.16:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742198_1374, duration(ns): 1235222
2025-03-26 02:26:34,388 INFO terminating
2025-03-26 02:26:34,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1375, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_
2025-03-26 02:26:34,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742199_1375 src: /172.20.1.14:48094 dest: /172.20.1.15:9866
2025-03-26 02:26:34,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742199_1375 src: /172.20.1.15:59894 dest: /172.20.1.16:9866
2025-03-26 02:26:34,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742199_1375 src: /172.20.1.16:57952 dest: /172.20.1.17:9866
2025-03-26 02:26:34,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57952, dest: /172.20.1.17:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742199_1375, duration(ns): 683154
2025-03-26 02:26:34,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742199_1375, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48094, dest: /172.20.1.15:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742199_1375, duration(ns): 1538223
2025-03-26 02:26:34,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59894, dest: /172.20.1.16:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742199_1375, duration(ns): 971520
2025-03-26 02:26:34,396 INFO terminating
2025-03-26 02:26:34,396 INFO terminating
2025-03-26 02:26:34,397 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,400 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1376, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_
2025-03-26 02:26:34,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742200_1376 src: /172.20.1.14:38178 dest: /172.20.1.17:9866
2025-03-26 02:26:34,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742200_1376 src: /172.20.1.17:51614 dest: /172.20.1.16:9866
2025-03-26 02:26:34,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742200_1376 src: /172.20.1.16:41438 dest: /172.20.1.15:9866
2025-03-26 02:26:34,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41438, dest: /172.20.1.15:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742200_1376, duration(ns): 795986
2025-03-26 02:26:34,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742200_1376, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38178, dest: /172.20.1.17:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742200_1376, duration(ns): 1259976
2025-03-26 02:26:34,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51614, dest: /172.20.1.16:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742200_1376, duration(ns): 929275
2025-03-26 02:26:34,405 INFO terminating
2025-03-26 02:26:34,406 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,406 INFO terminating
2025-03-26 02:26:34,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1377, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_
2025-03-26 02:26:34,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742201_1377 src: /172.20.1.14:52380 dest: /172.20.1.16:9866
2025-03-26 02:26:34,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742201_1377 src: /172.20.1.16:41452 dest: /172.20.1.15:9866
2025-03-26 02:26:34,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742201_1377 src: /172.20.1.15:40162 dest: /172.20.1.17:9866
2025-03-26 02:26:34,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52380, dest: /172.20.1.16:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742201_1377, duration(ns): 1280714
2025-03-26 02:26:34,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40162, dest: /172.20.1.17:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742201_1377, duration(ns): 763564
2025-03-26 02:26:34,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41452, dest: /172.20.1.15:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742201_1377, duration(ns): 1037562
2025-03-26 02:26:34,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742201_1377, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,414 INFO terminating
2025-03-26 02:26:34,414 INFO terminating
2025-03-26 02:26:34,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,418 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1378, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_
2025-03-26 02:26:34,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742202_1378 src: /172.20.1.14:48104 dest: /172.20.1.15:9866
2025-03-26 02:26:34,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742202_1378 src: /172.20.1.15:40170 dest: /172.20.1.17:9866
2025-03-26 02:26:34,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742202_1378 src: /172.20.1.17:51616 dest: /172.20.1.16:9866
2025-03-26 02:26:34,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51616, dest: /172.20.1.16:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742202_1378, duration(ns): 1073737
2025-03-26 02:26:34,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742202_1378, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40170, dest: /172.20.1.17:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742202_1378, duration(ns): 1377127
2025-03-26 02:26:34,423 INFO terminating
2025-03-26 02:26:34,426 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48104, dest: /172.20.1.15:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742202_1378, duration(ns): 3872862
2025-03-26 02:26:34,426 INFO terminating
2025-03-26 02:26:34,429 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1379, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_
2025-03-26 02:26:34,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742203_1379 src: /172.20.1.14:52392 dest: /172.20.1.16:9866
2025-03-26 02:26:34,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742203_1379 src: /172.20.1.16:57956 dest: /172.20.1.17:9866
2025-03-26 02:26:34,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742203_1379 src: /172.20.1.17:48534 dest: /172.20.1.15:9866
2025-03-26 02:26:34,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48534, dest: /172.20.1.15:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742203_1379, duration(ns): 758695
2025-03-26 02:26:34,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742203_1379, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52392, dest: /172.20.1.16:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742203_1379, duration(ns): 1223820
2025-03-26 02:26:34,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57956, dest: /172.20.1.17:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742203_1379, duration(ns): 877944
2025-03-26 02:26:34,434 INFO terminating
2025-03-26 02:26:34,434 INFO terminating
2025-03-26 02:26:34,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1380, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_
2025-03-26 02:26:34,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742204_1380 src: /172.20.1.14:48116 dest: /172.20.1.15:9866
2025-03-26 02:26:34,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742204_1380 src: /172.20.1.15:40172 dest: /172.20.1.17:9866
2025-03-26 02:26:34,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742204_1380 src: /172.20.1.17:51626 dest: /172.20.1.16:9866
2025-03-26 02:26:34,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51626, dest: /172.20.1.16:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742204_1380, duration(ns): 759107
2025-03-26 02:26:34,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742204_1380, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48116, dest: /172.20.1.15:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742204_1380, duration(ns): 1470210
2025-03-26 02:26:34,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40172, dest: /172.20.1.17:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742204_1380, duration(ns): 1083851
2025-03-26 02:26:34,443 INFO terminating
2025-03-26 02:26:34,443 INFO terminating
2025-03-26 02:26:34,444 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1381, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:26:34,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742205_1381 src: /172.20.1.14:38184 dest: /172.20.1.17:9866
2025-03-26 02:26:34,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742205_1381 src: /172.20.1.17:51630 dest: /172.20.1.16:9866
2025-03-26 02:26:34,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742205_1381 src: /172.20.1.16:41462 dest: /172.20.1.15:9866
2025-03-26 02:26:34,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41462, dest: /172.20.1.15:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742205_1381, duration(ns): 947919
2025-03-26 02:26:34,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51630, dest: /172.20.1.16:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742205_1381, duration(ns): 1105537
2025-03-26 02:26:34,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742205_1381, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,459 INFO terminating
2025-03-26 02:26:34,460 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38184, dest: /172.20.1.17:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742205_1381, duration(ns): 1451623
2025-03-26 02:26:34,460 INFO terminating
2025-03-26 02:26:34,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1382, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_
2025-03-26 02:26:34,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742206_1382 src: /172.20.1.14:38186 dest: /172.20.1.17:9866
2025-03-26 02:26:34,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742206_1382 src: /172.20.1.17:51646 dest: /172.20.1.16:9866
2025-03-26 02:26:34,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742206_1382 src: /172.20.1.16:41464 dest: /172.20.1.15:9866
2025-03-26 02:26:34,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41464, dest: /172.20.1.15:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742206_1382, duration(ns): 859181
2025-03-26 02:26:34,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51646, dest: /172.20.1.16:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742206_1382, duration(ns): 1040164
2025-03-26 02:26:34,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742206_1382, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,469 INFO terminating
2025-03-26 02:26:34,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38186, dest: /172.20.1.17:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742206_1382, duration(ns): 1364804
2025-03-26 02:26:34,470 INFO terminating
2025-03-26 02:26:34,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1383, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_
2025-03-26 02:26:34,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742207_1383 src: /172.20.1.14:38198 dest: /172.20.1.17:9866
2025-03-26 02:26:34,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742207_1383 src: /172.20.1.17:51648 dest: /172.20.1.16:9866
2025-03-26 02:26:34,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742207_1383 src: /172.20.1.16:41476 dest: /172.20.1.15:9866
2025-03-26 02:26:34,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41476, dest: /172.20.1.15:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742207_1383, duration(ns): 919035
2025-03-26 02:26:34,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51648, dest: /172.20.1.16:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742207_1383, duration(ns): 1163291
2025-03-26 02:26:34,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742207_1383, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,479 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38198, dest: /172.20.1.17:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742207_1383, duration(ns): 1485241
2025-03-26 02:26:34,479 INFO terminating
2025-03-26 02:26:34,479 INFO terminating
2025-03-26 02:26:34,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1384, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:26:34,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742208_1384 src: /172.20.1.14:52394 dest: /172.20.1.16:9866
2025-03-26 02:26:34,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742208_1384 src: /172.20.1.16:57960 dest: /172.20.1.17:9866
2025-03-26 02:26:34,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742208_1384 src: /172.20.1.17:48538 dest: /172.20.1.15:9866
2025-03-26 02:26:34,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48538, dest: /172.20.1.15:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742208_1384, duration(ns): 983452
2025-03-26 02:26:34,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742208_1384, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57960, dest: /172.20.1.17:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742208_1384, duration(ns): 1484470
2025-03-26 02:26:34,496 INFO terminating
2025-03-26 02:26:34,497 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52394, dest: /172.20.1.16:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742208_1384, duration(ns): 1674101
2025-03-26 02:26:34,497 INFO terminating
2025-03-26 02:26:34,502 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1385, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_
2025-03-26 02:26:34,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742209_1385 src: /172.20.1.14:38210 dest: /172.20.1.17:9866
2025-03-26 02:26:34,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742209_1385 src: /172.20.1.17:51656 dest: /172.20.1.16:9866
2025-03-26 02:26:34,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742209_1385 src: /172.20.1.16:41478 dest: /172.20.1.15:9866
2025-03-26 02:26:34,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41478, dest: /172.20.1.15:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742209_1385, duration(ns): 920606
2025-03-26 02:26:34,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742209_1385, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51656, dest: /172.20.1.16:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742209_1385, duration(ns): 2363920
2025-03-26 02:26:34,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38210, dest: /172.20.1.17:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742209_1385, duration(ns): 4353729
2025-03-26 02:26:34,511 INFO terminating
2025-03-26 02:26:34,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,513 INFO terminating
2025-03-26 02:26:34,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1386, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_
2025-03-26 02:26:34,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742210_1386 src: /172.20.1.14:38212 dest: /172.20.1.17:9866
2025-03-26 02:26:34,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742210_1386 src: /172.20.1.16:41490 dest: /172.20.1.15:9866
2025-03-26 02:26:34,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742210_1386 src: /172.20.1.17:51672 dest: /172.20.1.16:9866
2025-03-26 02:26:34,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41490, dest: /172.20.1.15:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742210_1386, duration(ns): 1975247
2025-03-26 02:26:34,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51672, dest: /172.20.1.16:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742210_1386, duration(ns): 2133460
2025-03-26 02:26:34,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742210_1386, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,523 INFO terminating
2025-03-26 02:26:34,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38212, dest: /172.20.1.17:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742210_1386, duration(ns): 2541856
2025-03-26 02:26:34,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,525 INFO terminating
2025-03-26 02:26:34,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1387, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_
2025-03-26 02:26:34,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742211_1387 src: /172.20.1.14:48118 dest: /172.20.1.15:9866
2025-03-26 02:26:34,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742211_1387 src: /172.20.1.15:40182 dest: /172.20.1.17:9866
2025-03-26 02:26:34,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742211_1387 src: /172.20.1.17:51688 dest: /172.20.1.16:9866
2025-03-26 02:26:34,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51688, dest: /172.20.1.16:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742211_1387, duration(ns): 832495
2025-03-26 02:26:34,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742211_1387, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48118, dest: /172.20.1.15:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742211_1387, duration(ns): 1637674
2025-03-26 02:26:34,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40182, dest: /172.20.1.17:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742211_1387, duration(ns): 1235459
2025-03-26 02:26:34,533 INFO terminating
2025-03-26 02:26:34,533 INFO terminating
2025-03-26 02:26:34,534 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1388, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_
2025-03-26 02:26:34,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742212_1388 src: /172.20.1.14:48124 dest: /172.20.1.15:9866
2025-03-26 02:26:34,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742212_1388 src: /172.20.1.15:40184 dest: /172.20.1.17:9866
2025-03-26 02:26:34,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742212_1388 src: /172.20.1.17:51704 dest: /172.20.1.16:9866
2025-03-26 02:26:34,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51704, dest: /172.20.1.16:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742212_1388, duration(ns): 802694
2025-03-26 02:26:34,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742212_1388, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48124, dest: /172.20.1.15:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742212_1388, duration(ns): 2162808
2025-03-26 02:26:34,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40184, dest: /172.20.1.17:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742212_1388, duration(ns): 1103601
2025-03-26 02:26:34,542 INFO terminating
2025-03-26 02:26:34,542 INFO terminating
2025-03-26 02:26:34,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1389, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:26:34,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742213_1389 src: /172.20.1.14:48132 dest: /172.20.1.15:9866
2025-03-26 02:26:34,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742213_1389 src: /172.20.1.15:59900 dest: /172.20.1.16:9866
2025-03-26 02:26:34,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742213_1389 src: /172.20.1.16:57974 dest: /172.20.1.17:9866
2025-03-26 02:26:34,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57974, dest: /172.20.1.17:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742213_1389, duration(ns): 900298
2025-03-26 02:26:34,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742213_1389, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48132, dest: /172.20.1.15:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742213_1389, duration(ns): 4950989
2025-03-26 02:26:34,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59900, dest: /172.20.1.16:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742213_1389, duration(ns): 4648178
2025-03-26 02:26:34,558 INFO terminating
2025-03-26 02:26:34,558 INFO terminating
2025-03-26 02:26:34,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1390, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_
2025-03-26 02:26:34,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742214_1390 src: /172.20.1.14:38224 dest: /172.20.1.17:9866
2025-03-26 02:26:34,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742214_1390 src: /172.20.1.17:51718 dest: /172.20.1.16:9866
2025-03-26 02:26:34,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742214_1390 src: /172.20.1.16:41498 dest: /172.20.1.15:9866
2025-03-26 02:26:34,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41498, dest: /172.20.1.15:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742214_1390, duration(ns): 1032194
2025-03-26 02:26:34,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742214_1390, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51718, dest: /172.20.1.16:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742214_1390, duration(ns): 1439762
2025-03-26 02:26:34,568 INFO terminating
2025-03-26 02:26:34,570 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38224, dest: /172.20.1.17:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742214_1390, duration(ns): 2054582
2025-03-26 02:26:34,570 INFO terminating
2025-03-26 02:26:34,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1391, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_
2025-03-26 02:26:34,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742215_1391 src: /172.20.1.14:48142 dest: /172.20.1.15:9866
2025-03-26 02:26:34,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742215_1391 src: /172.20.1.15:59910 dest: /172.20.1.16:9866
2025-03-26 02:26:34,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742215_1391 src: /172.20.1.16:57986 dest: /172.20.1.17:9866
2025-03-26 02:26:34,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57986, dest: /172.20.1.17:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742215_1391, duration(ns): 720075
2025-03-26 02:26:34,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742215_1391, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59910, dest: /172.20.1.16:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742215_1391, duration(ns): 1081534
2025-03-26 02:26:34,579 INFO terminating
2025-03-26 02:26:34,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48142, dest: /172.20.1.15:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742215_1391, duration(ns): 2089528
2025-03-26 02:26:34,580 INFO terminating
2025-03-26 02:26:34,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1392, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_
2025-03-26 02:26:34,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742216_1392 src: /172.20.1.14:38238 dest: /172.20.1.17:9866
2025-03-26 02:26:34,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742216_1392 src: /172.20.1.17:48540 dest: /172.20.1.15:9866
2025-03-26 02:26:34,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742216_1392 src: /172.20.1.15:59916 dest: /172.20.1.16:9866
2025-03-26 02:26:34,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59916, dest: /172.20.1.16:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742216_1392, duration(ns): 847693
2025-03-26 02:26:34,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742216_1392, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,589 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38238, dest: /172.20.1.17:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742216_1392, duration(ns): 1945962
2025-03-26 02:26:34,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48540, dest: /172.20.1.15:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742216_1392, duration(ns): 1610959
2025-03-26 02:26:34,589 INFO terminating
2025-03-26 02:26:34,589 INFO terminating
2025-03-26 02:26:34,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1393, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_
2025-03-26 02:26:34,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742217_1393 src: /172.20.1.14:52410 dest: /172.20.1.16:9866
2025-03-26 02:26:34,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742217_1393 src: /172.20.1.16:57990 dest: /172.20.1.17:9866
2025-03-26 02:26:34,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742217_1393 src: /172.20.1.17:48542 dest: /172.20.1.15:9866
2025-03-26 02:26:34,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48542, dest: /172.20.1.15:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742217_1393, duration(ns): 1980690
2025-03-26 02:26:34,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742217_1393, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:57990, dest: /172.20.1.17:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742217_1393, duration(ns): 2406355
2025-03-26 02:26:34,599 INFO terminating
2025-03-26 02:26:34,600 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52410, dest: /172.20.1.16:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742217_1393, duration(ns): 2704674
2025-03-26 02:26:34,600 INFO terminating
2025-03-26 02:26:34,605 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1394, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_
2025-03-26 02:26:34,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742218_1394 src: /172.20.1.14:48150 dest: /172.20.1.15:9866
2025-03-26 02:26:34,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742218_1394 src: /172.20.1.15:40190 dest: /172.20.1.17:9866
2025-03-26 02:26:34,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742218_1394 src: /172.20.1.17:51732 dest: /172.20.1.16:9866
2025-03-26 02:26:34,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51732, dest: /172.20.1.16:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742218_1394, duration(ns): 824652
2025-03-26 02:26:34,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742218_1394, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48150, dest: /172.20.1.15:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742218_1394, duration(ns): 1680173
2025-03-26 02:26:34,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40190, dest: /172.20.1.17:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742218_1394, duration(ns): 1076090
2025-03-26 02:26:34,611 INFO terminating
2025-03-26 02:26:34,611 INFO terminating
2025-03-26 02:26:34,612 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1395, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_
2025-03-26 02:26:34,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742219_1395 src: /172.20.1.14:52426 dest: /172.20.1.16:9866
2025-03-26 02:26:34,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742219_1395 src: /172.20.1.16:58002 dest: /172.20.1.17:9866
2025-03-26 02:26:34,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742219_1395 src: /172.20.1.17:48548 dest: /172.20.1.15:9866
2025-03-26 02:26:34,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58002, dest: /172.20.1.17:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742219_1395, duration(ns): 1398042
2025-03-26 02:26:34,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48548, dest: /172.20.1.15:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742219_1395, duration(ns): 981820
2025-03-26 02:26:34,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742219_1395, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,621 INFO terminating
2025-03-26 02:26:34,622 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52426, dest: /172.20.1.16:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742219_1395, duration(ns): 1842365
2025-03-26 02:26:34,622 INFO terminating
2025-03-26 02:26:34,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1396, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_
2025-03-26 02:26:34,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742220_1396 src: /172.20.1.14:52428 dest: /172.20.1.16:9866
2025-03-26 02:26:34,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742220_1396 src: /172.20.1.16:41510 dest: /172.20.1.15:9866
2025-03-26 02:26:34,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742220_1396 src: /172.20.1.15:40200 dest: /172.20.1.17:9866
2025-03-26 02:26:34,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40200, dest: /172.20.1.17:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742220_1396, duration(ns): 1087355
2025-03-26 02:26:34,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742220_1396, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52428, dest: /172.20.1.16:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742220_1396, duration(ns): 1982658
2025-03-26 02:26:34,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41510, dest: /172.20.1.15:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742220_1396, duration(ns): 1400480
2025-03-26 02:26:34,632 INFO terminating
2025-03-26 02:26:34,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,633 INFO terminating
2025-03-26 02:26:34,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1397, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_
2025-03-26 02:26:34,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742221_1397 src: /172.20.1.14:52430 dest: /172.20.1.16:9866
2025-03-26 02:26:34,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742221_1397 src: /172.20.1.16:58010 dest: /172.20.1.17:9866
2025-03-26 02:26:34,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742221_1397 src: /172.20.1.17:48552 dest: /172.20.1.15:9866
2025-03-26 02:26:34,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48552, dest: /172.20.1.15:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742221_1397, duration(ns): 767390
2025-03-26 02:26:34,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742221_1397, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52430, dest: /172.20.1.16:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742221_1397, duration(ns): 1759270
2025-03-26 02:26:34,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58010, dest: /172.20.1.17:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742221_1397, duration(ns): 1303821
2025-03-26 02:26:34,643 INFO terminating
2025-03-26 02:26:34,643 INFO terminating
2025-03-26 02:26:34,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1398, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_
2025-03-26 02:26:34,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742222_1398 src: /172.20.1.14:52434 dest: /172.20.1.16:9866
2025-03-26 02:26:34,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742222_1398 src: /172.20.1.16:58020 dest: /172.20.1.17:9866
2025-03-26 02:26:34,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742222_1398 src: /172.20.1.17:48556 dest: /172.20.1.15:9866
2025-03-26 02:26:34,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58020, dest: /172.20.1.17:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742222_1398, duration(ns): 1314011
2025-03-26 02:26:34,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48556, dest: /172.20.1.15:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742222_1398, duration(ns): 633530
2025-03-26 02:26:34,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742222_1398, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,656 INFO terminating
2025-03-26 02:26:34,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52434, dest: /172.20.1.16:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742222_1398, duration(ns): 1932631
2025-03-26 02:26:34,658 INFO terminating
2025-03-26 02:26:34,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1399, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_
2025-03-26 02:26:34,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742223_1399 src: /172.20.1.14:48156 dest: /172.20.1.15:9866
2025-03-26 02:26:34,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742223_1399 src: /172.20.1.15:40216 dest: /172.20.1.17:9866
2025-03-26 02:26:34,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742223_1399 src: /172.20.1.17:51746 dest: /172.20.1.16:9866
2025-03-26 02:26:34,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51746, dest: /172.20.1.16:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742223_1399, duration(ns): 842219
2025-03-26 02:26:34,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742223_1399, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48156, dest: /172.20.1.15:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742223_1399, duration(ns): 1561374
2025-03-26 02:26:34,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40216, dest: /172.20.1.17:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742223_1399, duration(ns): 1105011
2025-03-26 02:26:34,667 INFO terminating
2025-03-26 02:26:34,667 INFO terminating
2025-03-26 02:26:34,668 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1400, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_
2025-03-26 02:26:34,671 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,671 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742224_1400 src: /172.20.1.14:52446 dest: /172.20.1.16:9866
2025-03-26 02:26:34,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742224_1400 src: /172.20.1.15:40232 dest: /172.20.1.17:9866
2025-03-26 02:26:34,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742224_1400 src: /172.20.1.16:41524 dest: /172.20.1.15:9866
2025-03-26 02:26:34,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40232, dest: /172.20.1.17:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742224_1400, duration(ns): 3509632
2025-03-26 02:26:34,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41524, dest: /172.20.1.15:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742224_1400, duration(ns): 4750275
2025-03-26 02:26:34,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742224_1400, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,680 INFO terminating
2025-03-26 02:26:34,681 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52446, dest: /172.20.1.16:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742224_1400, duration(ns): 5307555
2025-03-26 02:26:34,681 INFO terminating
2025-03-26 02:26:34,684 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1401, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_
2025-03-26 02:26:34,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742225_1401 src: /172.20.1.14:48172 dest: /172.20.1.15:9866
2025-03-26 02:26:34,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742225_1401 src: /172.20.1.15:40238 dest: /172.20.1.17:9866
2025-03-26 02:26:34,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742225_1401 src: /172.20.1.17:51750 dest: /172.20.1.16:9866
2025-03-26 02:26:34,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40238, dest: /172.20.1.17:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742225_1401, duration(ns): 1131338
2025-03-26 02:26:34,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51750, dest: /172.20.1.16:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742225_1401, duration(ns): 883036
2025-03-26 02:26:34,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742225_1401, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,689 INFO terminating
2025-03-26 02:26:34,690 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48172, dest: /172.20.1.15:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742225_1401, duration(ns): 1452139
2025-03-26 02:26:34,690 INFO terminating
2025-03-26 02:26:34,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1402, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_
2025-03-26 02:26:34,693 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,693 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742226_1402 src: /172.20.1.14:52450 dest: /172.20.1.16:9866
2025-03-26 02:26:34,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742226_1402 src: /172.20.1.16:58022 dest: /172.20.1.17:9866
2025-03-26 02:26:34,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742226_1402 src: /172.20.1.17:48568 dest: /172.20.1.15:9866
2025-03-26 02:26:34,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58022, dest: /172.20.1.17:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742226_1402, duration(ns): 1204531
2025-03-26 02:26:34,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48568, dest: /172.20.1.15:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742226_1402, duration(ns): 865591
2025-03-26 02:26:34,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742226_1402, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,699 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52450, dest: /172.20.1.16:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742226_1402, duration(ns): 1928866
2025-03-26 02:26:34,699 INFO terminating
2025-03-26 02:26:34,700 INFO terminating
2025-03-26 02:26:34,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1403, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_
2025-03-26 02:26:34,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742227_1403 src: /172.20.1.14:38250 dest: /172.20.1.17:9866
2025-03-26 02:26:34,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742227_1403 src: /172.20.1.17:51752 dest: /172.20.1.16:9866
2025-03-26 02:26:34,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742227_1403 src: /172.20.1.16:41530 dest: /172.20.1.15:9866
2025-03-26 02:26:34,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38250, dest: /172.20.1.17:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742227_1403, duration(ns): 1518228
2025-03-26 02:26:34,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41530, dest: /172.20.1.15:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742227_1403, duration(ns): 864788
2025-03-26 02:26:34,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51752, dest: /172.20.1.16:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742227_1403, duration(ns): 1319271
2025-03-26 02:26:34,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742227_1403, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,707 INFO terminating
2025-03-26 02:26:34,708 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,708 INFO terminating
2025-03-26 02:26:34,711 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1404, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_
2025-03-26 02:26:34,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742228_1404 src: /172.20.1.14:38258 dest: /172.20.1.17:9866
2025-03-26 02:26:34,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742228_1404 src: /172.20.1.17:51756 dest: /172.20.1.16:9866
2025-03-26 02:26:34,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742228_1404 src: /172.20.1.16:41534 dest: /172.20.1.15:9866
2025-03-26 02:26:34,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41534, dest: /172.20.1.15:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742228_1404, duration(ns): 796843
2025-03-26 02:26:34,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51756, dest: /172.20.1.16:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742228_1404, duration(ns): 1225604
2025-03-26 02:26:34,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742228_1404, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,715 INFO terminating
2025-03-26 02:26:34,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38258, dest: /172.20.1.17:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742228_1404, duration(ns): 1483369
2025-03-26 02:26:34,716 INFO terminating
2025-03-26 02:26:34,717 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1405, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_
2025-03-26 02:26:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742229_1405 src: /172.20.1.14:48174 dest: /172.20.1.15:9866
2025-03-26 02:26:34,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742229_1405 src: /172.20.1.15:40250 dest: /172.20.1.17:9866
2025-03-26 02:26:34,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742229_1405 src: /172.20.1.17:51758 dest: /172.20.1.16:9866
2025-03-26 02:26:34,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40250, dest: /172.20.1.17:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742229_1405, duration(ns): 5509901
2025-03-26 02:26:34,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51758, dest: /172.20.1.16:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742229_1405, duration(ns): 5313275
2025-03-26 02:26:34,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742229_1405, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,735 INFO terminating
2025-03-26 02:26:34,736 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48174, dest: /172.20.1.15:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742229_1405, duration(ns): 5769227
2025-03-26 02:26:34,736 INFO terminating
2025-03-26 02:26:34,741 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1406, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_
2025-03-26 02:26:34,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742230_1406 src: /172.20.1.14:52458 dest: /172.20.1.16:9866
2025-03-26 02:26:34,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742230_1406 src: /172.20.1.16:58024 dest: /172.20.1.17:9866
2025-03-26 02:26:34,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742230_1406 src: /172.20.1.17:48574 dest: /172.20.1.15:9866
2025-03-26 02:26:34,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58024, dest: /172.20.1.17:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742230_1406, duration(ns): 1452896
2025-03-26 02:26:34,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48574, dest: /172.20.1.15:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742230_1406, duration(ns): 936048
2025-03-26 02:26:34,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742230_1406, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,746 INFO terminating
2025-03-26 02:26:34,747 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52458, dest: /172.20.1.16:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742230_1406, duration(ns): 1807124
2025-03-26 02:26:34,747 INFO terminating
2025-03-26 02:26:34,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1407, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_
2025-03-26 02:26:34,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742231_1407 src: /172.20.1.14:48176 dest: /172.20.1.15:9866
2025-03-26 02:26:34,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742231_1407 src: /172.20.1.15:40266 dest: /172.20.1.17:9866
2025-03-26 02:26:34,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742231_1407 src: /172.20.1.17:51774 dest: /172.20.1.16:9866
2025-03-26 02:26:34,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51774, dest: /172.20.1.16:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742231_1407, duration(ns): 941719
2025-03-26 02:26:34,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742231_1407, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40266, dest: /172.20.1.17:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742231_1407, duration(ns): 1252500
2025-03-26 02:26:34,760 INFO terminating
2025-03-26 02:26:34,761 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48176, dest: /172.20.1.15:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742231_1407, duration(ns): 2062033
2025-03-26 02:26:34,761 INFO terminating
2025-03-26 02:26:34,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1408, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_
2025-03-26 02:26:34,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742232_1408 src: /172.20.1.14:48192 dest: /172.20.1.15:9866
2025-03-26 02:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742232_1408 src: /172.20.1.15:40274 dest: /172.20.1.17:9866
2025-03-26 02:26:34,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742232_1408 src: /172.20.1.17:51788 dest: /172.20.1.16:9866
2025-03-26 02:26:34,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40274, dest: /172.20.1.17:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742232_1408, duration(ns): 13683901
2025-03-26 02:26:34,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51788, dest: /172.20.1.16:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742232_1408, duration(ns): 767880
2025-03-26 02:26:34,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742232_1408, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,782 INFO terminating
2025-03-26 02:26:34,783 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48192, dest: /172.20.1.15:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742232_1408, duration(ns): 13949028
2025-03-26 02:26:34,783 INFO terminating
2025-03-26 02:26:34,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1409, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_
2025-03-26 02:26:34,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742233_1409 src: /172.20.1.14:38260 dest: /172.20.1.17:9866
2025-03-26 02:26:34,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742233_1409 src: /172.20.1.17:48580 dest: /172.20.1.15:9866
2025-03-26 02:26:34,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742233_1409 src: /172.20.1.15:59930 dest: /172.20.1.16:9866
2025-03-26 02:26:34,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59930, dest: /172.20.1.16:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742233_1409, duration(ns): 917759
2025-03-26 02:26:34,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742233_1409, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38260, dest: /172.20.1.17:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742233_1409, duration(ns): 1708150
2025-03-26 02:26:34,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48580, dest: /172.20.1.15:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742233_1409, duration(ns): 1306799
2025-03-26 02:26:34,797 INFO terminating
2025-03-26 02:26:34,797 INFO terminating
2025-03-26 02:26:34,798 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1410, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_
2025-03-26 02:26:34,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742234_1410 src: /172.20.1.14:38262 dest: /172.20.1.17:9866
2025-03-26 02:26:34,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742234_1410 src: /172.20.1.17:51790 dest: /172.20.1.16:9866
2025-03-26 02:26:34,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742234_1410 src: /172.20.1.16:41542 dest: /172.20.1.15:9866
2025-03-26 02:26:34,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41542, dest: /172.20.1.15:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742234_1410, duration(ns): 4174897
2025-03-26 02:26:34,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51790, dest: /172.20.1.16:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742234_1410, duration(ns): 4627548
2025-03-26 02:26:34,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742234_1410, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,810 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38262, dest: /172.20.1.17:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742234_1410, duration(ns): 4953739
2025-03-26 02:26:34,810 INFO terminating
2025-03-26 02:26:34,810 INFO terminating
2025-03-26 02:26:34,813 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1411, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_
2025-03-26 02:26:34,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742235_1411 src: /172.20.1.14:38268 dest: /172.20.1.17:9866
2025-03-26 02:26:34,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742235_1411 src: /172.20.1.17:48592 dest: /172.20.1.15:9866
2025-03-26 02:26:34,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742235_1411 src: /172.20.1.15:59946 dest: /172.20.1.16:9866
2025-03-26 02:26:34,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59946, dest: /172.20.1.16:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742235_1411, duration(ns): 741175
2025-03-26 02:26:34,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742235_1411, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38268, dest: /172.20.1.17:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742235_1411, duration(ns): 1505207
2025-03-26 02:26:34,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48592, dest: /172.20.1.15:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742235_1411, duration(ns): 1013647
2025-03-26 02:26:34,818 INFO terminating
2025-03-26 02:26:34,819 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,819 INFO terminating
2025-03-26 02:26:34,827 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1412, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_
2025-03-26 02:26:34,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742236_1412 src: /172.20.1.14:52468 dest: /172.20.1.16:9866
2025-03-26 02:26:34,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742236_1412 src: /172.20.1.16:41558 dest: /172.20.1.15:9866
2025-03-26 02:26:34,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742236_1412 src: /172.20.1.15:40290 dest: /172.20.1.17:9866
2025-03-26 02:26:34,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40290, dest: /172.20.1.17:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742236_1412, duration(ns): 768579
2025-03-26 02:26:34,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41558, dest: /172.20.1.15:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742236_1412, duration(ns): 1136383
2025-03-26 02:26:34,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742236_1412, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,832 INFO terminating
2025-03-26 02:26:34,833 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52468, dest: /172.20.1.16:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742236_1412, duration(ns): 1705675
2025-03-26 02:26:34,833 INFO terminating
2025-03-26 02:26:34,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1413, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_
2025-03-26 02:26:34,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742237_1413 src: /172.20.1.14:52470 dest: /172.20.1.16:9866
2025-03-26 02:26:34,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742237_1413 src: /172.20.1.16:58040 dest: /172.20.1.17:9866
2025-03-26 02:26:34,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742237_1413 src: /172.20.1.17:48594 dest: /172.20.1.15:9866
2025-03-26 02:26:34,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48594, dest: /172.20.1.15:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742237_1413, duration(ns): 1610115
2025-03-26 02:26:34,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742237_1413, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52470, dest: /172.20.1.16:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742237_1413, duration(ns): 2357283
2025-03-26 02:26:34,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58040, dest: /172.20.1.17:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742237_1413, duration(ns): 2030329
2025-03-26 02:26:34,843 INFO terminating
2025-03-26 02:26:34,844 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,844 INFO terminating
2025-03-26 02:26:34,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1414, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_
2025-03-26 02:26:34,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742238_1414 src: /172.20.1.14:52472 dest: /172.20.1.16:9866
2025-03-26 02:26:34,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742238_1414 src: /172.20.1.15:40302 dest: /172.20.1.17:9866
2025-03-26 02:26:34,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742238_1414 src: /172.20.1.16:41566 dest: /172.20.1.15:9866
2025-03-26 02:26:34,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40302, dest: /172.20.1.17:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742238_1414, duration(ns): 714691
2025-03-26 02:26:34,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41566, dest: /172.20.1.15:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742238_1414, duration(ns): 986783
2025-03-26 02:26:34,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742238_1414, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,851 INFO terminating
2025-03-26 02:26:34,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52472, dest: /172.20.1.16:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742238_1414, duration(ns): 1586262
2025-03-26 02:26:34,852 INFO terminating
2025-03-26 02:26:34,853 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1415, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:26:34,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742239_1415 src: /172.20.1.14:52476 dest: /172.20.1.16:9866
2025-03-26 02:26:34,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742239_1415 src: /172.20.1.16:58042 dest: /172.20.1.17:9866
2025-03-26 02:26:34,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742239_1415 src: /172.20.1.17:48596 dest: /172.20.1.15:9866
2025-03-26 02:26:34,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58042, dest: /172.20.1.17:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742239_1415, duration(ns): 1126025
2025-03-26 02:26:34,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48596, dest: /172.20.1.15:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742239_1415, duration(ns): 699719
2025-03-26 02:26:34,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742239_1415, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,863 INFO terminating
2025-03-26 02:26:34,864 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52476, dest: /172.20.1.16:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742239_1415, duration(ns): 1424902
2025-03-26 02:26:34,864 INFO terminating
2025-03-26 02:26:34,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1416, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_
2025-03-26 02:26:34,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742240_1416 src: /172.20.1.14:52490 dest: /172.20.1.16:9866
2025-03-26 02:26:34,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742240_1416 src: /172.20.1.16:41582 dest: /172.20.1.15:9866
2025-03-26 02:26:34,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742240_1416 src: /172.20.1.15:40318 dest: /172.20.1.17:9866
2025-03-26 02:26:34,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40318, dest: /172.20.1.17:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742240_1416, duration(ns): 684703
2025-03-26 02:26:34,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41582, dest: /172.20.1.15:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742240_1416, duration(ns): 828607
2025-03-26 02:26:34,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742240_1416, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,874 INFO terminating
2025-03-26 02:26:34,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52490, dest: /172.20.1.16:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742240_1416, duration(ns): 1487853
2025-03-26 02:26:34,875 INFO terminating
2025-03-26 02:26:34,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1417, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_
2025-03-26 02:26:34,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742241_1417 src: /172.20.1.14:38280 dest: /172.20.1.17:9866
2025-03-26 02:26:34,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742241_1417 src: /172.20.1.17:48604 dest: /172.20.1.15:9866
2025-03-26 02:26:34,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742241_1417 src: /172.20.1.15:59962 dest: /172.20.1.16:9866
2025-03-26 02:26:34,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59962, dest: /172.20.1.16:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742241_1417, duration(ns): 714136
2025-03-26 02:26:34,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742241_1417, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38280, dest: /172.20.1.17:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742241_1417, duration(ns): 1507314
2025-03-26 02:26:34,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48604, dest: /172.20.1.15:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742241_1417, duration(ns): 959147
2025-03-26 02:26:34,883 INFO terminating
2025-03-26 02:26:34,883 INFO terminating
2025-03-26 02:26:34,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1418, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_
2025-03-26 02:26:34,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742242_1418 src: /172.20.1.14:48204 dest: /172.20.1.15:9866
2025-03-26 02:26:34,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742242_1418 src: /172.20.1.15:59972 dest: /172.20.1.16:9866
2025-03-26 02:26:34,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742242_1418 src: /172.20.1.16:58058 dest: /172.20.1.17:9866
2025-03-26 02:26:34,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59972, dest: /172.20.1.16:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742242_1418, duration(ns): 918429
2025-03-26 02:26:34,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58058, dest: /172.20.1.17:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742242_1418, duration(ns): 642976
2025-03-26 02:26:34,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742242_1418, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48204, dest: /172.20.1.15:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742242_1418, duration(ns): 1403884
2025-03-26 02:26:34,893 INFO terminating
2025-03-26 02:26:34,893 INFO terminating
2025-03-26 02:26:34,894 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,902 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1419, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_
2025-03-26 02:26:34,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742243_1419 src: /172.20.1.14:38292 dest: /172.20.1.17:9866
2025-03-26 02:26:34,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742243_1419 src: /172.20.1.17:51794 dest: /172.20.1.16:9866
2025-03-26 02:26:34,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742243_1419 src: /172.20.1.16:41588 dest: /172.20.1.15:9866
2025-03-26 02:26:34,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41588, dest: /172.20.1.15:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742243_1419, duration(ns): 724477
2025-03-26 02:26:34,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51794, dest: /172.20.1.16:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742243_1419, duration(ns): 1126662
2025-03-26 02:26:34,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742243_1419, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38292, dest: /172.20.1.17:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742243_1419, duration(ns): 1481628
2025-03-26 02:26:34,907 INFO terminating
2025-03-26 02:26:34,907 INFO terminating
2025-03-26 02:26:34,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1420, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_
2025-03-26 02:26:34,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742244_1420 src: /172.20.1.14:52494 dest: /172.20.1.16:9866
2025-03-26 02:26:34,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742244_1420 src: /172.20.1.16:58070 dest: /172.20.1.17:9866
2025-03-26 02:26:34,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742244_1420 src: /172.20.1.17:48606 dest: /172.20.1.15:9866
2025-03-26 02:26:34,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58070, dest: /172.20.1.17:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742244_1420, duration(ns): 1275832
2025-03-26 02:26:34,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48606, dest: /172.20.1.15:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742244_1420, duration(ns): 792139
2025-03-26 02:26:34,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742244_1420, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,918 INFO terminating
2025-03-26 02:26:34,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52494, dest: /172.20.1.16:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742244_1420, duration(ns): 1605124
2025-03-26 02:26:34,919 INFO terminating
2025-03-26 02:26:34,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1421, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_
2025-03-26 02:26:34,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742245_1421 src: /172.20.1.14:52496 dest: /172.20.1.16:9866
2025-03-26 02:26:34,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742245_1421 src: /172.20.1.16:41600 dest: /172.20.1.15:9866
2025-03-26 02:26:34,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742245_1421 src: /172.20.1.15:40334 dest: /172.20.1.17:9866
2025-03-26 02:26:34,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40334, dest: /172.20.1.17:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742245_1421, duration(ns): 724406
2025-03-26 02:26:34,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742245_1421, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52496, dest: /172.20.1.16:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742245_1421, duration(ns): 1549480
2025-03-26 02:26:34,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41600, dest: /172.20.1.15:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742245_1421, duration(ns): 989427
2025-03-26 02:26:34,928 INFO terminating
2025-03-26 02:26:34,928 INFO terminating
2025-03-26 02:26:34,929 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,934 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1422, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_
2025-03-26 02:26:34,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742246_1422 src: /172.20.1.14:52498 dest: /172.20.1.16:9866
2025-03-26 02:26:34,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742246_1422 src: /172.20.1.16:41606 dest: /172.20.1.15:9866
2025-03-26 02:26:34,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742246_1422 src: /172.20.1.15:40344 dest: /172.20.1.17:9866
2025-03-26 02:26:34,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40344, dest: /172.20.1.17:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742246_1422, duration(ns): 651269
2025-03-26 02:26:34,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742246_1422, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52498, dest: /172.20.1.16:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742246_1422, duration(ns): 1491340
2025-03-26 02:26:34,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41606, dest: /172.20.1.15:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742246_1422, duration(ns): 925186
2025-03-26 02:26:34,941 INFO terminating
2025-03-26 02:26:34,941 INFO terminating
2025-03-26 02:26:34,942 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1423, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_
2025-03-26 02:26:34,944 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,944 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742247_1423 src: /172.20.1.14:38304 dest: /172.20.1.17:9866
2025-03-26 02:26:34,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742247_1423 src: /172.20.1.17:51802 dest: /172.20.1.16:9866
2025-03-26 02:26:34,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742247_1423 src: /172.20.1.16:41614 dest: /172.20.1.15:9866
2025-03-26 02:26:34,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41614, dest: /172.20.1.15:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742247_1423, duration(ns): 668836
2025-03-26 02:26:34,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742247_1423, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51802, dest: /172.20.1.16:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742247_1423, duration(ns): 1104416
2025-03-26 02:26:34,950 INFO terminating
2025-03-26 02:26:34,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38304, dest: /172.20.1.17:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742247_1423, duration(ns): 2800991
2025-03-26 02:26:34,951 INFO terminating
2025-03-26 02:26:34,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1424, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_
2025-03-26 02:26:34,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742248_1424 src: /172.20.1.14:48216 dest: /172.20.1.15:9866
2025-03-26 02:26:34,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742248_1424 src: /172.20.1.15:59986 dest: /172.20.1.16:9866
2025-03-26 02:26:34,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742248_1424 src: /172.20.1.16:58078 dest: /172.20.1.17:9866
2025-03-26 02:26:34,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58078, dest: /172.20.1.17:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742248_1424, duration(ns): 741133
2025-03-26 02:26:34,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742248_1424, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48216, dest: /172.20.1.15:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742248_1424, duration(ns): 1311965
2025-03-26 02:26:34,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59986, dest: /172.20.1.16:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742248_1424, duration(ns): 1029590
2025-03-26 02:26:34,959 INFO terminating
2025-03-26 02:26:34,959 INFO terminating
2025-03-26 02:26:34,960 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1425, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_
2025-03-26 02:26:34,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742249_1425 src: /172.20.1.14:52502 dest: /172.20.1.16:9866
2025-03-26 02:26:34,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742249_1425 src: /172.20.1.16:41618 dest: /172.20.1.15:9866
2025-03-26 02:26:34,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742249_1425 src: /172.20.1.15:40360 dest: /172.20.1.17:9866
2025-03-26 02:26:34,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52502, dest: /172.20.1.16:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742249_1425, duration(ns): 1648815
2025-03-26 02:26:34,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40360, dest: /172.20.1.17:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742249_1425, duration(ns): 659609
2025-03-26 02:26:34,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41618, dest: /172.20.1.15:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742249_1425, duration(ns): 1208729
2025-03-26 02:26:34,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742249_1425, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,967 INFO terminating
2025-03-26 02:26:34,967 INFO terminating
2025-03-26 02:26:34,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1426, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:26:34,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742250_1426 src: /172.20.1.14:52514 dest: /172.20.1.16:9866
2025-03-26 02:26:34,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742250_1426 src: /172.20.1.16:58080 dest: /172.20.1.17:9866
2025-03-26 02:26:34,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742250_1426 src: /172.20.1.17:48622 dest: /172.20.1.15:9866
2025-03-26 02:26:34,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48622, dest: /172.20.1.15:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742250_1426, duration(ns): 1043138
2025-03-26 02:26:34,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742250_1426, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52514, dest: /172.20.1.16:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742250_1426, duration(ns): 2110188
2025-03-26 02:26:34,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58080, dest: /172.20.1.17:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742250_1426, duration(ns): 1504801
2025-03-26 02:26:34,976 INFO terminating
2025-03-26 02:26:34,976 INFO terminating
2025-03-26 02:26:34,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,979 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1427, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_
2025-03-26 02:26:34,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742251_1427 src: /172.20.1.14:48224 dest: /172.20.1.15:9866
2025-03-26 02:26:34,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742251_1427 src: /172.20.1.15:59996 dest: /172.20.1.16:9866
2025-03-26 02:26:34,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742251_1427 src: /172.20.1.16:58096 dest: /172.20.1.17:9866
2025-03-26 02:26:34,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58096, dest: /172.20.1.17:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742251_1427, duration(ns): 671245
2025-03-26 02:26:34,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742251_1427, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48224, dest: /172.20.1.15:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742251_1427, duration(ns): 1260191
2025-03-26 02:26:34,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:59996, dest: /172.20.1.16:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742251_1427, duration(ns): 1041855
2025-03-26 02:26:34,984 INFO terminating
2025-03-26 02:26:34,984 INFO terminating
2025-03-26 02:26:34,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:34,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1428, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_
2025-03-26 02:26:34,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742252_1428 src: /172.20.1.14:52528 dest: /172.20.1.16:9866
2025-03-26 02:26:34,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742252_1428 src: /172.20.1.16:41632 dest: /172.20.1.15:9866
2025-03-26 02:26:34,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742252_1428 src: /172.20.1.15:40374 dest: /172.20.1.17:9866
2025-03-26 02:26:34,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40374, dest: /172.20.1.17:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742252_1428, duration(ns): 828062
2025-03-26 02:26:34,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41632, dest: /172.20.1.15:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742252_1428, duration(ns): 1577212
2025-03-26 02:26:34,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742252_1428, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:34,996 INFO terminating
2025-03-26 02:26:35,001 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52528, dest: /172.20.1.16:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742252_1428, duration(ns): 2154655
2025-03-26 02:26:35,001 INFO terminating
2025-03-26 02:26:35,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1429, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_
2025-03-26 02:26:35,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742253_1429 src: /172.20.1.14:48236 dest: /172.20.1.15:9866
2025-03-26 02:26:35,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742253_1429 src: /172.20.1.15:60004 dest: /172.20.1.16:9866
2025-03-26 02:26:35,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742253_1429 src: /172.20.1.16:58106 dest: /172.20.1.17:9866
2025-03-26 02:26:35,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60004, dest: /172.20.1.16:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742253_1429, duration(ns): 1179348
2025-03-26 02:26:35,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58106, dest: /172.20.1.17:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742253_1429, duration(ns): 857763
2025-03-26 02:26:35,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742253_1429, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,011 INFO terminating
2025-03-26 02:26:35,012 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48236, dest: /172.20.1.15:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742253_1429, duration(ns): 1536701
2025-03-26 02:26:35,012 INFO terminating
2025-03-26 02:26:35,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1430, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_
2025-03-26 02:26:35,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742254_1430 src: /172.20.1.14:48242 dest: /172.20.1.15:9866
2025-03-26 02:26:35,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742254_1430 src: /172.20.1.15:40382 dest: /172.20.1.17:9866
2025-03-26 02:26:35,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742254_1430 src: /172.20.1.17:51810 dest: /172.20.1.16:9866
2025-03-26 02:26:35,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40382, dest: /172.20.1.17:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742254_1430, duration(ns): 1352733
2025-03-26 02:26:35,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51810, dest: /172.20.1.16:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742254_1430, duration(ns): 867887
2025-03-26 02:26:35,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742254_1430, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48242, dest: /172.20.1.15:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742254_1430, duration(ns): 1602165
2025-03-26 02:26:35,021 INFO terminating
2025-03-26 02:26:35,021 INFO terminating
2025-03-26 02:26:35,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1431, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_
2025-03-26 02:26:35,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742255_1431 src: /172.20.1.14:38308 dest: /172.20.1.17:9866
2025-03-26 02:26:35,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742255_1431 src: /172.20.1.16:41646 dest: /172.20.1.15:9866
2025-03-26 02:26:35,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742255_1431 src: /172.20.1.17:51818 dest: /172.20.1.16:9866
2025-03-26 02:26:35,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41646, dest: /172.20.1.15:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742255_1431, duration(ns): 892003
2025-03-26 02:26:35,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742255_1431, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51818, dest: /172.20.1.16:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742255_1431, duration(ns): 1401881
2025-03-26 02:26:35,042 INFO terminating
2025-03-26 02:26:35,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38308, dest: /172.20.1.17:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742255_1431, duration(ns): 5094823
2025-03-26 02:26:35,049 INFO terminating
2025-03-26 02:26:35,050 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1432, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_
2025-03-26 02:26:35,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742256_1432 src: /172.20.1.14:48250 dest: /172.20.1.15:9866
2025-03-26 02:26:35,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742256_1432 src: /172.20.1.15:60020 dest: /172.20.1.16:9866
2025-03-26 02:26:35,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742256_1432 src: /172.20.1.16:58114 dest: /172.20.1.17:9866
2025-03-26 02:26:35,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60020, dest: /172.20.1.16:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742256_1432, duration(ns): 984477
2025-03-26 02:26:35,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58114, dest: /172.20.1.17:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742256_1432, duration(ns): 680565
2025-03-26 02:26:35,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742256_1432, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48250, dest: /172.20.1.15:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742256_1432, duration(ns): 1295076
2025-03-26 02:26:35,058 INFO terminating
2025-03-26 02:26:35,058 INFO terminating
2025-03-26 02:26:35,059 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1433, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_
2025-03-26 02:26:35,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742257_1433 src: /172.20.1.14:52536 dest: /172.20.1.16:9866
2025-03-26 02:26:35,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742257_1433 src: /172.20.1.16:58120 dest: /172.20.1.17:9866
2025-03-26 02:26:35,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742257_1433 src: /172.20.1.17:48638 dest: /172.20.1.15:9866
2025-03-26 02:26:35,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48638, dest: /172.20.1.15:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742257_1433, duration(ns): 1014302
2025-03-26 02:26:35,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742257_1433, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52536, dest: /172.20.1.16:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742257_1433, duration(ns): 2026574
2025-03-26 02:26:35,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58120, dest: /172.20.1.17:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742257_1433, duration(ns): 1736817
2025-03-26 02:26:35,077 INFO terminating
2025-03-26 02:26:35,077 INFO terminating
2025-03-26 02:26:35,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1434, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_
2025-03-26 02:26:35,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742258_1434 src: /172.20.1.14:48260 dest: /172.20.1.15:9866
2025-03-26 02:26:35,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742258_1434 src: /172.20.1.15:60022 dest: /172.20.1.16:9866
2025-03-26 02:26:35,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742258_1434 src: /172.20.1.16:58124 dest: /172.20.1.17:9866
2025-03-26 02:26:35,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58124, dest: /172.20.1.17:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742258_1434, duration(ns): 4211449
2025-03-26 02:26:35,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742258_1434, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60022, dest: /172.20.1.16:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742258_1434, duration(ns): 4540792
2025-03-26 02:26:35,106 INFO terminating
2025-03-26 02:26:35,107 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48260, dest: /172.20.1.15:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742258_1434, duration(ns): 3614093
2025-03-26 02:26:35,107 INFO terminating
2025-03-26 02:26:35,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1435, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_
2025-03-26 02:26:35,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742259_1435 src: /172.20.1.14:52546 dest: /172.20.1.16:9866
2025-03-26 02:26:35,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742259_1435 src: /172.20.1.16:41650 dest: /172.20.1.15:9866
2025-03-26 02:26:35,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742259_1435 src: /172.20.1.15:40398 dest: /172.20.1.17:9866
2025-03-26 02:26:35,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40398, dest: /172.20.1.17:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742259_1435, duration(ns): 803038
2025-03-26 02:26:35,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742259_1435, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52546, dest: /172.20.1.16:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742259_1435, duration(ns): 2205903
2025-03-26 02:26:35,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41650, dest: /172.20.1.15:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742259_1435, duration(ns): 1445473
2025-03-26 02:26:35,118 INFO terminating
2025-03-26 02:26:35,118 INFO terminating
2025-03-26 02:26:35,119 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1436, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:26:35,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742260_1436 src: /172.20.1.14:48276 dest: /172.20.1.15:9866
2025-03-26 02:26:35,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742260_1436 src: /172.20.1.15:40408 dest: /172.20.1.17:9866
2025-03-26 02:26:35,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742260_1436 src: /172.20.1.17:51824 dest: /172.20.1.16:9866
2025-03-26 02:26:35,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51824, dest: /172.20.1.16:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742260_1436, duration(ns): 928900
2025-03-26 02:26:35,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742260_1436, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40408, dest: /172.20.1.17:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742260_1436, duration(ns): 1118372
2025-03-26 02:26:35,130 INFO terminating
2025-03-26 02:26:35,131 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48276, dest: /172.20.1.15:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742260_1436, duration(ns): 1818517
2025-03-26 02:26:35,131 INFO terminating
2025-03-26 02:26:35,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1437, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_
2025-03-26 02:26:35,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742261_1437 src: /172.20.1.14:48282 dest: /172.20.1.15:9866
2025-03-26 02:26:35,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742261_1437 src: /172.20.1.15:40410 dest: /172.20.1.17:9866
2025-03-26 02:26:35,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742261_1437 src: /172.20.1.17:51830 dest: /172.20.1.16:9866
2025-03-26 02:26:35,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40410, dest: /172.20.1.17:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742261_1437, duration(ns): 1230409
2025-03-26 02:26:35,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51830, dest: /172.20.1.16:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742261_1437, duration(ns): 971292
2025-03-26 02:26:35,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742261_1437, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,143 INFO terminating
2025-03-26 02:26:35,144 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48282, dest: /172.20.1.15:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742261_1437, duration(ns): 1450214
2025-03-26 02:26:35,144 INFO terminating
2025-03-26 02:26:35,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1438, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:26:35,148 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,148 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742262_1438 src: /172.20.1.14:52556 dest: /172.20.1.16:9866
2025-03-26 02:26:35,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742262_1438 src: /172.20.1.16:58138 dest: /172.20.1.17:9866
2025-03-26 02:26:35,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742262_1438 src: /172.20.1.17:48652 dest: /172.20.1.15:9866
2025-03-26 02:26:35,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48652, dest: /172.20.1.15:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742262_1438, duration(ns): 907342
2025-03-26 02:26:35,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742262_1438, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52556, dest: /172.20.1.16:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742262_1438, duration(ns): 1940661
2025-03-26 02:26:35,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58138, dest: /172.20.1.17:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742262_1438, duration(ns): 1578233
2025-03-26 02:26:35,155 INFO terminating
2025-03-26 02:26:35,155 INFO terminating
2025-03-26 02:26:35,156 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1439, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_
2025-03-26 02:26:35,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742263_1439 src: /172.20.1.14:48296 dest: /172.20.1.15:9866
2025-03-26 02:26:35,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742263_1439 src: /172.20.1.15:60032 dest: /172.20.1.16:9866
2025-03-26 02:26:35,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742263_1439 src: /172.20.1.16:58148 dest: /172.20.1.17:9866
2025-03-26 02:26:35,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58148, dest: /172.20.1.17:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742263_1439, duration(ns): 875763
2025-03-26 02:26:35,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742263_1439, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60032, dest: /172.20.1.16:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742263_1439, duration(ns): 1223695
2025-03-26 02:26:35,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48296, dest: /172.20.1.15:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742263_1439, duration(ns): 7007536
2025-03-26 02:26:35,170 INFO terminating
2025-03-26 02:26:35,171 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,171 INFO terminating
2025-03-26 02:26:35,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1440, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_
2025-03-26 02:26:35,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742264_1440 src: /172.20.1.14:38316 dest: /172.20.1.17:9866
2025-03-26 02:26:35,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742264_1440 src: /172.20.1.17:51838 dest: /172.20.1.16:9866
2025-03-26 02:26:35,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742264_1440 src: /172.20.1.16:41662 dest: /172.20.1.15:9866
2025-03-26 02:26:35,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41662, dest: /172.20.1.15:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742264_1440, duration(ns): 926943
2025-03-26 02:26:35,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742264_1440, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38316, dest: /172.20.1.17:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742264_1440, duration(ns): 1778310
2025-03-26 02:26:35,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51838, dest: /172.20.1.16:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742264_1440, duration(ns): 1522915
2025-03-26 02:26:35,180 INFO terminating
2025-03-26 02:26:35,180 INFO terminating
2025-03-26 02:26:35,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1441, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_
2025-03-26 02:26:35,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742265_1441 src: /172.20.1.14:38324 dest: /172.20.1.17:9866
2025-03-26 02:26:35,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742265_1441 src: /172.20.1.17:51848 dest: /172.20.1.16:9866
2025-03-26 02:26:35,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742265_1441 src: /172.20.1.16:41666 dest: /172.20.1.15:9866
2025-03-26 02:26:35,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41666, dest: /172.20.1.15:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742265_1441, duration(ns): 966233
2025-03-26 02:26:35,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742265_1441, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38324, dest: /172.20.1.17:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742265_1441, duration(ns): 2065027
2025-03-26 02:26:35,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51848, dest: /172.20.1.16:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742265_1441, duration(ns): 1508975
2025-03-26 02:26:35,190 INFO terminating
2025-03-26 02:26:35,190 INFO terminating
2025-03-26 02:26:35,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1442, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:26:35,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742266_1442 src: /172.20.1.14:38334 dest: /172.20.1.17:9866
2025-03-26 02:26:35,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742266_1442 src: /172.20.1.17:48658 dest: /172.20.1.15:9866
2025-03-26 02:26:35,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742266_1442 src: /172.20.1.15:60036 dest: /172.20.1.16:9866
2025-03-26 02:26:35,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60036, dest: /172.20.1.16:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742266_1442, duration(ns): 806147
2025-03-26 02:26:35,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48658, dest: /172.20.1.15:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742266_1442, duration(ns): 1064714
2025-03-26 02:26:35,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742266_1442, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,199 INFO terminating
2025-03-26 02:26:35,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38334, dest: /172.20.1.17:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742266_1442, duration(ns): 1579064
2025-03-26 02:26:35,201 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,201 INFO terminating
2025-03-26 02:26:35,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1443, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:26:35,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742267_1443 src: /172.20.1.14:52568 dest: /172.20.1.16:9866
2025-03-26 02:26:35,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742267_1443 src: /172.20.1.16:41680 dest: /172.20.1.15:9866
2025-03-26 02:26:35,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742267_1443 src: /172.20.1.15:40412 dest: /172.20.1.17:9866
2025-03-26 02:26:35,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40412, dest: /172.20.1.17:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742267_1443, duration(ns): 872271
2025-03-26 02:26:35,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742267_1443, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,210 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52568, dest: /172.20.1.16:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742267_1443, duration(ns): 1713400
2025-03-26 02:26:35,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41680, dest: /172.20.1.15:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742267_1443, duration(ns): 1170409
2025-03-26 02:26:35,210 INFO terminating
2025-03-26 02:26:35,210 INFO terminating
2025-03-26 02:26:35,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1444, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_
2025-03-26 02:26:35,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742268_1444 src: /172.20.1.14:48310 dest: /172.20.1.15:9866
2025-03-26 02:26:35,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742268_1444 src: /172.20.1.15:40424 dest: /172.20.1.17:9866
2025-03-26 02:26:35,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742268_1444 src: /172.20.1.17:51856 dest: /172.20.1.16:9866
2025-03-26 02:26:35,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51856, dest: /172.20.1.16:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742268_1444, duration(ns): 735091
2025-03-26 02:26:35,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48310, dest: /172.20.1.15:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742268_1444, duration(ns): 1298662
2025-03-26 02:26:35,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40424, dest: /172.20.1.17:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742268_1444, duration(ns): 998147
2025-03-26 02:26:35,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742268_1444, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,218 INFO terminating
2025-03-26 02:26:35,218 INFO terminating
2025-03-26 02:26:35,219 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1445, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_
2025-03-26 02:26:35,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742269_1445 src: /172.20.1.14:38336 dest: /172.20.1.17:9866
2025-03-26 02:26:35,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742269_1445 src: /172.20.1.17:51866 dest: /172.20.1.16:9866
2025-03-26 02:26:35,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742269_1445 src: /172.20.1.16:41684 dest: /172.20.1.15:9866
2025-03-26 02:26:35,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41684, dest: /172.20.1.15:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742269_1445, duration(ns): 665638
2025-03-26 02:26:35,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742269_1445, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38336, dest: /172.20.1.17:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742269_1445, duration(ns): 1190059
2025-03-26 02:26:35,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51866, dest: /172.20.1.16:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742269_1445, duration(ns): 819636
2025-03-26 02:26:35,226 INFO terminating
2025-03-26 02:26:35,226 INFO terminating
2025-03-26 02:26:35,227 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,229 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1446, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:26:35,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742270_1446 src: /172.20.1.14:52570 dest: /172.20.1.16:9866
2025-03-26 02:26:35,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742270_1446 src: /172.20.1.16:41698 dest: /172.20.1.15:9866
2025-03-26 02:26:35,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742270_1446 src: /172.20.1.15:40434 dest: /172.20.1.17:9866
2025-03-26 02:26:35,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40434, dest: /172.20.1.17:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742270_1446, duration(ns): 609138
2025-03-26 02:26:35,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41698, dest: /172.20.1.15:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742270_1446, duration(ns): 4780658
2025-03-26 02:26:35,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742270_1446, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,237 INFO terminating
2025-03-26 02:26:35,238 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52570, dest: /172.20.1.16:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742270_1446, duration(ns): 4960406
2025-03-26 02:26:35,238 INFO terminating
2025-03-26 02:26:35,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1447, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_
2025-03-26 02:26:35,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742271_1447 src: /172.20.1.14:48316 dest: /172.20.1.15:9866
2025-03-26 02:26:35,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742271_1447 src: /172.20.1.15:60046 dest: /172.20.1.16:9866
2025-03-26 02:26:35,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742271_1447 src: /172.20.1.16:58154 dest: /172.20.1.17:9866
2025-03-26 02:26:35,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48316, dest: /172.20.1.15:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742271_1447, duration(ns): 1341015
2025-03-26 02:26:35,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60046, dest: /172.20.1.16:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742271_1447, duration(ns): 1001060
2025-03-26 02:26:35,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58154, dest: /172.20.1.17:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742271_1447, duration(ns): 699907
2025-03-26 02:26:35,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742271_1447, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,247 INFO terminating
2025-03-26 02:26:35,247 INFO terminating
2025-03-26 02:26:35,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1448, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_
2025-03-26 02:26:35,251 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,251 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742272_1448 src: /172.20.1.14:52574 dest: /172.20.1.16:9866
2025-03-26 02:26:35,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742272_1448 src: /172.20.1.16:58168 dest: /172.20.1.17:9866
2025-03-26 02:26:35,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742272_1448 src: /172.20.1.17:48664 dest: /172.20.1.15:9866
2025-03-26 02:26:35,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48664, dest: /172.20.1.15:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742272_1448, duration(ns): 837955
2025-03-26 02:26:35,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742272_1448, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52574, dest: /172.20.1.16:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742272_1448, duration(ns): 1279014
2025-03-26 02:26:35,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58168, dest: /172.20.1.17:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742272_1448, duration(ns): 1018132
2025-03-26 02:26:35,257 INFO terminating
2025-03-26 02:26:35,257 INFO terminating
2025-03-26 02:26:35,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,261 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1449, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:26:35,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742273_1449 src: /172.20.1.14:48330 dest: /172.20.1.15:9866
2025-03-26 02:26:35,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742273_1449 src: /172.20.1.15:60060 dest: /172.20.1.16:9866
2025-03-26 02:26:35,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742273_1449 src: /172.20.1.16:58170 dest: /172.20.1.17:9866
2025-03-26 02:26:35,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58170, dest: /172.20.1.17:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742273_1449, duration(ns): 690815
2025-03-26 02:26:35,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742273_1449, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48330, dest: /172.20.1.15:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742273_1449, duration(ns): 1435209
2025-03-26 02:26:35,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60060, dest: /172.20.1.16:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742273_1449, duration(ns): 1083339
2025-03-26 02:26:35,266 INFO terminating
2025-03-26 02:26:35,266 INFO terminating
2025-03-26 02:26:35,267 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1450, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:26:35,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742274_1450 src: /172.20.1.14:38350 dest: /172.20.1.17:9866
2025-03-26 02:26:35,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742274_1450 src: /172.20.1.17:51874 dest: /172.20.1.16:9866
2025-03-26 02:26:35,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742274_1450 src: /172.20.1.16:41710 dest: /172.20.1.15:9866
2025-03-26 02:26:35,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41710, dest: /172.20.1.15:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742274_1450, duration(ns): 807011
2025-03-26 02:26:35,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51874, dest: /172.20.1.16:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742274_1450, duration(ns): 978271
2025-03-26 02:26:35,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742274_1450, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,275 INFO terminating
2025-03-26 02:26:35,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38350, dest: /172.20.1.17:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742274_1450, duration(ns): 3608987
2025-03-26 02:26:35,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,281 INFO terminating
2025-03-26 02:26:35,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1451, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_
2025-03-26 02:26:35,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742275_1451 src: /172.20.1.14:38358 dest: /172.20.1.17:9866
2025-03-26 02:26:35,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742275_1451 src: /172.20.1.17:51876 dest: /172.20.1.16:9866
2025-03-26 02:26:35,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742275_1451 src: /172.20.1.16:41714 dest: /172.20.1.15:9866
2025-03-26 02:26:35,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38358, dest: /172.20.1.17:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742275_1451, duration(ns): 1366802
2025-03-26 02:26:35,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41714, dest: /172.20.1.15:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742275_1451, duration(ns): 904912
2025-03-26 02:26:35,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51876, dest: /172.20.1.16:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742275_1451, duration(ns): 1075032
2025-03-26 02:26:35,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742275_1451, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,295 INFO terminating
2025-03-26 02:26:35,296 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,296 INFO terminating
2025-03-26 02:26:35,299 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1452, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_
2025-03-26 02:26:35,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742276_1452 src: /172.20.1.14:52590 dest: /172.20.1.16:9866
2025-03-26 02:26:35,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742276_1452 src: /172.20.1.16:58184 dest: /172.20.1.17:9866
2025-03-26 02:26:35,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742276_1452 src: /172.20.1.17:48672 dest: /172.20.1.15:9866
2025-03-26 02:26:35,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48672, dest: /172.20.1.15:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742276_1452, duration(ns): 778761
2025-03-26 02:26:35,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742276_1452, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,304 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52590, dest: /172.20.1.16:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742276_1452, duration(ns): 1231586
2025-03-26 02:26:35,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58184, dest: /172.20.1.17:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742276_1452, duration(ns): 815758
2025-03-26 02:26:35,304 INFO terminating
2025-03-26 02:26:35,304 INFO terminating
2025-03-26 02:26:35,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1453, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_
2025-03-26 02:26:35,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742277_1453 src: /172.20.1.14:38364 dest: /172.20.1.17:9866
2025-03-26 02:26:35,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742277_1453 src: /172.20.1.16:41728 dest: /172.20.1.15:9866
2025-03-26 02:26:35,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742277_1453 src: /172.20.1.17:51884 dest: /172.20.1.16:9866
2025-03-26 02:26:35,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41728, dest: /172.20.1.15:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742277_1453, duration(ns): 4095267
2025-03-26 02:26:35,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742277_1453, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38364, dest: /172.20.1.17:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742277_1453, duration(ns): 4802626
2025-03-26 02:26:35,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51884, dest: /172.20.1.16:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742277_1453, duration(ns): 4279928
2025-03-26 02:26:35,320 INFO terminating
2025-03-26 02:26:35,320 INFO terminating
2025-03-26 02:26:35,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1454, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:26:35,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742278_1454 src: /172.20.1.14:48338 dest: /172.20.1.15:9866
2025-03-26 02:26:35,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742278_1454 src: /172.20.1.15:60062 dest: /172.20.1.16:9866
2025-03-26 02:26:35,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742278_1454 src: /172.20.1.16:58188 dest: /172.20.1.17:9866
2025-03-26 02:26:35,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58188, dest: /172.20.1.17:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742278_1454, duration(ns): 641468
2025-03-26 02:26:35,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48338, dest: /172.20.1.15:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742278_1454, duration(ns): 1270103
2025-03-26 02:26:35,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60062, dest: /172.20.1.16:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742278_1454, duration(ns): 935582
2025-03-26 02:26:35,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742278_1454, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,329 INFO terminating
2025-03-26 02:26:35,329 INFO terminating
2025-03-26 02:26:35,330 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,334 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1455, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_
2025-03-26 02:26:35,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742279_1455 src: /172.20.1.14:52596 dest: /172.20.1.16:9866
2025-03-26 02:26:35,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742279_1455 src: /172.20.1.15:40442 dest: /172.20.1.17:9866
2025-03-26 02:26:35,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742279_1455 src: /172.20.1.16:41744 dest: /172.20.1.15:9866
2025-03-26 02:26:35,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40442, dest: /172.20.1.17:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742279_1455, duration(ns): 650544
2025-03-26 02:26:35,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41744, dest: /172.20.1.15:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742279_1455, duration(ns): 925371
2025-03-26 02:26:35,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742279_1455, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,338 INFO terminating
2025-03-26 02:26:35,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52596, dest: /172.20.1.16:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742279_1455, duration(ns): 1189267
2025-03-26 02:26:35,339 INFO terminating
2025-03-26 02:26:35,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1456, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_
2025-03-26 02:26:35,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742280_1456 src: /172.20.1.14:38368 dest: /172.20.1.17:9866
2025-03-26 02:26:35,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742280_1456 src: /172.20.1.17:48674 dest: /172.20.1.15:9866
2025-03-26 02:26:35,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742280_1456 src: /172.20.1.15:60076 dest: /172.20.1.16:9866
2025-03-26 02:26:35,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60076, dest: /172.20.1.16:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742280_1456, duration(ns): 834072
2025-03-26 02:26:35,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48674, dest: /172.20.1.15:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742280_1456, duration(ns): 1499460
2025-03-26 02:26:35,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742280_1456, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,348 INFO terminating
2025-03-26 02:26:35,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38368, dest: /172.20.1.17:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742280_1456, duration(ns): 1997933
2025-03-26 02:26:35,349 INFO terminating
2025-03-26 02:26:35,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1457, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_
2025-03-26 02:26:35,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742281_1457 src: /172.20.1.14:38376 dest: /172.20.1.17:9866
2025-03-26 02:26:35,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742281_1457 src: /172.20.1.17:51898 dest: /172.20.1.16:9866
2025-03-26 02:26:35,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742281_1457 src: /172.20.1.16:41754 dest: /172.20.1.15:9866
2025-03-26 02:26:35,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41754, dest: /172.20.1.15:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742281_1457, duration(ns): 678640
2025-03-26 02:26:35,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51898, dest: /172.20.1.16:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742281_1457, duration(ns): 810130
2025-03-26 02:26:35,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742281_1457, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,356 INFO terminating
2025-03-26 02:26:35,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38376, dest: /172.20.1.17:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742281_1457, duration(ns): 1131280
2025-03-26 02:26:35,357 INFO terminating
2025-03-26 02:26:35,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1458, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_
2025-03-26 02:26:35,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742282_1458 src: /172.20.1.14:38386 dest: /172.20.1.17:9866
2025-03-26 02:26:35,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742282_1458 src: /172.20.1.16:41768 dest: /172.20.1.15:9866
2025-03-26 02:26:35,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742282_1458 src: /172.20.1.17:51902 dest: /172.20.1.16:9866
2025-03-26 02:26:35,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38386, dest: /172.20.1.17:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742282_1458, duration(ns): 1169277
2025-03-26 02:26:35,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41768, dest: /172.20.1.15:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742282_1458, duration(ns): 649583
2025-03-26 02:26:35,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51902, dest: /172.20.1.16:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742282_1458, duration(ns): 787370
2025-03-26 02:26:35,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742282_1458, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,364 INFO terminating
2025-03-26 02:26:35,365 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,365 INFO terminating
2025-03-26 02:26:35,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1459, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_
2025-03-26 02:26:35,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742283_1459 src: /172.20.1.14:52604 dest: /172.20.1.16:9866
2025-03-26 02:26:35,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742283_1459 src: /172.20.1.16:41776 dest: /172.20.1.15:9866
2025-03-26 02:26:35,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742283_1459 src: /172.20.1.15:40452 dest: /172.20.1.17:9866
2025-03-26 02:26:35,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40452, dest: /172.20.1.17:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742283_1459, duration(ns): 1317519
2025-03-26 02:26:35,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41776, dest: /172.20.1.15:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742283_1459, duration(ns): 1628084
2025-03-26 02:26:35,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742283_1459, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,373 INFO terminating
2025-03-26 02:26:35,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52604, dest: /172.20.1.16:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742283_1459, duration(ns): 2059857
2025-03-26 02:26:35,374 INFO terminating
2025-03-26 02:26:35,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1460, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:26:35,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742284_1460 src: /172.20.1.14:38398 dest: /172.20.1.17:9866
2025-03-26 02:26:35,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742284_1460 src: /172.20.1.17:48686 dest: /172.20.1.15:9866
2025-03-26 02:26:35,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742284_1460 src: /172.20.1.15:60082 dest: /172.20.1.16:9866
2025-03-26 02:26:35,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60082, dest: /172.20.1.16:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742284_1460, duration(ns): 2498174
2025-03-26 02:26:35,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742284_1460, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38398, dest: /172.20.1.17:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742284_1460, duration(ns): 3205399
2025-03-26 02:26:35,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48686, dest: /172.20.1.15:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742284_1460, duration(ns): 2943349
2025-03-26 02:26:35,452 INFO terminating
2025-03-26 02:26:35,452 INFO terminating
2025-03-26 02:26:35,453 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1461, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:26:35,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742285_1461 src: /172.20.1.14:38414 dest: /172.20.1.17:9866
2025-03-26 02:26:35,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742285_1461 src: /172.20.1.17:51916 dest: /172.20.1.16:9866
2025-03-26 02:26:35,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742285_1461 src: /172.20.1.16:41790 dest: /172.20.1.15:9866
2025-03-26 02:26:35,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41790, dest: /172.20.1.15:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742285_1461, duration(ns): 2069063
2025-03-26 02:26:35,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742285_1461, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51916, dest: /172.20.1.16:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742285_1461, duration(ns): 2293048
2025-03-26 02:26:35,473 INFO terminating
2025-03-26 02:26:35,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38414, dest: /172.20.1.17:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742285_1461, duration(ns): 2471674
2025-03-26 02:26:35,474 INFO terminating
2025-03-26 02:26:35,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1462, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_
2025-03-26 02:26:35,481 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,481 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742286_1462 src: /172.20.1.14:48354 dest: /172.20.1.15:9866
2025-03-26 02:26:35,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742286_1462 src: /172.20.1.15:60098 dest: /172.20.1.16:9866
2025-03-26 02:26:35,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742286_1462 src: /172.20.1.16:58194 dest: /172.20.1.17:9866
2025-03-26 02:26:35,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58194, dest: /172.20.1.17:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742286_1462, duration(ns): 1686055
2025-03-26 02:26:35,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742286_1462, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60098, dest: /172.20.1.16:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742286_1462, duration(ns): 2443506
2025-03-26 02:26:35,492 INFO terminating
2025-03-26 02:26:35,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48354, dest: /172.20.1.15:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742286_1462, duration(ns): 3104728
2025-03-26 02:26:35,493 INFO terminating
2025-03-26 02:26:35,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1463, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_
2025-03-26 02:26:35,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742287_1463 src: /172.20.1.14:38422 dest: /172.20.1.17:9866
2025-03-26 02:26:35,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742287_1463 src: /172.20.1.17:51922 dest: /172.20.1.16:9866
2025-03-26 02:26:35,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742287_1463 src: /172.20.1.16:41798 dest: /172.20.1.15:9866
2025-03-26 02:26:35,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38422, dest: /172.20.1.17:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742287_1463, duration(ns): 1556849
2025-03-26 02:26:35,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41798, dest: /172.20.1.15:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742287_1463, duration(ns): 746150
2025-03-26 02:26:35,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51922, dest: /172.20.1.16:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742287_1463, duration(ns): 1210759
2025-03-26 02:26:35,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742287_1463, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,502 INFO terminating
2025-03-26 02:26:35,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,503 INFO terminating
2025-03-26 02:26:35,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1464, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_
2025-03-26 02:26:35,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742288_1464 src: /172.20.1.14:48368 dest: /172.20.1.15:9866
2025-03-26 02:26:35,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742288_1464 src: /172.20.1.15:60110 dest: /172.20.1.16:9866
2025-03-26 02:26:35,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742288_1464 src: /172.20.1.16:58198 dest: /172.20.1.17:9866
2025-03-26 02:26:35,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48368, dest: /172.20.1.15:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742288_1464, duration(ns): 11102044
2025-03-26 02:26:35,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60110, dest: /172.20.1.16:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742288_1464, duration(ns): 10665927
2025-03-26 02:26:35,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58198, dest: /172.20.1.17:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742288_1464, duration(ns): 518225
2025-03-26 02:26:35,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742288_1464, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,520 INFO terminating
2025-03-26 02:26:35,520 INFO terminating
2025-03-26 02:26:35,521 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1465, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_
2025-03-26 02:26:35,524 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,524 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742289_1465 src: /172.20.1.14:48382 dest: /172.20.1.15:9866
2025-03-26 02:26:35,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742289_1465 src: /172.20.1.15:40456 dest: /172.20.1.17:9866
2025-03-26 02:26:35,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742289_1465 src: /172.20.1.17:51936 dest: /172.20.1.16:9866
2025-03-26 02:26:35,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40456, dest: /172.20.1.17:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742289_1465, duration(ns): 1199734
2025-03-26 02:26:35,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51936, dest: /172.20.1.16:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742289_1465, duration(ns): 804128
2025-03-26 02:26:35,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742289_1465, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,529 INFO terminating
2025-03-26 02:26:35,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48382, dest: /172.20.1.15:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742289_1465, duration(ns): 1753882
2025-03-26 02:26:35,530 INFO terminating
2025-03-26 02:26:35,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1466, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_
2025-03-26 02:26:35,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742290_1466 src: /172.20.1.14:52618 dest: /172.20.1.16:9866
2025-03-26 02:26:35,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742290_1466 src: /172.20.1.16:58200 dest: /172.20.1.17:9866
2025-03-26 02:26:35,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742290_1466 src: /172.20.1.17:48696 dest: /172.20.1.15:9866
2025-03-26 02:26:35,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48696, dest: /172.20.1.15:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742290_1466, duration(ns): 1175120
2025-03-26 02:26:35,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742290_1466, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58200, dest: /172.20.1.17:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742290_1466, duration(ns): 1355453
2025-03-26 02:26:35,540 INFO terminating
2025-03-26 02:26:35,541 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52618, dest: /172.20.1.16:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742290_1466, duration(ns): 2274279
2025-03-26 02:26:35,541 INFO terminating
2025-03-26 02:26:35,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1467, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_
2025-03-26 02:26:35,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742291_1467 src: /172.20.1.14:52622 dest: /172.20.1.16:9866
2025-03-26 02:26:35,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742291_1467 src: /172.20.1.16:41802 dest: /172.20.1.15:9866
2025-03-26 02:26:35,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742291_1467 src: /172.20.1.15:40466 dest: /172.20.1.17:9866
2025-03-26 02:26:35,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40466, dest: /172.20.1.17:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742291_1467, duration(ns): 1585239
2025-03-26 02:26:35,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41802, dest: /172.20.1.15:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742291_1467, duration(ns): 2336360
2025-03-26 02:26:35,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742291_1467, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,552 INFO terminating
2025-03-26 02:26:35,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52622, dest: /172.20.1.16:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742291_1467, duration(ns): 2238137
2025-03-26 02:26:35,553 INFO terminating
2025-03-26 02:26:35,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1468, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_
2025-03-26 02:26:35,557 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,557 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742292_1468 src: /172.20.1.14:38426 dest: /172.20.1.17:9866
2025-03-26 02:26:35,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742292_1468 src: /172.20.1.17:51940 dest: /172.20.1.16:9866
2025-03-26 02:26:35,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742292_1468 src: /172.20.1.16:41818 dest: /172.20.1.15:9866
2025-03-26 02:26:35,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41818, dest: /172.20.1.15:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742292_1468, duration(ns): 1049337
2025-03-26 02:26:35,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742292_1468, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38426, dest: /172.20.1.17:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742292_1468, duration(ns): 2873297
2025-03-26 02:26:35,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51940, dest: /172.20.1.16:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742292_1468, duration(ns): 1210840
2025-03-26 02:26:35,566 INFO terminating
2025-03-26 02:26:35,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,567 INFO terminating
2025-03-26 02:26:35,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1469, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_
2025-03-26 02:26:35,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742293_1469 src: /172.20.1.14:38440 dest: /172.20.1.17:9866
2025-03-26 02:26:35,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742293_1469 src: /172.20.1.17:51946 dest: /172.20.1.16:9866
2025-03-26 02:26:35,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742293_1469 src: /172.20.1.16:41830 dest: /172.20.1.15:9866
2025-03-26 02:26:35,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41830, dest: /172.20.1.15:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742293_1469, duration(ns): 948334
2025-03-26 02:26:35,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742293_1469, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51946, dest: /172.20.1.16:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742293_1469, duration(ns): 1101531
2025-03-26 02:26:35,579 INFO terminating
2025-03-26 02:26:35,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38440, dest: /172.20.1.17:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742293_1469, duration(ns): 1740265
2025-03-26 02:26:35,580 INFO terminating
2025-03-26 02:26:35,581 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1470, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_
2025-03-26 02:26:35,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742294_1470 src: /172.20.1.14:38446 dest: /172.20.1.17:9866
2025-03-26 02:26:35,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742294_1470 src: /172.20.1.17:51950 dest: /172.20.1.16:9866
2025-03-26 02:26:35,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742294_1470 src: /172.20.1.16:41844 dest: /172.20.1.15:9866
2025-03-26 02:26:35,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41844, dest: /172.20.1.15:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742294_1470, duration(ns): 932929
2025-03-26 02:26:35,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742294_1470, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51950, dest: /172.20.1.16:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742294_1470, duration(ns): 1063342
2025-03-26 02:26:35,593 INFO terminating
2025-03-26 02:26:35,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38446, dest: /172.20.1.17:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742294_1470, duration(ns): 1733871
2025-03-26 02:26:35,595 INFO terminating
2025-03-26 02:26:35,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,599 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1471, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_
2025-03-26 02:26:35,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742295_1471 src: /172.20.1.14:48388 dest: /172.20.1.15:9866
2025-03-26 02:26:35,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742295_1471 src: /172.20.1.15:40476 dest: /172.20.1.17:9866
2025-03-26 02:26:35,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742295_1471 src: /172.20.1.17:51956 dest: /172.20.1.16:9866
2025-03-26 02:26:35,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51956, dest: /172.20.1.16:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742295_1471, duration(ns): 1021590
2025-03-26 02:26:35,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742295_1471, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48388, dest: /172.20.1.15:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742295_1471, duration(ns): 2622901
2025-03-26 02:26:35,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40476, dest: /172.20.1.17:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742295_1471, duration(ns): 1678586
2025-03-26 02:26:35,605 INFO terminating
2025-03-26 02:26:35,605 INFO terminating
2025-03-26 02:26:35,606 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1472, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_
2025-03-26 02:26:35,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742296_1472 src: /172.20.1.14:52636 dest: /172.20.1.16:9866
2025-03-26 02:26:35,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742296_1472 src: /172.20.1.16:41846 dest: /172.20.1.15:9866
2025-03-26 02:26:35,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742296_1472 src: /172.20.1.15:40490 dest: /172.20.1.17:9866
2025-03-26 02:26:35,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40490, dest: /172.20.1.17:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742296_1472, duration(ns): 1549726
2025-03-26 02:26:35,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41846, dest: /172.20.1.15:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742296_1472, duration(ns): 2359117
2025-03-26 02:26:35,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742296_1472, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,615 INFO terminating
2025-03-26 02:26:35,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52636, dest: /172.20.1.16:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742296_1472, duration(ns): 2373084
2025-03-26 02:26:35,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,617 INFO terminating
2025-03-26 02:26:35,620 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1473, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:26:35,620 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,620 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742297_1473 src: /172.20.1.14:48402 dest: /172.20.1.15:9866
2025-03-26 02:26:35,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742297_1473 src: /172.20.1.15:40496 dest: /172.20.1.17:9866
2025-03-26 02:26:35,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742297_1473 src: /172.20.1.17:51964 dest: /172.20.1.16:9866
2025-03-26 02:26:35,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51964, dest: /172.20.1.16:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742297_1473, duration(ns): 1045391
2025-03-26 02:26:35,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742297_1473, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40496, dest: /172.20.1.17:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742297_1473, duration(ns): 1677849
2025-03-26 02:26:35,627 INFO terminating
2025-03-26 02:26:35,628 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48402, dest: /172.20.1.15:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742297_1473, duration(ns): 3366715
2025-03-26 02:26:35,628 INFO terminating
2025-03-26 02:26:35,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1474, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_
2025-03-26 02:26:35,631 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,631 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742298_1474 src: /172.20.1.14:38456 dest: /172.20.1.17:9866
2025-03-26 02:26:35,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742298_1474 src: /172.20.1.17:51978 dest: /172.20.1.16:9866
2025-03-26 02:26:35,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742298_1474 src: /172.20.1.16:41858 dest: /172.20.1.15:9866
2025-03-26 02:26:35,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41858, dest: /172.20.1.15:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742298_1474, duration(ns): 1006556
2025-03-26 02:26:35,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742298_1474, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51978, dest: /172.20.1.16:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742298_1474, duration(ns): 1145156
2025-03-26 02:26:35,637 INFO terminating
2025-03-26 02:26:35,638 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38456, dest: /172.20.1.17:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742298_1474, duration(ns): 1808152
2025-03-26 02:26:35,638 INFO terminating
2025-03-26 02:26:35,642 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1475, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_
2025-03-26 02:26:35,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742299_1475 src: /172.20.1.14:48412 dest: /172.20.1.15:9866
2025-03-26 02:26:35,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742299_1475 src: /172.20.1.15:40504 dest: /172.20.1.17:9866
2025-03-26 02:26:35,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742299_1475 src: /172.20.1.17:51992 dest: /172.20.1.16:9866
2025-03-26 02:26:35,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51992, dest: /172.20.1.16:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742299_1475, duration(ns): 985034
2025-03-26 02:26:35,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742299_1475, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40504, dest: /172.20.1.17:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742299_1475, duration(ns): 1705845
2025-03-26 02:26:35,648 INFO terminating
2025-03-26 02:26:35,649 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48412, dest: /172.20.1.15:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742299_1475, duration(ns): 2759739
2025-03-26 02:26:35,649 INFO terminating
2025-03-26 02:26:35,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1476, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_
2025-03-26 02:26:35,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742300_1476 src: /172.20.1.14:52646 dest: /172.20.1.16:9866
2025-03-26 02:26:35,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742300_1476 src: /172.20.1.16:58206 dest: /172.20.1.17:9866
2025-03-26 02:26:35,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742300_1476 src: /172.20.1.17:48702 dest: /172.20.1.15:9866
2025-03-26 02:26:35,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48702, dest: /172.20.1.15:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742300_1476, duration(ns): 1145771
2025-03-26 02:26:35,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742300_1476, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58206, dest: /172.20.1.17:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742300_1476, duration(ns): 1342039
2025-03-26 02:26:35,659 INFO terminating
2025-03-26 02:26:35,661 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52646, dest: /172.20.1.16:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742300_1476, duration(ns): 2941145
2025-03-26 02:26:35,661 INFO terminating
2025-03-26 02:26:35,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1477, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_
2025-03-26 02:26:35,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742301_1477 src: /172.20.1.14:52662 dest: /172.20.1.16:9866
2025-03-26 02:26:35,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742301_1477 src: /172.20.1.16:58220 dest: /172.20.1.17:9866
2025-03-26 02:26:35,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742301_1477 src: /172.20.1.17:48710 dest: /172.20.1.15:9866
2025-03-26 02:26:35,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48710, dest: /172.20.1.15:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742301_1477, duration(ns): 1918862
2025-03-26 02:26:35,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742301_1477, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58220, dest: /172.20.1.17:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742301_1477, duration(ns): 2083120
2025-03-26 02:26:35,679 INFO terminating
2025-03-26 02:26:35,680 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52662, dest: /172.20.1.16:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742301_1477, duration(ns): 2902270
2025-03-26 02:26:35,680 INFO terminating
2025-03-26 02:26:35,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1478, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_
2025-03-26 02:26:35,683 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,683 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742302_1478 src: /172.20.1.14:48428 dest: /172.20.1.15:9866
2025-03-26 02:26:35,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742302_1478 src: /172.20.1.15:40506 dest: /172.20.1.17:9866
2025-03-26 02:26:35,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742302_1478 src: /172.20.1.17:51994 dest: /172.20.1.16:9866
2025-03-26 02:26:35,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:51994, dest: /172.20.1.16:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742302_1478, duration(ns): 1433306
2025-03-26 02:26:35,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742302_1478, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,690 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48428, dest: /172.20.1.15:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742302_1478, duration(ns): 2983082
2025-03-26 02:26:35,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40506, dest: /172.20.1.17:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742302_1478, duration(ns): 2074887
2025-03-26 02:26:35,690 INFO terminating
2025-03-26 02:26:35,690 INFO terminating
2025-03-26 02:26:35,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742303_1479, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_
2025-03-26 02:26:35,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742303_1479 src: /172.20.1.14:48434 dest: /172.20.1.15:9866
2025-03-26 02:26:35,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742303_1479 src: /172.20.1.15:40522 dest: /172.20.1.17:9866
2025-03-26 02:26:35,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742303_1479 src: /172.20.1.17:52004 dest: /172.20.1.16:9866
2025-03-26 02:26:35,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52004, dest: /172.20.1.16:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742303_1479, duration(ns): 905988
2025-03-26 02:26:35,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742303_1479, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48434, dest: /172.20.1.15:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742303_1479, duration(ns): 2290484
2025-03-26 02:26:35,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40522, dest: /172.20.1.17:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742303_1479, duration(ns): 1523837
2025-03-26 02:26:35,700 INFO terminating
2025-03-26 02:26:35,700 INFO terminating
2025-03-26 02:26:35,701 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,704 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742304_1480, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_
2025-03-26 02:26:35,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742304_1480 src: /172.20.1.14:38468 dest: /172.20.1.17:9866
2025-03-26 02:26:35,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742304_1480 src: /172.20.1.17:48716 dest: /172.20.1.15:9866
2025-03-26 02:26:35,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742304_1480 src: /172.20.1.15:60118 dest: /172.20.1.16:9866
2025-03-26 02:26:35,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60118, dest: /172.20.1.16:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742304_1480, duration(ns): 1181885
2025-03-26 02:26:35,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742304_1480, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48716, dest: /172.20.1.15:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742304_1480, duration(ns): 2263340
2025-03-26 02:26:35,712 INFO terminating
2025-03-26 02:26:35,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38468, dest: /172.20.1.17:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742304_1480, duration(ns): 2544613
2025-03-26 02:26:35,713 INFO terminating
2025-03-26 02:26:35,714 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,718 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742305_1481, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:26:35,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742305_1481 src: /172.20.1.14:38484 dest: /172.20.1.17:9866
2025-03-26 02:26:35,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742305_1481 src: /172.20.1.17:48724 dest: /172.20.1.15:9866
2025-03-26 02:26:35,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742305_1481 src: /172.20.1.15:60134 dest: /172.20.1.16:9866
2025-03-26 02:26:35,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60134, dest: /172.20.1.16:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742305_1481, duration(ns): 1205129
2025-03-26 02:26:35,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742305_1481, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48724, dest: /172.20.1.15:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742305_1481, duration(ns): 2133102
2025-03-26 02:26:35,725 INFO terminating
2025-03-26 02:26:35,726 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38484, dest: /172.20.1.17:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742305_1481, duration(ns): 2360154
2025-03-26 02:26:35,726 INFO terminating
2025-03-26 02:26:35,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742306_1482, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_
2025-03-26 02:26:35,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742306_1482 src: /172.20.1.14:52672 dest: /172.20.1.16:9866
2025-03-26 02:26:35,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742306_1482 src: /172.20.1.16:58222 dest: /172.20.1.17:9866
2025-03-26 02:26:35,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742306_1482 src: /172.20.1.17:48734 dest: /172.20.1.15:9866
2025-03-26 02:26:35,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48734, dest: /172.20.1.15:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742306_1482, duration(ns): 2365290
2025-03-26 02:26:35,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742306_1482, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58222, dest: /172.20.1.17:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742306_1482, duration(ns): 4521605
2025-03-26 02:26:35,742 INFO terminating
2025-03-26 02:26:35,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52672, dest: /172.20.1.16:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742306_1482, duration(ns): 5671745
2025-03-26 02:26:35,743 INFO terminating
2025-03-26 02:26:35,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742307_1483, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_
2025-03-26 02:26:35,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742307_1483 src: /172.20.1.14:52686 dest: /172.20.1.16:9866
2025-03-26 02:26:35,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742307_1483 src: /172.20.1.16:41874 dest: /172.20.1.15:9866
2025-03-26 02:26:35,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742307_1483 src: /172.20.1.15:40534 dest: /172.20.1.17:9866
2025-03-26 02:26:35,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40534, dest: /172.20.1.17:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742307_1483, duration(ns): 1067011
2025-03-26 02:26:35,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41874, dest: /172.20.1.15:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742307_1483, duration(ns): 1825697
2025-03-26 02:26:35,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742307_1483, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,753 INFO terminating
2025-03-26 02:26:35,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52686, dest: /172.20.1.16:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742307_1483, duration(ns): 1982375
2025-03-26 02:26:35,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,755 INFO terminating
2025-03-26 02:26:35,758 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742308_1484, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_
2025-03-26 02:26:35,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742308_1484 src: /172.20.1.14:38494 dest: /172.20.1.17:9866
2025-03-26 02:26:35,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742308_1484 src: /172.20.1.17:52018 dest: /172.20.1.16:9866
2025-03-26 02:26:35,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742308_1484 src: /172.20.1.16:41886 dest: /172.20.1.15:9866
2025-03-26 02:26:35,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41886, dest: /172.20.1.15:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742308_1484, duration(ns): 1712389
2025-03-26 02:26:35,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742308_1484, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52018, dest: /172.20.1.16:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742308_1484, duration(ns): 2120567
2025-03-26 02:26:35,767 INFO terminating
2025-03-26 02:26:35,769 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38494, dest: /172.20.1.17:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742308_1484, duration(ns): 3429820
2025-03-26 02:26:35,769 INFO terminating
2025-03-26 02:26:35,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742309_1485, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_
2025-03-26 02:26:35,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742309_1485 src: /172.20.1.14:38508 dest: /172.20.1.17:9866
2025-03-26 02:26:35,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742309_1485 src: /172.20.1.17:52030 dest: /172.20.1.16:9866
2025-03-26 02:26:35,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742309_1485 src: /172.20.1.16:41898 dest: /172.20.1.15:9866
2025-03-26 02:26:35,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41898, dest: /172.20.1.15:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742309_1485, duration(ns): 1139242
2025-03-26 02:26:35,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52030, dest: /172.20.1.16:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742309_1485, duration(ns): 1289197
2025-03-26 02:26:35,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742309_1485, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38508, dest: /172.20.1.17:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742309_1485, duration(ns): 2062319
2025-03-26 02:26:35,782 INFO terminating
2025-03-26 02:26:35,782 INFO terminating
2025-03-26 02:26:35,783 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742310_1486, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_
2025-03-26 02:26:35,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742310_1486 src: /172.20.1.14:52692 dest: /172.20.1.16:9866
2025-03-26 02:26:35,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742310_1486 src: /172.20.1.16:58234 dest: /172.20.1.17:9866
2025-03-26 02:26:35,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742310_1486 src: /172.20.1.17:48744 dest: /172.20.1.15:9866
2025-03-26 02:26:35,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48744, dest: /172.20.1.15:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742310_1486, duration(ns): 1485328
2025-03-26 02:26:35,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742310_1486, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58234, dest: /172.20.1.17:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742310_1486, duration(ns): 1750985
2025-03-26 02:26:35,799 INFO terminating
2025-03-26 02:26:35,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52692, dest: /172.20.1.16:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742310_1486, duration(ns): 2713990
2025-03-26 02:26:35,800 INFO terminating
2025-03-26 02:26:35,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742311_1487, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_
2025-03-26 02:26:35,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742311_1487 src: /172.20.1.14:52702 dest: /172.20.1.16:9866
2025-03-26 02:26:35,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742311_1487 src: /172.20.1.16:58242 dest: /172.20.1.17:9866
2025-03-26 02:26:35,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742311_1487 src: /172.20.1.17:48754 dest: /172.20.1.15:9866
2025-03-26 02:26:35,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48754, dest: /172.20.1.15:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742311_1487, duration(ns): 1259098
2025-03-26 02:26:35,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742311_1487, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58242, dest: /172.20.1.17:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742311_1487, duration(ns): 1419864
2025-03-26 02:26:35,814 INFO terminating
2025-03-26 02:26:35,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52702, dest: /172.20.1.16:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742311_1487, duration(ns): 2174683
2025-03-26 02:26:35,815 INFO terminating
2025-03-26 02:26:35,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742312_1488, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_
2025-03-26 02:26:35,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742312_1488 src: /172.20.1.14:48448 dest: /172.20.1.15:9866
2025-03-26 02:26:35,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742312_1488 src: /172.20.1.15:40546 dest: /172.20.1.17:9866
2025-03-26 02:26:35,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742312_1488 src: /172.20.1.17:52042 dest: /172.20.1.16:9866
2025-03-26 02:26:35,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52042, dest: /172.20.1.16:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742312_1488, duration(ns): 1052950
2025-03-26 02:26:35,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742312_1488, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48448, dest: /172.20.1.15:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742312_1488, duration(ns): 2543892
2025-03-26 02:26:35,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40546, dest: /172.20.1.17:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742312_1488, duration(ns): 1713093
2025-03-26 02:26:35,825 INFO terminating
2025-03-26 02:26:35,825 INFO terminating
2025-03-26 02:26:35,826 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1489, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_
2025-03-26 02:26:35,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742313_1489 src: /172.20.1.14:38510 dest: /172.20.1.17:9866
2025-03-26 02:26:35,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742313_1489 src: /172.20.1.17:48768 dest: /172.20.1.15:9866
2025-03-26 02:26:35,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742313_1489 src: /172.20.1.15:60138 dest: /172.20.1.16:9866
2025-03-26 02:26:35,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60138, dest: /172.20.1.16:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742313_1489, duration(ns): 1224575
2025-03-26 02:26:35,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48768, dest: /172.20.1.15:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742313_1489, duration(ns): 2148023
2025-03-26 02:26:35,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742313_1489, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,836 INFO terminating
2025-03-26 02:26:35,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38510, dest: /172.20.1.17:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742313_1489, duration(ns): 2172493
2025-03-26 02:26:35,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,838 INFO terminating
2025-03-26 02:26:35,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,845 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1490, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_
2025-03-26 02:26:35,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742314_1490 src: /172.20.1.14:52704 dest: /172.20.1.16:9866
2025-03-26 02:26:35,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742314_1490 src: /172.20.1.16:58244 dest: /172.20.1.17:9866
2025-03-26 02:26:35,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742314_1490 src: /172.20.1.17:48776 dest: /172.20.1.15:9866
2025-03-26 02:26:35,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48776, dest: /172.20.1.15:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742314_1490, duration(ns): 1562365
2025-03-26 02:26:35,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742314_1490, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58244, dest: /172.20.1.17:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742314_1490, duration(ns): 1707883
2025-03-26 02:26:35,856 INFO terminating
2025-03-26 02:26:35,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52704, dest: /172.20.1.16:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742314_1490, duration(ns): 3113983
2025-03-26 02:26:35,857 INFO terminating
2025-03-26 02:26:35,858 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1491, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_
2025-03-26 02:26:35,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742315_1491 src: /172.20.1.14:52706 dest: /172.20.1.16:9866
2025-03-26 02:26:35,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742315_1491 src: /172.20.1.16:41912 dest: /172.20.1.15:9866
2025-03-26 02:26:35,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742315_1491 src: /172.20.1.15:40552 dest: /172.20.1.17:9866
2025-03-26 02:26:35,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40552, dest: /172.20.1.17:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742315_1491, duration(ns): 904933
2025-03-26 02:26:35,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742315_1491, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52706, dest: /172.20.1.16:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742315_1491, duration(ns): 1665326
2025-03-26 02:26:35,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41912, dest: /172.20.1.15:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742315_1491, duration(ns): 1540730
2025-03-26 02:26:35,869 INFO terminating
2025-03-26 02:26:35,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,870 INFO terminating
2025-03-26 02:26:35,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1492, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_
2025-03-26 02:26:35,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742316_1492 src: /172.20.1.14:38512 dest: /172.20.1.17:9866
2025-03-26 02:26:35,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742316_1492 src: /172.20.1.17:52058 dest: /172.20.1.16:9866
2025-03-26 02:26:35,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742316_1492 src: /172.20.1.16:41920 dest: /172.20.1.15:9866
2025-03-26 02:26:35,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41920, dest: /172.20.1.15:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742316_1492, duration(ns): 1103548
2025-03-26 02:26:35,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742316_1492, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52058, dest: /172.20.1.16:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742316_1492, duration(ns): 1291600
2025-03-26 02:26:35,880 INFO terminating
2025-03-26 02:26:35,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38512, dest: /172.20.1.17:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742316_1492, duration(ns): 2019487
2025-03-26 02:26:35,881 INFO terminating
2025-03-26 02:26:35,882 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1493, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:26:35,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742317_1493 src: /172.20.1.14:48452 dest: /172.20.1.15:9866
2025-03-26 02:26:35,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742317_1493 src: /172.20.1.15:40568 dest: /172.20.1.17:9866
2025-03-26 02:26:35,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742317_1493 src: /172.20.1.17:52070 dest: /172.20.1.16:9866
2025-03-26 02:26:35,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52070, dest: /172.20.1.16:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742317_1493, duration(ns): 1322821
2025-03-26 02:26:35,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742317_1493, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48452, dest: /172.20.1.15:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742317_1493, duration(ns): 2773268
2025-03-26 02:26:35,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40568, dest: /172.20.1.17:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742317_1493, duration(ns): 1977447
2025-03-26 02:26:35,893 INFO terminating
2025-03-26 02:26:35,893 INFO terminating
2025-03-26 02:26:35,894 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1494, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:26:35,899 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,899 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742318_1494 src: /172.20.1.14:48456 dest: /172.20.1.15:9866
2025-03-26 02:26:35,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742318_1494 src: /172.20.1.15:60142 dest: /172.20.1.16:9866
2025-03-26 02:26:35,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742318_1494 src: /172.20.1.16:58248 dest: /172.20.1.17:9866
2025-03-26 02:26:35,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58248, dest: /172.20.1.17:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742318_1494, duration(ns): 1129856
2025-03-26 02:26:35,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742318_1494, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60142, dest: /172.20.1.16:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742318_1494, duration(ns): 1903084
2025-03-26 02:26:35,908 INFO terminating
2025-03-26 02:26:35,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48456, dest: /172.20.1.15:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742318_1494, duration(ns): 4688240
2025-03-26 02:26:35,909 INFO terminating
2025-03-26 02:26:35,910 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1495, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_
2025-03-26 02:26:35,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742319_1495 src: /172.20.1.14:52708 dest: /172.20.1.16:9866
2025-03-26 02:26:35,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742319_1495 src: /172.20.1.16:58262 dest: /172.20.1.17:9866
2025-03-26 02:26:35,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742319_1495 src: /172.20.1.17:48792 dest: /172.20.1.15:9866
2025-03-26 02:26:35,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48792, dest: /172.20.1.15:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742319_1495, duration(ns): 949812
2025-03-26 02:26:35,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742319_1495, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58262, dest: /172.20.1.17:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742319_1495, duration(ns): 1121321
2025-03-26 02:26:35,919 INFO terminating
2025-03-26 02:26:35,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52708, dest: /172.20.1.16:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742319_1495, duration(ns): 2064022
2025-03-26 02:26:35,920 INFO terminating
2025-03-26 02:26:35,921 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1496, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_
2025-03-26 02:26:35,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742320_1496 src: /172.20.1.14:52724 dest: /172.20.1.16:9866
2025-03-26 02:26:35,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742320_1496 src: /172.20.1.16:58274 dest: /172.20.1.17:9866
2025-03-26 02:26:35,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742320_1496 src: /172.20.1.17:48808 dest: /172.20.1.15:9866
2025-03-26 02:26:35,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48808, dest: /172.20.1.15:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742320_1496, duration(ns): 1458356
2025-03-26 02:26:35,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742320_1496, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58274, dest: /172.20.1.17:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742320_1496, duration(ns): 1635249
2025-03-26 02:26:35,938 INFO terminating
2025-03-26 02:26:35,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52724, dest: /172.20.1.16:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742320_1496, duration(ns): 2712613
2025-03-26 02:26:35,939 INFO terminating
2025-03-26 02:26:35,940 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1497, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_
2025-03-26 02:26:35,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742321_1497 src: /172.20.1.14:38524 dest: /172.20.1.17:9866
2025-03-26 02:26:35,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742321_1497 src: /172.20.1.17:48822 dest: /172.20.1.15:9866
2025-03-26 02:26:35,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742321_1497 src: /172.20.1.15:60144 dest: /172.20.1.16:9866
2025-03-26 02:26:35,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60144, dest: /172.20.1.16:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742321_1497, duration(ns): 1134889
2025-03-26 02:26:35,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48822, dest: /172.20.1.15:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742321_1497, duration(ns): 1534481
2025-03-26 02:26:35,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742321_1497, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,949 INFO terminating
2025-03-26 02:26:35,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38524, dest: /172.20.1.17:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742321_1497, duration(ns): 1601858
2025-03-26 02:26:35,950 INFO terminating
2025-03-26 02:26:35,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1498, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_
2025-03-26 02:26:35,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742322_1498 src: /172.20.1.14:52730 dest: /172.20.1.16:9866
2025-03-26 02:26:35,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742322_1498 src: /172.20.1.16:41932 dest: /172.20.1.15:9866
2025-03-26 02:26:35,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742322_1498 src: /172.20.1.15:40584 dest: /172.20.1.17:9866
2025-03-26 02:26:35,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40584, dest: /172.20.1.17:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742322_1498, duration(ns): 806243
2025-03-26 02:26:35,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41932, dest: /172.20.1.15:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742322_1498, duration(ns): 1186870
2025-03-26 02:26:35,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742322_1498, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,959 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52730, dest: /172.20.1.16:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742322_1498, duration(ns): 1287788
2025-03-26 02:26:35,959 INFO terminating
2025-03-26 02:26:35,959 INFO terminating
2025-03-26 02:26:35,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1499, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_
2025-03-26 02:26:35,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742323_1499 src: /172.20.1.14:52734 dest: /172.20.1.16:9866
2025-03-26 02:26:35,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742323_1499 src: /172.20.1.16:58284 dest: /172.20.1.17:9866
2025-03-26 02:26:35,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742323_1499 src: /172.20.1.17:48836 dest: /172.20.1.15:9866
2025-03-26 02:26:35,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48836, dest: /172.20.1.15:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742323_1499, duration(ns): 908664
2025-03-26 02:26:35,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742323_1499, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52734, dest: /172.20.1.16:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742323_1499, duration(ns): 1307767
2025-03-26 02:26:35,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58284, dest: /172.20.1.17:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742323_1499, duration(ns): 940597
2025-03-26 02:26:35,968 INFO terminating
2025-03-26 02:26:35,968 INFO terminating
2025-03-26 02:26:35,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1500, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_
2025-03-26 02:26:35,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742324_1500 src: /172.20.1.14:52736 dest: /172.20.1.16:9866
2025-03-26 02:26:35,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742324_1500 src: /172.20.1.16:41944 dest: /172.20.1.15:9866
2025-03-26 02:26:35,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742324_1500 src: /172.20.1.15:40586 dest: /172.20.1.17:9866
2025-03-26 02:26:35,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40586, dest: /172.20.1.17:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742324_1500, duration(ns): 675627
2025-03-26 02:26:35,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41944, dest: /172.20.1.15:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742324_1500, duration(ns): 1017571
2025-03-26 02:26:35,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742324_1500, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,976 INFO terminating
2025-03-26 02:26:35,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52736, dest: /172.20.1.16:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742324_1500, duration(ns): 1204894
2025-03-26 02:26:35,977 INFO terminating
2025-03-26 02:26:35,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1501, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:26:35,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742325_1501 src: /172.20.1.14:52744 dest: /172.20.1.16:9866
2025-03-26 02:26:35,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742325_1501 src: /172.20.1.16:58292 dest: /172.20.1.17:9866
2025-03-26 02:26:35,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742325_1501 src: /172.20.1.17:48852 dest: /172.20.1.15:9866
2025-03-26 02:26:35,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48852, dest: /172.20.1.15:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742325_1501, duration(ns): 624865
2025-03-26 02:26:35,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742325_1501, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52744, dest: /172.20.1.16:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742325_1501, duration(ns): 1070253
2025-03-26 02:26:35,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58292, dest: /172.20.1.17:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742325_1501, duration(ns): 762161
2025-03-26 02:26:35,985 INFO terminating
2025-03-26 02:26:35,985 INFO terminating
2025-03-26 02:26:35,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1502, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_
2025-03-26 02:26:35,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742326_1502 src: /172.20.1.14:38534 dest: /172.20.1.17:9866
2025-03-26 02:26:35,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742326_1502 src: /172.20.1.17:52084 dest: /172.20.1.16:9866
2025-03-26 02:26:35,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742326_1502 src: /172.20.1.16:41952 dest: /172.20.1.15:9866
2025-03-26 02:26:35,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41952, dest: /172.20.1.15:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742326_1502, duration(ns): 705316
2025-03-26 02:26:35,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52084, dest: /172.20.1.16:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742326_1502, duration(ns): 859822
2025-03-26 02:26:35,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742326_1502, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:35,992 INFO terminating
2025-03-26 02:26:35,993 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:35,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38534, dest: /172.20.1.17:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742326_1502, duration(ns): 982923
2025-03-26 02:26:35,993 INFO terminating
2025-03-26 02:26:35,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1503, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_
2025-03-26 02:26:35,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742327_1503 src: /172.20.1.14:52748 dest: /172.20.1.16:9866
2025-03-26 02:26:35,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742327_1503 src: /172.20.1.16:58306 dest: /172.20.1.17:9866
2025-03-26 02:26:35,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742327_1503 src: /172.20.1.17:48854 dest: /172.20.1.15:9866
2025-03-26 02:26:36,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58306, dest: /172.20.1.17:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742327_1503, duration(ns): 1155992
2025-03-26 02:26:36,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48854, dest: /172.20.1.15:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742327_1503, duration(ns): 679550
2025-03-26 02:26:36,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742327_1503, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,001 INFO terminating
2025-03-26 02:26:36,004 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52748, dest: /172.20.1.16:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742327_1503, duration(ns): 1490443
2025-03-26 02:26:36,004 INFO terminating
2025-03-26 02:26:36,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1504, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:26:36,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742328_1504 src: /172.20.1.14:48464 dest: /172.20.1.15:9866
2025-03-26 02:26:36,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742328_1504 src: /172.20.1.15:40602 dest: /172.20.1.17:9866
2025-03-26 02:26:36,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742328_1504 src: /172.20.1.17:52092 dest: /172.20.1.16:9866
2025-03-26 02:26:36,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48464, dest: /172.20.1.15:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742328_1504, duration(ns): 1259313
2025-03-26 02:26:36,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40602, dest: /172.20.1.17:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742328_1504, duration(ns): 922057
2025-03-26 02:26:36,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52092, dest: /172.20.1.16:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742328_1504, duration(ns): 685535
2025-03-26 02:26:36,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742328_1504, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,013 INFO terminating
2025-03-26 02:26:36,013 INFO terminating
2025-03-26 02:26:36,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,017 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1505, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_
2025-03-26 02:26:36,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742329_1505 src: /172.20.1.14:38548 dest: /172.20.1.17:9866
2025-03-26 02:26:36,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742329_1505 src: /172.20.1.17:48856 dest: /172.20.1.15:9866
2025-03-26 02:26:36,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742329_1505 src: /172.20.1.15:60160 dest: /172.20.1.16:9866
2025-03-26 02:26:36,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60160, dest: /172.20.1.16:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742329_1505, duration(ns): 591516
2025-03-26 02:26:36,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48856, dest: /172.20.1.15:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742329_1505, duration(ns): 6790644
2025-03-26 02:26:36,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742329_1505, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38548, dest: /172.20.1.17:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742329_1505, duration(ns): 7187621
2025-03-26 02:26:36,028 INFO terminating
2025-03-26 02:26:36,029 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,029 INFO terminating
2025-03-26 02:26:36,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1506, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_
2025-03-26 02:26:36,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742330_1506 src: /172.20.1.14:48476 dest: /172.20.1.15:9866
2025-03-26 02:26:36,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742330_1506 src: /172.20.1.15:40604 dest: /172.20.1.17:9866
2025-03-26 02:26:36,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742330_1506 src: /172.20.1.17:52100 dest: /172.20.1.16:9866
2025-03-26 02:26:36,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52100, dest: /172.20.1.16:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742330_1506, duration(ns): 2131699
2025-03-26 02:26:36,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742330_1506, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48476, dest: /172.20.1.15:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742330_1506, duration(ns): 4264680
2025-03-26 02:26:36,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40604, dest: /172.20.1.17:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742330_1506, duration(ns): 3902571
2025-03-26 02:26:36,041 INFO terminating
2025-03-26 02:26:36,041 INFO terminating
2025-03-26 02:26:36,042 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1507, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_
2025-03-26 02:26:36,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742331_1507 src: /172.20.1.14:52754 dest: /172.20.1.16:9866
2025-03-26 02:26:36,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742331_1507 src: /172.20.1.16:58322 dest: /172.20.1.17:9866
2025-03-26 02:26:36,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742331_1507 src: /172.20.1.17:48862 dest: /172.20.1.15:9866
2025-03-26 02:26:36,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48862, dest: /172.20.1.15:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742331_1507, duration(ns): 808142
2025-03-26 02:26:36,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742331_1507, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,050 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52754, dest: /172.20.1.16:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742331_1507, duration(ns): 1174635
2025-03-26 02:26:36,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58322, dest: /172.20.1.17:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742331_1507, duration(ns): 982249
2025-03-26 02:26:36,050 INFO terminating
2025-03-26 02:26:36,050 INFO terminating
2025-03-26 02:26:36,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1508, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_
2025-03-26 02:26:36,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742332_1508 src: /172.20.1.14:38550 dest: /172.20.1.17:9866
2025-03-26 02:26:36,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742332_1508 src: /172.20.1.17:52108 dest: /172.20.1.16:9866
2025-03-26 02:26:36,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742332_1508 src: /172.20.1.16:41964 dest: /172.20.1.15:9866
2025-03-26 02:26:36,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046 to 172.20.1.16:9866
2025-03-26 02:26:36,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38550, dest: /172.20.1.17:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742332_1508, duration(ns): 5357373
2025-03-26 02:26:36,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41964, dest: /172.20.1.15:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742332_1508, duration(ns): 4537174
2025-03-26 02:26:36,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52108, dest: /172.20.1.16:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742332_1508, duration(ns): 4966919
2025-03-26 02:26:36,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048 to 172.20.1.16:9866
2025-03-26 02:26:36,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742332_1508, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,063 INFO terminating
2025-03-26 02:26:36,064 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,064 INFO terminating
2025-03-26 02:26:36,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1509, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_
2025-03-26 02:26:36,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742333_1509 src: /172.20.1.14:52758 dest: /172.20.1.16:9866
2025-03-26 02:26:36,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742333_1509 src: /172.20.1.16:41972 dest: /172.20.1.15:9866
2025-03-26 02:26:36,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742333_1509 src: /172.20.1.15:40614 dest: /172.20.1.17:9866
2025-03-26 02:26:36,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046 src: /172.20.1.15:60164 dest: /172.20.1.16:9866
2025-03-26 02:26:36,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048 src: /172.20.1.15:60176 dest: /172.20.1.16:9866
2025-03-26 02:26:36,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40614, dest: /172.20.1.17:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742333_1509, duration(ns): 11327693
2025-03-26 02:26:36,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41972, dest: /172.20.1.15:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742333_1509, duration(ns): 9954973
2025-03-26 02:26:36,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742333_1509, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,084 INFO terminating
2025-03-26 02:26:36,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52758, dest: /172.20.1.16:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742333_1509, duration(ns): 10354124
2025-03-26 02:26:36,085 INFO terminating
2025-03-26 02:26:36,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046 (numBytes=3212) to /172.20.1.16:9866
2025-03-26 02:26:36,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741870_1046 src: /172.20.1.15:60164 dest: /172.20.1.16:9866 of size 3212
2025-03-26 02:26:36,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1510, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_
2025-03-26 02:26:36,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048 (numBytes=2818) to /172.20.1.16:9866
2025-03-26 02:26:36,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741872_1048 src: /172.20.1.15:60176 dest: /172.20.1.16:9866 of size 2818
2025-03-26 02:26:36,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742334_1510 src: /172.20.1.14:52764 dest: /172.20.1.16:9866
2025-03-26 02:26:36,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742334_1510 src: /172.20.1.16:41978 dest: /172.20.1.15:9866
2025-03-26 02:26:36,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742334_1510 src: /172.20.1.15:40628 dest: /172.20.1.17:9866
2025-03-26 02:26:36,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40628, dest: /172.20.1.17:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742334_1510, duration(ns): 747449
2025-03-26 02:26:36,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41978, dest: /172.20.1.15:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742334_1510, duration(ns): 1422604
2025-03-26 02:26:36,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742334_1510, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,093 INFO terminating
2025-03-26 02:26:36,094 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52764, dest: /172.20.1.16:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742334_1510, duration(ns): 1807815
2025-03-26 02:26:36,094 INFO terminating
2025-03-26 02:26:36,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1511, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_
2025-03-26 02:26:36,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742335_1511 src: /172.20.1.14:48486 dest: /172.20.1.15:9866
2025-03-26 02:26:36,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742335_1511 src: /172.20.1.15:60192 dest: /172.20.1.16:9866
2025-03-26 02:26:36,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742335_1511 src: /172.20.1.16:58326 dest: /172.20.1.17:9866
2025-03-26 02:26:36,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60192, dest: /172.20.1.16:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742335_1511, duration(ns): 840503
2025-03-26 02:26:36,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58326, dest: /172.20.1.17:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742335_1511, duration(ns): 588401
2025-03-26 02:26:36,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742335_1511, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48486, dest: /172.20.1.15:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742335_1511, duration(ns): 1544196
2025-03-26 02:26:36,102 INFO terminating
2025-03-26 02:26:36,102 INFO terminating
2025-03-26 02:26:36,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1512, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_
2025-03-26 02:26:36,109 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742336_1512 src: /172.20.1.14:52766 dest: /172.20.1.16:9866
2025-03-26 02:26:36,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742336_1512 src: /172.20.1.16:41982 dest: /172.20.1.15:9866
2025-03-26 02:26:36,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742336_1512 src: /172.20.1.15:40634 dest: /172.20.1.17:9866
2025-03-26 02:26:36,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40634, dest: /172.20.1.17:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742336_1512, duration(ns): 887988
2025-03-26 02:26:36,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52766, dest: /172.20.1.16:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742336_1512, duration(ns): 1582841
2025-03-26 02:26:36,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41982, dest: /172.20.1.15:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742336_1512, duration(ns): 1110407
2025-03-26 02:26:36,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742336_1512, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,114 INFO terminating
2025-03-26 02:26:36,115 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,115 INFO terminating
2025-03-26 02:26:36,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742337_1513, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:26:36,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742337_1513 src: /172.20.1.14:48500 dest: /172.20.1.15:9866
2025-03-26 02:26:36,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742337_1513 src: /172.20.1.15:40642 dest: /172.20.1.17:9866
2025-03-26 02:26:36,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742337_1513 src: /172.20.1.17:52114 dest: /172.20.1.16:9866
2025-03-26 02:26:36,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52114, dest: /172.20.1.16:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742337_1513, duration(ns): 671255
2025-03-26 02:26:36,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742337_1513, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48500, dest: /172.20.1.15:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742337_1513, duration(ns): 2538323
2025-03-26 02:26:36,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40642, dest: /172.20.1.17:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742337_1513, duration(ns): 877348
2025-03-26 02:26:36,128 INFO terminating
2025-03-26 02:26:36,128 INFO terminating
2025-03-26 02:26:36,129 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742338_1514, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_
2025-03-26 02:26:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742338_1514 src: /172.20.1.14:38554 dest: /172.20.1.17:9866
2025-03-26 02:26:36,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742338_1514 src: /172.20.1.17:52120 dest: /172.20.1.16:9866
2025-03-26 02:26:36,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742338_1514 src: /172.20.1.16:41988 dest: /172.20.1.15:9866
2025-03-26 02:26:36,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41988, dest: /172.20.1.15:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742338_1514, duration(ns): 658131
2025-03-26 02:26:36,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52120, dest: /172.20.1.16:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742338_1514, duration(ns): 782317
2025-03-26 02:26:36,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742338_1514, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,135 INFO terminating
2025-03-26 02:26:36,136 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38554, dest: /172.20.1.17:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742338_1514, duration(ns): 1026293
2025-03-26 02:26:36,136 INFO terminating
2025-03-26 02:26:36,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742339_1515, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_
2025-03-26 02:26:36,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742339_1515 src: /172.20.1.14:38556 dest: /172.20.1.17:9866
2025-03-26 02:26:36,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742339_1515 src: /172.20.1.17:48874 dest: /172.20.1.15:9866
2025-03-26 02:26:36,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742339_1515 src: /172.20.1.15:60206 dest: /172.20.1.16:9866
2025-03-26 02:26:36,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38556, dest: /172.20.1.17:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742339_1515, duration(ns): 1617163
2025-03-26 02:26:36,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60206, dest: /172.20.1.16:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742339_1515, duration(ns): 863723
2025-03-26 02:26:36,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48874, dest: /172.20.1.15:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742339_1515, duration(ns): 1558310
2025-03-26 02:26:36,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742339_1515, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,144 INFO terminating
2025-03-26 02:26:36,144 INFO terminating
2025-03-26 02:26:36,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742340_1516, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:26:36,152 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,152 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742340_1516 src: /172.20.1.14:48502 dest: /172.20.1.15:9866
2025-03-26 02:26:36,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742340_1516 src: /172.20.1.15:40648 dest: /172.20.1.17:9866
2025-03-26 02:26:36,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742340_1516 src: /172.20.1.17:52132 dest: /172.20.1.16:9866
2025-03-26 02:26:36,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40648, dest: /172.20.1.17:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742340_1516, duration(ns): 1067887
2025-03-26 02:26:36,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52132, dest: /172.20.1.16:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742340_1516, duration(ns): 907002
2025-03-26 02:26:36,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742340_1516, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,159 INFO terminating
2025-03-26 02:26:36,160 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48502, dest: /172.20.1.15:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742340_1516, duration(ns): 1438307
2025-03-26 02:26:36,160 INFO terminating
2025-03-26 02:26:36,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742341_1517, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_
2025-03-26 02:26:36,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742341_1517 src: /172.20.1.14:48512 dest: /172.20.1.15:9866
2025-03-26 02:26:36,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742341_1517 src: /172.20.1.15:60212 dest: /172.20.1.16:9866
2025-03-26 02:26:36,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742341_1517 src: /172.20.1.16:58342 dest: /172.20.1.17:9866
2025-03-26 02:26:36,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60212, dest: /172.20.1.16:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742341_1517, duration(ns): 936458
2025-03-26 02:26:36,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58342, dest: /172.20.1.17:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742341_1517, duration(ns): 675973
2025-03-26 02:26:36,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742341_1517, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,171 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48512, dest: /172.20.1.15:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742341_1517, duration(ns): 1679398
2025-03-26 02:26:36,171 INFO terminating
2025-03-26 02:26:36,171 INFO terminating
2025-03-26 02:26:36,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742342_1518, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_
2025-03-26 02:26:36,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742342_1518 src: /172.20.1.14:48514 dest: /172.20.1.15:9866
2025-03-26 02:26:36,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742342_1518 src: /172.20.1.15:40654 dest: /172.20.1.17:9866
2025-03-26 02:26:36,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742342_1518 src: /172.20.1.17:52138 dest: /172.20.1.16:9866
2025-03-26 02:26:36,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52138, dest: /172.20.1.16:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742342_1518, duration(ns): 745097
2025-03-26 02:26:36,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742342_1518, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48514, dest: /172.20.1.15:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742342_1518, duration(ns): 1283623
2025-03-26 02:26:36,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40654, dest: /172.20.1.17:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742342_1518, duration(ns): 925883
2025-03-26 02:26:36,179 INFO terminating
2025-03-26 02:26:36,179 INFO terminating
2025-03-26 02:26:36,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742343_1519, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_
2025-03-26 02:26:36,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742343_1519 src: /172.20.1.14:48530 dest: /172.20.1.15:9866
2025-03-26 02:26:36,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742343_1519 src: /172.20.1.15:60222 dest: /172.20.1.16:9866
2025-03-26 02:26:36,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742343_1519 src: /172.20.1.16:58348 dest: /172.20.1.17:9866
2025-03-26 02:26:36,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60222, dest: /172.20.1.16:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742343_1519, duration(ns): 826788
2025-03-26 02:26:36,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58348, dest: /172.20.1.17:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742343_1519, duration(ns): 543747
2025-03-26 02:26:36,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742343_1519, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,186 INFO terminating
2025-03-26 02:26:36,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48530, dest: /172.20.1.15:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742343_1519, duration(ns): 1171599
2025-03-26 02:26:36,187 INFO terminating
2025-03-26 02:26:36,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742344_1520, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_
2025-03-26 02:26:36,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742344_1520 src: /172.20.1.14:52768 dest: /172.20.1.16:9866
2025-03-26 02:26:36,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742344_1520 src: /172.20.1.16:41994 dest: /172.20.1.15:9866
2025-03-26 02:26:36,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742344_1520 src: /172.20.1.15:40656 dest: /172.20.1.17:9866
2025-03-26 02:26:36,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40656, dest: /172.20.1.17:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742344_1520, duration(ns): 729939
2025-03-26 02:26:36,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:41994, dest: /172.20.1.15:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742344_1520, duration(ns): 1009725
2025-03-26 02:26:36,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742344_1520, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,199 INFO terminating
2025-03-26 02:26:36,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52768, dest: /172.20.1.16:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742344_1520, duration(ns): 1188929
2025-03-26 02:26:36,200 INFO terminating
2025-03-26 02:26:36,201 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,207 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742345_1521, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:26:36,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742345_1521 src: /172.20.1.14:52778 dest: /172.20.1.16:9866
2025-03-26 02:26:36,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742345_1521 src: /172.20.1.16:58350 dest: /172.20.1.17:9866
2025-03-26 02:26:36,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742345_1521 src: /172.20.1.17:48890 dest: /172.20.1.15:9866
2025-03-26 02:26:36,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58350, dest: /172.20.1.17:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742345_1521, duration(ns): 965639
2025-03-26 02:26:36,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48890, dest: /172.20.1.15:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742345_1521, duration(ns): 846521
2025-03-26 02:26:36,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742345_1521, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,211 INFO terminating
2025-03-26 02:26:36,212 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52778, dest: /172.20.1.16:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742345_1521, duration(ns): 1062243
2025-03-26 02:26:36,212 INFO terminating
2025-03-26 02:26:36,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742346_1522, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:26:36,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742346_1522 src: /172.20.1.14:38558 dest: /172.20.1.17:9866
2025-03-26 02:26:36,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742346_1522 src: /172.20.1.15:60224 dest: /172.20.1.16:9866
2025-03-26 02:26:36,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742346_1522 src: /172.20.1.17:48898 dest: /172.20.1.15:9866
2025-03-26 02:26:36,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60224, dest: /172.20.1.16:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742346_1522, duration(ns): 799883
2025-03-26 02:26:36,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742346_1522, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,220 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38558, dest: /172.20.1.17:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742346_1522, duration(ns): 1568167
2025-03-26 02:26:36,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48898, dest: /172.20.1.15:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742346_1522, duration(ns): 1495035
2025-03-26 02:26:36,220 INFO terminating
2025-03-26 02:26:36,220 INFO terminating
2025-03-26 02:26:36,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742347_1523, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_
2025-03-26 02:26:36,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742347_1523 src: /172.20.1.14:52786 dest: /172.20.1.16:9866
2025-03-26 02:26:36,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742347_1523 src: /172.20.1.16:58364 dest: /172.20.1.17:9866
2025-03-26 02:26:36,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742347_1523 src: /172.20.1.17:48912 dest: /172.20.1.15:9866
2025-03-26 02:26:36,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58364, dest: /172.20.1.17:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742347_1523, duration(ns): 1922927
2025-03-26 02:26:36,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48912, dest: /172.20.1.15:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742347_1523, duration(ns): 1799240
2025-03-26 02:26:36,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742347_1523, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52786, dest: /172.20.1.16:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742347_1523, duration(ns): 2100659
2025-03-26 02:26:36,229 INFO terminating
2025-03-26 02:26:36,229 INFO terminating
2025-03-26 02:26:36,230 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,232 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742348_1524, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:26:36,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742348_1524 src: /172.20.1.14:48534 dest: /172.20.1.15:9866
2025-03-26 02:26:36,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742348_1524 src: /172.20.1.15:40670 dest: /172.20.1.17:9866
2025-03-26 02:26:36,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742348_1524 src: /172.20.1.17:52144 dest: /172.20.1.16:9866
2025-03-26 02:26:36,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52144, dest: /172.20.1.16:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742348_1524, duration(ns): 685763
2025-03-26 02:26:36,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48534, dest: /172.20.1.15:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742348_1524, duration(ns): 1583280
2025-03-26 02:26:36,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40670, dest: /172.20.1.17:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742348_1524, duration(ns): 1226078
2025-03-26 02:26:36,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742348_1524, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,237 INFO terminating
2025-03-26 02:26:36,237 INFO terminating
2025-03-26 02:26:36,238 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,241 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742349_1525, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_
2025-03-26 02:26:36,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742349_1525 src: /172.20.1.14:38566 dest: /172.20.1.17:9866
2025-03-26 02:26:36,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742349_1525 src: /172.20.1.17:48914 dest: /172.20.1.15:9866
2025-03-26 02:26:36,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742349_1525 src: /172.20.1.15:60236 dest: /172.20.1.16:9866
2025-03-26 02:26:36,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60236, dest: /172.20.1.16:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742349_1525, duration(ns): 15581625
2025-03-26 02:26:36,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48914, dest: /172.20.1.15:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742349_1525, duration(ns): 16341149
2025-03-26 02:26:36,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742349_1525, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,261 INFO terminating
2025-03-26 02:26:36,262 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38566, dest: /172.20.1.17:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742349_1525, duration(ns): 17039858
2025-03-26 02:26:36,262 INFO terminating
2025-03-26 02:26:36,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742350_1526, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_
2025-03-26 02:26:36,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742350_1526 src: /172.20.1.14:52796 dest: /172.20.1.16:9866
2025-03-26 02:26:36,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742350_1526 src: /172.20.1.16:58372 dest: /172.20.1.17:9866
2025-03-26 02:26:36,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742350_1526 src: /172.20.1.17:48922 dest: /172.20.1.15:9866
2025-03-26 02:26:36,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48922, dest: /172.20.1.15:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742350_1526, duration(ns): 1122563
2025-03-26 02:26:36,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742350_1526, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58372, dest: /172.20.1.17:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742350_1526, duration(ns): 1221365
2025-03-26 02:26:36,273 INFO terminating
2025-03-26 02:26:36,274 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52796, dest: /172.20.1.16:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742350_1526, duration(ns): 1867912
2025-03-26 02:26:36,274 INFO terminating
2025-03-26 02:26:36,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742351_1527, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:26:36,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742351_1527 src: /172.20.1.14:48548 dest: /172.20.1.15:9866
2025-03-26 02:26:36,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742351_1527 src: /172.20.1.15:40676 dest: /172.20.1.17:9866
2025-03-26 02:26:36,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742351_1527 src: /172.20.1.17:52160 dest: /172.20.1.16:9866
2025-03-26 02:26:36,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40676, dest: /172.20.1.17:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742351_1527, duration(ns): 1568619
2025-03-26 02:26:36,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52160, dest: /172.20.1.16:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742351_1527, duration(ns): 934835
2025-03-26 02:26:36,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742351_1527, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,284 INFO terminating
2025-03-26 02:26:36,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48548, dest: /172.20.1.15:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742351_1527, duration(ns): 2364884
2025-03-26 02:26:36,285 INFO terminating
2025-03-26 02:26:36,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742352_1528, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_
2025-03-26 02:26:36,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742352_1528 src: /172.20.1.14:48560 dest: /172.20.1.15:9866
2025-03-26 02:26:36,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742352_1528 src: /172.20.1.15:40688 dest: /172.20.1.17:9866
2025-03-26 02:26:36,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742352_1528 src: /172.20.1.17:52172 dest: /172.20.1.16:9866
2025-03-26 02:26:36,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52172, dest: /172.20.1.16:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742352_1528, duration(ns): 13893523
2025-03-26 02:26:36,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40688, dest: /172.20.1.17:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742352_1528, duration(ns): 1714444
2025-03-26 02:26:36,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742352_1528, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,333 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48560, dest: /172.20.1.15:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742352_1528, duration(ns): 15526226
2025-03-26 02:26:36,333 INFO terminating
2025-03-26 02:26:36,333 INFO terminating
2025-03-26 02:26:36,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742353_1529, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_
2025-03-26 02:26:36,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742353_1529 src: /172.20.1.14:52810 dest: /172.20.1.16:9866
2025-03-26 02:26:36,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742353_1529 src: /172.20.1.16:58374 dest: /172.20.1.17:9866
2025-03-26 02:26:36,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742353_1529 src: /172.20.1.17:48930 dest: /172.20.1.15:9866
2025-03-26 02:26:36,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48930, dest: /172.20.1.15:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742353_1529, duration(ns): 1608305
2025-03-26 02:26:36,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742353_1529, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58374, dest: /172.20.1.17:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742353_1529, duration(ns): 1392026
2025-03-26 02:26:36,349 INFO terminating
2025-03-26 02:26:36,350 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52810, dest: /172.20.1.16:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742353_1529, duration(ns): 2280164
2025-03-26 02:26:36,350 INFO terminating
2025-03-26 02:26:36,353 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742354_1530, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:26:36,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742354_1530 src: /172.20.1.14:52818 dest: /172.20.1.16:9866
2025-03-26 02:26:36,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742354_1530 src: /172.20.1.15:40694 dest: /172.20.1.17:9866
2025-03-26 02:26:36,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742354_1530 src: /172.20.1.16:42004 dest: /172.20.1.15:9866
2025-03-26 02:26:36,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40694, dest: /172.20.1.17:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742354_1530, duration(ns): 901350
2025-03-26 02:26:36,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42004, dest: /172.20.1.15:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742354_1530, duration(ns): 1667940
2025-03-26 02:26:36,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742354_1530, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,359 INFO terminating
2025-03-26 02:26:36,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52818, dest: /172.20.1.16:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742354_1530, duration(ns): 1677966
2025-03-26 02:26:36,360 INFO terminating
2025-03-26 02:26:36,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,364 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1531, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_
2025-03-26 02:26:36,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742355_1531 src: /172.20.1.14:38570 dest: /172.20.1.17:9866
2025-03-26 02:26:36,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742355_1531 src: /172.20.1.17:52178 dest: /172.20.1.16:9866
2025-03-26 02:26:36,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742355_1531 src: /172.20.1.16:42018 dest: /172.20.1.15:9866
2025-03-26 02:26:36,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42018, dest: /172.20.1.15:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742355_1531, duration(ns): 1079968
2025-03-26 02:26:36,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52178, dest: /172.20.1.16:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742355_1531, duration(ns): 1190582
2025-03-26 02:26:36,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742355_1531, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38570, dest: /172.20.1.17:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742355_1531, duration(ns): 1830949
2025-03-26 02:26:36,373 INFO terminating
2025-03-26 02:26:36,373 INFO terminating
2025-03-26 02:26:36,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1532, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_
2025-03-26 02:26:36,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742356_1532 src: /172.20.1.14:38586 dest: /172.20.1.17:9866
2025-03-26 02:26:36,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742356_1532 src: /172.20.1.17:48938 dest: /172.20.1.15:9866
2025-03-26 02:26:36,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742356_1532 src: /172.20.1.15:60248 dest: /172.20.1.16:9866
2025-03-26 02:26:36,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60248, dest: /172.20.1.16:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742356_1532, duration(ns): 986424
2025-03-26 02:26:36,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48938, dest: /172.20.1.15:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742356_1532, duration(ns): 1806147
2025-03-26 02:26:36,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742356_1532, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,384 INFO terminating
2025-03-26 02:26:36,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38586, dest: /172.20.1.17:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742356_1532, duration(ns): 1826441
2025-03-26 02:26:36,385 INFO terminating
2025-03-26 02:26:36,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1533, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_
2025-03-26 02:26:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742357_1533 src: /172.20.1.14:48576 dest: /172.20.1.15:9866
2025-03-26 02:26:36,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742357_1533 src: /172.20.1.15:60262 dest: /172.20.1.16:9866
2025-03-26 02:26:36,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742357_1533 src: /172.20.1.16:58388 dest: /172.20.1.17:9866
2025-03-26 02:26:36,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58388, dest: /172.20.1.17:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742357_1533, duration(ns): 818127
2025-03-26 02:26:36,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60262, dest: /172.20.1.16:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742357_1533, duration(ns): 1459619
2025-03-26 02:26:36,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742357_1533, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,395 INFO terminating
2025-03-26 02:26:36,396 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48576, dest: /172.20.1.15:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742357_1533, duration(ns): 2348226
2025-03-26 02:26:36,396 INFO terminating
2025-03-26 02:26:36,399 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1534, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_
2025-03-26 02:26:36,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742358_1534 src: /172.20.1.14:52834 dest: /172.20.1.16:9866
2025-03-26 02:26:36,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742358_1534 src: /172.20.1.16:58400 dest: /172.20.1.17:9866
2025-03-26 02:26:36,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742358_1534 src: /172.20.1.17:48942 dest: /172.20.1.15:9866
2025-03-26 02:26:36,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48942, dest: /172.20.1.15:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742358_1534, duration(ns): 1407591
2025-03-26 02:26:36,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742358_1534, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58400, dest: /172.20.1.17:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742358_1534, duration(ns): 1519286
2025-03-26 02:26:36,413 INFO terminating
2025-03-26 02:26:36,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52834, dest: /172.20.1.16:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742358_1534, duration(ns): 1816360
2025-03-26 02:26:36,414 INFO terminating
2025-03-26 02:26:36,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1535, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_
2025-03-26 02:26:36,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742359_1535 src: /172.20.1.14:52844 dest: /172.20.1.16:9866
2025-03-26 02:26:36,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742359_1535 src: /172.20.1.16:42020 dest: /172.20.1.15:9866
2025-03-26 02:26:36,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742359_1535 src: /172.20.1.15:40700 dest: /172.20.1.17:9866
2025-03-26 02:26:36,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40700, dest: /172.20.1.17:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742359_1535, duration(ns): 1653198
2025-03-26 02:26:36,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42020, dest: /172.20.1.15:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742359_1535, duration(ns): 2401704
2025-03-26 02:26:36,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742359_1535, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,441 INFO terminating
2025-03-26 02:26:36,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52844, dest: /172.20.1.16:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742359_1535, duration(ns): 1879951
2025-03-26 02:26:36,442 INFO terminating
2025-03-26 02:26:36,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,450 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1536, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_
2025-03-26 02:26:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742360_1536 src: /172.20.1.14:52860 dest: /172.20.1.16:9866
2025-03-26 02:26:36,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742360_1536 src: /172.20.1.16:58412 dest: /172.20.1.17:9866
2025-03-26 02:26:36,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742360_1536 src: /172.20.1.17:48952 dest: /172.20.1.15:9866
2025-03-26 02:26:36,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:48952, dest: /172.20.1.15:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742360_1536, duration(ns): 1137642
2025-03-26 02:26:36,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742360_1536, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:58412, dest: /172.20.1.17:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742360_1536, duration(ns): 1249530
2025-03-26 02:26:36,457 INFO terminating
2025-03-26 02:26:36,458 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52860, dest: /172.20.1.16:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742360_1536, duration(ns): 1982605
2025-03-26 02:26:36,458 INFO terminating
2025-03-26 02:26:36,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1537, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_
2025-03-26 02:26:36,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742361_1537 src: /172.20.1.14:48586 dest: /172.20.1.15:9866
2025-03-26 02:26:36,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742361_1537 src: /172.20.1.15:40714 dest: /172.20.1.17:9866
2025-03-26 02:26:36,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742361_1537 src: /172.20.1.17:52194 dest: /172.20.1.16:9866
2025-03-26 02:26:36,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40714, dest: /172.20.1.17:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742361_1537, duration(ns): 1432128
2025-03-26 02:26:36,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52194, dest: /172.20.1.16:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742361_1537, duration(ns): 1188595
2025-03-26 02:26:36,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742361_1537, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48586, dest: /172.20.1.15:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742361_1537, duration(ns): 2233840
2025-03-26 02:26:36,474 INFO terminating
2025-03-26 02:26:36,474 INFO terminating
2025-03-26 02:26:36,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1538, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_
2025-03-26 02:26:36,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742362_1538 src: /172.20.1.14:48588 dest: /172.20.1.15:9866
2025-03-26 02:26:36,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742362_1538 src: /172.20.1.15:40724 dest: /172.20.1.17:9866
2025-03-26 02:26:36,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742362_1538 src: /172.20.1.17:52204 dest: /172.20.1.16:9866
2025-03-26 02:26:36,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52204, dest: /172.20.1.16:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742362_1538, duration(ns): 1010972
2025-03-26 02:26:36,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742362_1538, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,491 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48588, dest: /172.20.1.15:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742362_1538, duration(ns): 2084733
2025-03-26 02:26:36,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:40724, dest: /172.20.1.17:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742362_1538, duration(ns): 1330669
2025-03-26 02:26:36,491 INFO terminating
2025-03-26 02:26:36,491 INFO terminating
2025-03-26 02:26:36,495 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1539, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_
2025-03-26 02:26:36,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742363_1539 src: /172.20.1.14:38602 dest: /172.20.1.17:9866
2025-03-26 02:26:36,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051 to 172.20.1.16:9866
2025-03-26 02:26:36,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053 to 172.20.1.16:9866
2025-03-26 02:26:36,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051 src: /172.20.1.17:52220 dest: /172.20.1.16:9866
2025-03-26 02:26:36,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053 src: /172.20.1.17:52216 dest: /172.20.1.16:9866
2025-03-26 02:26:36,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053 (numBytes=2533) to /172.20.1.16:9866
2025-03-26 02:26:36,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742363_1539 src: /172.20.1.17:52208 dest: /172.20.1.16:9866
2025-03-26 02:26:36,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051 (numBytes=2082) to /172.20.1.16:9866
2025-03-26 02:26:36,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741875_1051 src: /172.20.1.17:52220 dest: /172.20.1.16:9866 of size 2082
2025-03-26 02:26:36,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742363_1539 src: /172.20.1.16:42024 dest: /172.20.1.15:9866
2025-03-26 02:26:36,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741877_1053 src: /172.20.1.17:52216 dest: /172.20.1.16:9866 of size 2533
2025-03-26 02:26:36,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42024, dest: /172.20.1.15:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742363_1539, duration(ns): 1750794
2025-03-26 02:26:36,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:52208, dest: /172.20.1.16:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742363_1539, duration(ns): 1424078
2025-03-26 02:26:36,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742363_1539, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,508 INFO terminating
2025-03-26 02:26:36,509 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:38602, dest: /172.20.1.17:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 95dfd055-2daa-423b-a78c-81d3cae22127, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742363_1539, duration(ns): 1697138
2025-03-26 02:26:36,509 INFO terminating
2025-03-26 02:26:36,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1540, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_
2025-03-26 02:26:36,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,513 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,513 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,513 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742364_1540 src: /172.20.1.14:48598 dest: /172.20.1.15:9866
2025-03-26 02:26:36,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742364_1540 src: /172.20.1.15:60276 dest: /172.20.1.16:9866
2025-03-26 02:26:36,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48598, dest: /172.20.1.15:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742364_1540, duration(ns): 2431158
2025-03-26 02:26:36,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60276, dest: /172.20.1.16:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742364_1540, duration(ns): 2121418
2025-03-26 02:26:36,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742364_1540, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,518 INFO terminating
2025-03-26 02:26:36,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1541, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_
2025-03-26 02:26:36,535 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,535 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,535 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,535 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,535 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,535 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742365_1541 src: /172.20.1.14:52864 dest: /172.20.1.16:9866
2025-03-26 02:26:36,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742365_1541 src: /172.20.1.16:42038 dest: /172.20.1.15:9866
2025-03-26 02:26:36,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52864, dest: /172.20.1.16:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742365_1541, duration(ns): 525256
2025-03-26 02:26:36,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42038, dest: /172.20.1.15:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742365_1541, duration(ns): 488959
2025-03-26 02:26:36,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742365_1541, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,538 INFO terminating
2025-03-26 02:26:36,539 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,542 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1542, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_
2025-03-26 02:26:36,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,542 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,542 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,542 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742366_1542 src: /172.20.1.14:52872 dest: /172.20.1.16:9866
2025-03-26 02:26:36,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42044, dest: /172.20.1.15:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742366_1542, duration(ns): 361094
2025-03-26 02:26:36,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742366_1542, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742366_1542 src: /172.20.1.16:42044 dest: /172.20.1.15:9866
2025-03-26 02:26:36,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52872, dest: /172.20.1.16:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742366_1542, duration(ns): 487514
2025-03-26 02:26:36,548 INFO terminating
2025-03-26 02:26:36,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1543, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_
2025-03-26 02:26:36,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,553 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,553 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,553 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742367_1543 src: /172.20.1.14:52878 dest: /172.20.1.16:9866
2025-03-26 02:26:36,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742367_1543 src: /172.20.1.16:42048 dest: /172.20.1.15:9866
2025-03-26 02:26:36,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52878, dest: /172.20.1.16:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742367_1543, duration(ns): 580970
2025-03-26 02:26:36,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42048, dest: /172.20.1.15:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742367_1543, duration(ns): 417187
2025-03-26 02:26:36,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742367_1543, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,556 INFO terminating
2025-03-26 02:26:36,557 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1544, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_
2025-03-26 02:26:36,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,560 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,560 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,560 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742368_1544 src: /172.20.1.14:48600 dest: /172.20.1.15:9866
2025-03-26 02:26:36,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742368_1544 src: /172.20.1.15:60288 dest: /172.20.1.16:9866
2025-03-26 02:26:36,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60288, dest: /172.20.1.16:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742368_1544, duration(ns): 400892
2025-03-26 02:26:36,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742368_1544, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,563 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48600, dest: /172.20.1.15:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742368_1544, duration(ns): 665461
2025-03-26 02:26:36,563 INFO terminating
2025-03-26 02:26:36,566 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1545, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_
2025-03-26 02:26:36,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,566 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,566 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,566 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742369_1545 src: /172.20.1.14:52890 dest: /172.20.1.16:9866
2025-03-26 02:26:36,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742369_1545 src: /172.20.1.16:42054 dest: /172.20.1.15:9866
2025-03-26 02:26:36,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52890, dest: /172.20.1.16:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742369_1545, duration(ns): 521868
2025-03-26 02:26:36,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42054, dest: /172.20.1.15:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742369_1545, duration(ns): 376234
2025-03-26 02:26:36,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742369_1545, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,569 INFO terminating
2025-03-26 02:26:36,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1546, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_
2025-03-26 02:26:36,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,574 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,574 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,574 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742370_1546 src: /172.20.1.14:52900 dest: /172.20.1.16:9866
2025-03-26 02:26:36,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742370_1546 src: /172.20.1.16:42056 dest: /172.20.1.15:9866
2025-03-26 02:26:36,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42056, dest: /172.20.1.15:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742370_1546, duration(ns): 2119079
2025-03-26 02:26:36,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742370_1546, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,579 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52900, dest: /172.20.1.16:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742370_1546, duration(ns): 2285886
2025-03-26 02:26:36,579 INFO terminating
2025-03-26 02:26:36,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1547, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_
2025-03-26 02:26:36,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,584 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,584 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,584 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742371_1547 src: /172.20.1.14:52912 dest: /172.20.1.16:9866
2025-03-26 02:26:36,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742371_1547 src: /172.20.1.16:42066 dest: /172.20.1.15:9866
2025-03-26 02:26:36,589 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52912, dest: /172.20.1.16:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742371_1547, duration(ns): 488119
2025-03-26 02:26:36,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42066, dest: /172.20.1.15:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742371_1547, duration(ns): 348060
2025-03-26 02:26:36,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742371_1547, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,589 INFO terminating
2025-03-26 02:26:36,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1548, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_
2025-03-26 02:26:36,593 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,593 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,593 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,593 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,593 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,593 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742372_1548 src: /172.20.1.14:52926 dest: /172.20.1.16:9866
2025-03-26 02:26:36,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742372_1548 src: /172.20.1.16:42080 dest: /172.20.1.15:9866
2025-03-26 02:26:36,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42080, dest: /172.20.1.15:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742372_1548, duration(ns): 337583
2025-03-26 02:26:36,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742372_1548, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52926, dest: /172.20.1.16:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742372_1548, duration(ns): 463234
2025-03-26 02:26:36,596 INFO terminating
2025-03-26 02:26:36,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1549, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_
2025-03-26 02:26:36,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,604 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,604 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,604 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742373_1549 src: /172.20.1.14:48614 dest: /172.20.1.15:9866
2025-03-26 02:26:36,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742373_1549 src: /172.20.1.15:60296 dest: /172.20.1.16:9866
2025-03-26 02:26:36,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48614, dest: /172.20.1.15:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742373_1549, duration(ns): 1181273
2025-03-26 02:26:36,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60296, dest: /172.20.1.16:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742373_1549, duration(ns): 924353
2025-03-26 02:26:36,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742373_1549, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,609 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,609 INFO terminating
2025-03-26 02:26:36,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1550, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_
2025-03-26 02:26:36,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,614 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,614 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,614 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742374_1550 src: /172.20.1.14:52928 dest: /172.20.1.16:9866
2025-03-26 02:26:36,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742374_1550 src: /172.20.1.16:42086 dest: /172.20.1.15:9866
2025-03-26 02:26:36,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52928, dest: /172.20.1.16:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742374_1550, duration(ns): 498779
2025-03-26 02:26:36,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42086, dest: /172.20.1.15:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742374_1550, duration(ns): 366489
2025-03-26 02:26:36,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742374_1550, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,617 INFO terminating
2025-03-26 02:26:36,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1551, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_
2025-03-26 02:26:36,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,622 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,622 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,622 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742375_1551 src: /172.20.1.14:52944 dest: /172.20.1.16:9866
2025-03-26 02:26:36,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742375_1551 src: /172.20.1.16:42100 dest: /172.20.1.15:9866
2025-03-26 02:26:36,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42100, dest: /172.20.1.15:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742375_1551, duration(ns): 2557598
2025-03-26 02:26:36,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52944, dest: /172.20.1.16:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742375_1551, duration(ns): 2682234
2025-03-26 02:26:36,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742375_1551, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,627 INFO terminating
2025-03-26 02:26:36,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1552, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_
2025-03-26 02:26:36,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,630 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,630 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,630 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742376_1552 src: /172.20.1.14:52958 dest: /172.20.1.16:9866
2025-03-26 02:26:36,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742376_1552 src: /172.20.1.16:42106 dest: /172.20.1.15:9866
2025-03-26 02:26:36,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52958, dest: /172.20.1.16:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742376_1552, duration(ns): 545247
2025-03-26 02:26:36,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42106, dest: /172.20.1.15:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742376_1552, duration(ns): 378329
2025-03-26 02:26:36,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742376_1552, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,633 INFO terminating
2025-03-26 02:26:36,634 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1553, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_
2025-03-26 02:26:36,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,638 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,638 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,638 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742377_1553 src: /172.20.1.14:52972 dest: /172.20.1.16:9866
2025-03-26 02:26:36,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42114, dest: /172.20.1.15:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742377_1553, duration(ns): 333186
2025-03-26 02:26:36,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742377_1553, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742377_1553 src: /172.20.1.16:42114 dest: /172.20.1.15:9866
2025-03-26 02:26:36,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52972, dest: /172.20.1.16:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742377_1553, duration(ns): 491592
2025-03-26 02:26:36,641 INFO terminating
2025-03-26 02:26:36,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1554, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:26:36,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,643 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,643 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,643 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742378_1554 src: /172.20.1.14:48620 dest: /172.20.1.15:9866
2025-03-26 02:26:36,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742378_1554 src: /172.20.1.15:60308 dest: /172.20.1.16:9866
2025-03-26 02:26:36,646 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48620, dest: /172.20.1.15:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742378_1554, duration(ns): 493496
2025-03-26 02:26:36,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60308, dest: /172.20.1.16:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742378_1554, duration(ns): 264284
2025-03-26 02:26:36,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742378_1554, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,646 INFO terminating
2025-03-26 02:26:36,649 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1555, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_
2025-03-26 02:26:36,649 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,649 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,649 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,649 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,649 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,649 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742379_1555 src: /172.20.1.14:48636 dest: /172.20.1.15:9866
2025-03-26 02:26:36,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742379_1555 src: /172.20.1.15:60316 dest: /172.20.1.16:9866
2025-03-26 02:26:36,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48636, dest: /172.20.1.15:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742379_1555, duration(ns): 535136
2025-03-26 02:26:36,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60316, dest: /172.20.1.16:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742379_1555, duration(ns): 291123
2025-03-26 02:26:36,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742379_1555, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,651 INFO terminating
2025-03-26 02:26:36,652 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1556, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_
2025-03-26 02:26:36,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,656 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,656 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,656 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742380_1556 src: /172.20.1.14:48650 dest: /172.20.1.15:9866
2025-03-26 02:26:36,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742380_1556 src: /172.20.1.15:60328 dest: /172.20.1.16:9866
2025-03-26 02:26:36,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60328, dest: /172.20.1.16:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742380_1556, duration(ns): 2879967
2025-03-26 02:26:36,662 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48650, dest: /172.20.1.15:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742380_1556, duration(ns): 3120408
2025-03-26 02:26:36,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742380_1556, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,662 INFO terminating
2025-03-26 02:26:36,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1557, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_
2025-03-26 02:26:36,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,665 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,665 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,665 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742381_1557 src: /172.20.1.14:48666 dest: /172.20.1.15:9866
2025-03-26 02:26:36,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742381_1557 src: /172.20.1.15:60342 dest: /172.20.1.16:9866
2025-03-26 02:26:36,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60342, dest: /172.20.1.16:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742381_1557, duration(ns): 3566172
2025-03-26 02:26:36,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742381_1557, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,671 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48666, dest: /172.20.1.15:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742381_1557, duration(ns): 3820622
2025-03-26 02:26:36,671 INFO terminating
2025-03-26 02:26:36,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1558, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_
2025-03-26 02:26:36,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,674 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,674 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,674 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742382_1558 src: /172.20.1.14:48676 dest: /172.20.1.15:9866
2025-03-26 02:26:36,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742382_1558 src: /172.20.1.15:60354 dest: /172.20.1.16:9866
2025-03-26 02:26:36,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60354, dest: /172.20.1.16:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742382_1558, duration(ns): 2212991
2025-03-26 02:26:36,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742382_1558, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,679 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48676, dest: /172.20.1.15:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742382_1558, duration(ns): 2458834
2025-03-26 02:26:36,679 INFO terminating
2025-03-26 02:26:36,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1559, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:26:36,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,685 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,685 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,685 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742383_1559 src: /172.20.1.14:48682 dest: /172.20.1.15:9866
2025-03-26 02:26:36,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742383_1559 src: /172.20.1.15:60368 dest: /172.20.1.16:9866
2025-03-26 02:26:36,689 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48682, dest: /172.20.1.15:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742383_1559, duration(ns): 1574202
2025-03-26 02:26:36,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60368, dest: /172.20.1.16:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742383_1559, duration(ns): 1348591
2025-03-26 02:26:36,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742383_1559, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,689 INFO terminating
2025-03-26 02:26:36,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1560, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_
2025-03-26 02:26:36,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,692 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,692 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,692 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742384_1560 src: /172.20.1.14:48698 dest: /172.20.1.15:9866
2025-03-26 02:26:36,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742384_1560 src: /172.20.1.15:60374 dest: /172.20.1.16:9866
2025-03-26 02:26:36,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60374, dest: /172.20.1.16:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742384_1560, duration(ns): 397455
2025-03-26 02:26:36,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742384_1560, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,695 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48698, dest: /172.20.1.15:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742384_1560, duration(ns): 523759
2025-03-26 02:26:36,695 INFO terminating
2025-03-26 02:26:36,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1561, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_
2025-03-26 02:26:36,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,697 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,697 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,697 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742385_1561 src: /172.20.1.14:48706 dest: /172.20.1.15:9866
2025-03-26 02:26:36,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742385_1561 src: /172.20.1.15:60380 dest: /172.20.1.16:9866
2025-03-26 02:26:36,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48706, dest: /172.20.1.15:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742385_1561, duration(ns): 442912
2025-03-26 02:26:36,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60380, dest: /172.20.1.16:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742385_1561, duration(ns): 313417
2025-03-26 02:26:36,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742385_1561, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,700 INFO terminating
2025-03-26 02:26:36,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1562, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_
2025-03-26 02:26:36,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,703 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,703 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,703 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742386_1562 src: /172.20.1.14:48714 dest: /172.20.1.15:9866
2025-03-26 02:26:36,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742386_1562 src: /172.20.1.15:60386 dest: /172.20.1.16:9866
2025-03-26 02:26:36,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60386, dest: /172.20.1.16:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742386_1562, duration(ns): 1418748
2025-03-26 02:26:36,707 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48714, dest: /172.20.1.15:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742386_1562, duration(ns): 1657763
2025-03-26 02:26:36,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742386_1562, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,707 INFO terminating
2025-03-26 02:26:36,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1563, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_
2025-03-26 02:26:36,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,709 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,709 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,709 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742387_1563 src: /172.20.1.14:48722 dest: /172.20.1.15:9866
2025-03-26 02:26:36,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742387_1563 src: /172.20.1.15:60398 dest: /172.20.1.16:9866
2025-03-26 02:26:36,712 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48722, dest: /172.20.1.15:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742387_1563, duration(ns): 503415
2025-03-26 02:26:36,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60398, dest: /172.20.1.16:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742387_1563, duration(ns): 296056
2025-03-26 02:26:36,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742387_1563, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,712 INFO terminating
2025-03-26 02:26:36,715 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1564, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_
2025-03-26 02:26:36,715 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,715 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,715 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,715 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,715 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,715 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742388_1564 src: /172.20.1.14:52980 dest: /172.20.1.16:9866
2025-03-26 02:26:36,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42120, dest: /172.20.1.15:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742388_1564, duration(ns): 316165
2025-03-26 02:26:36,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742388_1564 src: /172.20.1.16:42120 dest: /172.20.1.15:9866
2025-03-26 02:26:36,718 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52980, dest: /172.20.1.16:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742388_1564, duration(ns): 450764
2025-03-26 02:26:36,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742388_1564, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,718 INFO terminating
2025-03-26 02:26:36,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1565, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_
2025-03-26 02:26:36,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,721 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,721 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,721 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742389_1565 src: /172.20.1.14:52994 dest: /172.20.1.16:9866
2025-03-26 02:26:36,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742389_1565 src: /172.20.1.16:42126 dest: /172.20.1.15:9866
2025-03-26 02:26:36,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:52994, dest: /172.20.1.16:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742389_1565, duration(ns): 491200
2025-03-26 02:26:36,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42126, dest: /172.20.1.15:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742389_1565, duration(ns): 360376
2025-03-26 02:26:36,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742389_1565, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,723 INFO terminating
2025-03-26 02:26:36,725 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1566, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_
2025-03-26 02:26:36,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,728 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,728 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,728 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742390_1566 src: /172.20.1.14:48730 dest: /172.20.1.15:9866
2025-03-26 02:26:36,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742390_1566 src: /172.20.1.15:60404 dest: /172.20.1.16:9866
2025-03-26 02:26:36,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48730, dest: /172.20.1.15:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742390_1566, duration(ns): 597604
2025-03-26 02:26:36,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60404, dest: /172.20.1.16:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742390_1566, duration(ns): 326979
2025-03-26 02:26:36,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742390_1566, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,731 INFO terminating
2025-03-26 02:26:36,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1567, replicas=172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_
2025-03-26 02:26:36,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,734 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,734 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,734 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742391_1567 src: /172.20.1.14:53000 dest: /172.20.1.16:9866
2025-03-26 02:26:36,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742391_1567 src: /172.20.1.16:42134 dest: /172.20.1.15:9866
2025-03-26 02:26:36,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:53000, dest: /172.20.1.16:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742391_1567, duration(ns): 381761
2025-03-26 02:26:36,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:42134, dest: /172.20.1.15:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742391_1567, duration(ns): 394506
2025-03-26 02:26:36,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742391_1567, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,737 INFO terminating
2025-03-26 02:26:36,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:36,741 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:36,741 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:36,741 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:36,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1568, replicas=172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_
2025-03-26 02:26:36,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742392_1568 src: /172.20.1.14:48744 dest: /172.20.1.15:9866
2025-03-26 02:26:36,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073742392_1568 src: /172.20.1.15:60406 dest: /172.20.1.16:9866
2025-03-26 02:26:36,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:60406, dest: /172.20.1.16:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: a786e12c-eb47-49c4-acb5-28b43b2d2445, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742392_1568, duration(ns): 611778
2025-03-26 02:26:36,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_418707308_1
2025-03-26 02:26:36,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48744, dest: /172.20.1.15:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_418707308_1, offset: 0, srvID: 7372a77e-76ec-4505-ae05-24bed3ec1154, blockid: BP-1131994297-172.20.1.14-1742955960730:blk_1073742392_1568, duration(ns): 1214640
2025-03-26 02:26:36,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1131994297-172.20.1.14-1742955960730:blk_1073742392_1568, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:36,745 INFO terminating
2025-03-26 02:26:39,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052 to 172.20.1.16:9866
2025-03-26 02:26:39,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054 to 172.20.1.16:9866
2025-03-26 02:26:39,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052 (numBytes=2015) to /172.20.1.16:9866
2025-03-26 02:26:39,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052 src: /172.20.1.15:35458 dest: /172.20.1.16:9866
2025-03-26 02:26:39,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054 (numBytes=2694) to /172.20.1.16:9866
2025-03-26 02:26:39,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741876_1052 src: /172.20.1.15:35458 dest: /172.20.1.16:9866 of size 2015
2025-03-26 02:26:39,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054 src: /172.20.1.15:35460 dest: /172.20.1.16:9866
2025-03-26 02:26:39,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741878_1054 src: /172.20.1.15:35460 dest: /172.20.1.16:9866 of size 2694
2025-03-26 02:26:39,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:39,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:39,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:39,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:39,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058 to 172.20.1.16:9866
2025-03-26 02:26:39,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059 to 172.20.1.16:9866
2025-03-26 02:26:39,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058 src: /172.20.1.17:45240 dest: /172.20.1.16:9866
2025-03-26 02:26:39,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059 src: /172.20.1.17:45244 dest: /172.20.1.16:9866
2025-03-26 02:26:39,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058 (numBytes=1791) to /172.20.1.16:9866
2025-03-26 02:26:39,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059 (numBytes=2246) to /172.20.1.16:9866
2025-03-26 02:26:39,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741882_1058 src: /172.20.1.17:45240 dest: /172.20.1.16:9866 of size 1791
2025-03-26 02:26:39,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741883_1059 src: /172.20.1.17:45244 dest: /172.20.1.16:9866 of size 2246
2025-03-26 02:26:42,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057 to 172.20.1.16:9866
2025-03-26 02:26:42,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060 to 172.20.1.16:9866
2025-03-26 02:26:42,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060 (numBytes=2530) to /172.20.1.16:9866
2025-03-26 02:26:42,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060 src: /172.20.1.15:35472 dest: /172.20.1.16:9866
2025-03-26 02:26:42,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057 (numBytes=1512) to /172.20.1.16:9866
2025-03-26 02:26:42,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741884_1060 src: /172.20.1.15:35472 dest: /172.20.1.16:9866 of size 2530
2025-03-26 02:26:42,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057 src: /172.20.1.15:35486 dest: /172.20.1.16:9866 of size 1512
2025-03-26 02:26:42,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741881_1057 src: /172.20.1.15:35486 dest: /172.20.1.16:9866
2025-03-26 02:26:42,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:42,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:42,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:42,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:42,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063 to 172.20.1.16:9866
2025-03-26 02:26:42,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064 to 172.20.1.16:9866
2025-03-26 02:26:42,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063 (numBytes=1789) to /172.20.1.16:9866
2025-03-26 02:26:42,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064 (numBytes=2341) to /172.20.1.16:9866
2025-03-26 02:26:42,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063 src: /172.20.1.17:45252 dest: /172.20.1.16:9866
2025-03-26 02:26:42,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064 src: /172.20.1.17:45260 dest: /172.20.1.16:9866
2025-03-26 02:26:42,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741887_1063 src: /172.20.1.17:45252 dest: /172.20.1.16:9866 of size 1789
2025-03-26 02:26:42,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741888_1064 src: /172.20.1.17:45260 dest: /172.20.1.16:9866 of size 2341
2025-03-26 02:26:45,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065 to 172.20.1.16:9866
2025-03-26 02:26:45,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066 to 172.20.1.16:9866
2025-03-26 02:26:45,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065 (numBytes=1712) to /172.20.1.16:9866
2025-03-26 02:26:45,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066 (numBytes=1513) to /172.20.1.16:9866
2025-03-26 02:26:45,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066 src: /172.20.1.15:35498 dest: /172.20.1.16:9866
2025-03-26 02:26:45,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741890_1066 src: /172.20.1.15:35498 dest: /172.20.1.16:9866 of size 1513
2025-03-26 02:26:45,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065 src: /172.20.1.15:35492 dest: /172.20.1.16:9866 of size 1712
2025-03-26 02:26:45,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741889_1065 src: /172.20.1.15:35492 dest: /172.20.1.16:9866
2025-03-26 02:26:45,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:45,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:45,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:45,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:45,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070 to 172.20.1.16:9866
2025-03-26 02:26:45,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072 to 172.20.1.16:9866
2025-03-26 02:26:45,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070 (numBytes=784) to /172.20.1.16:9866
2025-03-26 02:26:45,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072 (numBytes=1511) to /172.20.1.16:9866
2025-03-26 02:26:45,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070 src: /172.20.1.17:45276 dest: /172.20.1.16:9866
2025-03-26 02:26:45,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072 src: /172.20.1.17:45278 dest: /172.20.1.16:9866
2025-03-26 02:26:45,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741894_1070 src: /172.20.1.17:45276 dest: /172.20.1.16:9866 of size 784
2025-03-26 02:26:45,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741896_1072 src: /172.20.1.17:45278 dest: /172.20.1.16:9866 of size 1511
2025-03-26 02:26:48,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069 to 172.20.1.16:9866
2025-03-26 02:26:48,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071 to 172.20.1.16:9866
2025-03-26 02:26:48,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069 src: /172.20.1.15:40266 dest: /172.20.1.16:9866
2025-03-26 02:26:48,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071 src: /172.20.1.15:40280 dest: /172.20.1.16:9866
2025-03-26 02:26:48,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069 (numBytes=2591) to /172.20.1.16:9866
2025-03-26 02:26:48,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071 (numBytes=2150) to /172.20.1.16:9866
2025-03-26 02:26:48,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741893_1069 src: /172.20.1.15:40266 dest: /172.20.1.16:9866 of size 2591
2025-03-26 02:26:48,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741895_1071 src: /172.20.1.15:40280 dest: /172.20.1.16:9866 of size 2150
2025-03-26 02:26:48,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:48,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:48,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:48,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:48,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076 to 172.20.1.16:9866
2025-03-26 02:26:48,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077 to 172.20.1.16:9866
2025-03-26 02:26:48,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076 src: /172.20.1.17:41114 dest: /172.20.1.16:9866
2025-03-26 02:26:48,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077 src: /172.20.1.17:41122 dest: /172.20.1.16:9866
2025-03-26 02:26:48,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076 (numBytes=1921) to /172.20.1.16:9866
2025-03-26 02:26:48,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077 (numBytes=2083) to /172.20.1.16:9866
2025-03-26 02:26:48,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741900_1076 src: /172.20.1.17:41114 dest: /172.20.1.16:9866 of size 1921
2025-03-26 02:26:48,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741901_1077 src: /172.20.1.17:41122 dest: /172.20.1.16:9866 of size 2083
2025-03-26 02:26:51,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075 to 172.20.1.16:9866
2025-03-26 02:26:51,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078 to 172.20.1.16:9866
2025-03-26 02:26:51,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075 (numBytes=1280) to /172.20.1.16:9866
2025-03-26 02:26:51,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078 (numBytes=2277) to /172.20.1.16:9866
2025-03-26 02:26:51,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075 src: /172.20.1.15:40282 dest: /172.20.1.16:9866 of size 1280
2025-03-26 02:26:51,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741899_1075 src: /172.20.1.15:40282 dest: /172.20.1.16:9866
2025-03-26 02:26:51,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078 src: /172.20.1.15:40284 dest: /172.20.1.16:9866
2025-03-26 02:26:51,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741902_1078 src: /172.20.1.15:40284 dest: /172.20.1.16:9866 of size 2277
2025-03-26 02:26:51,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:51,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:51,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:51,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:51,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082 to 172.20.1.16:9866
2025-03-26 02:26:51,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084 to 172.20.1.16:9866
2025-03-26 02:26:51,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082 (numBytes=1839) to /172.20.1.16:9866
2025-03-26 02:26:51,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084 (numBytes=2181) to /172.20.1.16:9866
2025-03-26 02:26:51,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082 src: /172.20.1.17:41138 dest: /172.20.1.16:9866
2025-03-26 02:26:51,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084 src: /172.20.1.17:41146 dest: /172.20.1.16:9866
2025-03-26 02:26:51,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741906_1082 src: /172.20.1.17:41138 dest: /172.20.1.16:9866 of size 1839
2025-03-26 02:26:51,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741908_1084 src: /172.20.1.17:41146 dest: /172.20.1.16:9866 of size 2181
2025-03-26 02:26:54,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081 to 172.20.1.16:9866
2025-03-26 02:26:54,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083 to 172.20.1.16:9866
2025-03-26 02:26:54,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083 (numBytes=1989) to /172.20.1.16:9866
2025-03-26 02:26:54,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083 src: /172.20.1.15:40310 dest: /172.20.1.16:9866
2025-03-26 02:26:54,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741907_1083 src: /172.20.1.15:40310 dest: /172.20.1.16:9866 of size 1989
2025-03-26 02:26:54,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081 (numBytes=2049) to /172.20.1.16:9866
2025-03-26 02:26:54,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081 src: /172.20.1.15:40300 dest: /172.20.1.16:9866
2025-03-26 02:26:54,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741905_1081 src: /172.20.1.15:40300 dest: /172.20.1.16:9866 of size 2049
2025-03-26 02:26:54,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:54,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:54,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:54,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:54,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087 to 172.20.1.16:9866
2025-03-26 02:26:54,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088 to 172.20.1.16:9866
2025-03-26 02:26:54,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087 (numBytes=1789) to /172.20.1.16:9866
2025-03-26 02:26:54,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088 (numBytes=1486) to /172.20.1.16:9866
2025-03-26 02:26:54,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088 src: /172.20.1.17:41160 dest: /172.20.1.16:9866
2025-03-26 02:26:54,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741912_1088 src: /172.20.1.17:41160 dest: /172.20.1.16:9866 of size 1486
2025-03-26 02:26:54,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087 src: /172.20.1.17:41158 dest: /172.20.1.16:9866
2025-03-26 02:26:54,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741911_1087 src: /172.20.1.17:41158 dest: /172.20.1.16:9866 of size 1789
2025-03-26 02:26:57,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089 to 172.20.1.16:9866
2025-03-26 02:26:57,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090 to 172.20.1.16:9866
2025-03-26 02:26:57,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089 (numBytes=2104) to /172.20.1.16:9866
2025-03-26 02:26:57,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090 (numBytes=1850) to /172.20.1.16:9866
2025-03-26 02:26:57,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089 src: /172.20.1.15:44506 dest: /172.20.1.16:9866
2025-03-26 02:26:57,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090 src: /172.20.1.15:44520 dest: /172.20.1.16:9866
2025-03-26 02:26:57,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741913_1089 src: /172.20.1.15:44506 dest: /172.20.1.16:9866 of size 2104
2025-03-26 02:26:57,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741914_1090 src: /172.20.1.15:44520 dest: /172.20.1.16:9866 of size 1850
2025-03-26 02:26:57,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:57,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:57,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:57,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:57,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095 to 172.20.1.16:9866
2025-03-26 02:26:57,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096 to 172.20.1.16:9866
2025-03-26 02:26:57,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095 src: /172.20.1.17:44264 dest: /172.20.1.16:9866
2025-03-26 02:26:57,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096 src: /172.20.1.17:44274 dest: /172.20.1.16:9866
2025-03-26 02:26:57,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095 (numBytes=784) to /172.20.1.16:9866
2025-03-26 02:26:57,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096 (numBytes=3339) to /172.20.1.16:9866
2025-03-26 02:26:57,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741919_1095 src: /172.20.1.17:44264 dest: /172.20.1.16:9866 of size 784
2025-03-26 02:26:57,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741920_1096 src: /172.20.1.17:44274 dest: /172.20.1.16:9866 of size 3339
2025-03-26 02:26:58,711 DEBUG org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 02:26:58,739 DEBUG org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 02:26:58,779 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 02:26:58,782 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 02:26:58,782 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 02:26:58,782 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 02:26:58,782 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 02:26:58,783 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 02:26:58,790 DEBUG org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 02:26:58,798 DEBUG org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 02:26:58,799 DEBUG org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 02:26:58,799 DEBUG org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 02:26:58,799 DEBUG org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 02:26:58,799 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 02:26:58,799 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 02:26:58,800 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 02:26:58,837 DEBUG org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 02:26:58,839 DEBUG org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 02:26:58,839 DEBUG org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 02:26:58,841 DEBUG org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 02:26:58,842 DEBUG org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 02:26:58,842 DEBUG org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 02:26:58,842 DEBUG org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 02:26:58,843 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.001s
2025-03-26 02:26:58,843 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:58,843 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:58,844 DEBUG org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-26 02:26:58,850 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,852 DEBUG org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,853 DEBUG org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,854 DEBUG org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,855 DEBUG org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,859 DEBUG org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,864 DEBUG org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,864 DEBUG org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:58,865 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:26:58,865 DEBUG org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:26:58,866 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 02:26:58,866 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 02:26:58,887 DEBUG org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 02:26:58,887 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:26:58,889 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.046s
2025-03-26 02:26:58,890 DEBUG org.apache.hadoop.fs.Globber: Created Globber for path=file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar, symlinks=true
2025-03-26 02:26:58,890 DEBUG org.apache.hadoop.fs.Globber: Filesystem glob /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:58,890 DEBUG org.apache.hadoop.fs.Globber: Pattern: /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:58,890 DEBUG org.apache.hadoop.fs.Globber: Starting: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:58,908 DEBUG org.apache.hadoop.fs.Globber: Component examples, patterned=false
2025-03-26 02:26:58,908 DEBUG org.apache.hadoop.fs.Globber: Component jars, patterned=false
2025-03-26 02:26:58,908 DEBUG org.apache.hadoop.fs.Globber: Component spark, patterned=false
2025-03-26 02:26:58,910 DEBUG org.apache.hadoop.fs.Globber: Component spark-examples_2.12-3.3.2.jar, patterned=false
2025-03-26 02:26:58,910 DEBUG org.apache.hadoop.fs.Globber: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.020s
2025-03-26 02:26:58,961 DEBUG org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.YarnClientImpl entered state INITED
2025-03-26 02:26:58,986 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8032
2025-03-26 02:26:58,987 DEBUG org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@184497d1] java.lang.Exception at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852) at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145) at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65) at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172) at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132) at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103) at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73) at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceStart(YarnClientImpl.java:242) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194) at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:192) at org.apache.spark.deploy.yarn.Client.run(Client.scala:1327) at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1764) at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958) at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180) at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203) at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90) at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2025-03-26 02:26:58,988 DEBUG org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationClientProtocol
2025-03-26 02:26:58,988 DEBUG org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 02:26:59,003 DEBUG org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@3bde62ff
2025-03-26 02:26:59,006 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-6fbd7dba631f45eb8150e15da234ea51
2025-03-26 02:26:59,064 DEBUG org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.YarnClientImpl is started
2025-03-26 02:26:59,104 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:26:59,105 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:8032
2025-03-26 02:26:59,105 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:8032
2025-03-26 02:26:59,114 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root: starting, having connections 1
2025-03-26 02:26:59,115 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root sending #0 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getClusterMetrics
2025-03-26 02:26:59,126 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root got value #0
2025-03-26 02:26:59,126 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getClusterMetrics took 45ms
2025-03-26 02:26:59,128 DEBUG org.apache.spark.deploy.yarn.Client: Requesting a new application from cluster with 3 NodeManagers
2025-03-26 02:26:59,140 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root sending #1 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getNewApplication
2025-03-26 02:26:59,146 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2025-03-26 02:26:59,149 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root got value #1
2025-03-26 02:26:59,149 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getNewApplication took 10ms
2025-03-26 02:26:59,155 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000: duration 0:00.001s
2025-03-26 02:26:59,155 DEBUG org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-26 02:26:59,155 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-26 02:26:59,155 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:26:59,155 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000
2025-03-26 02:26:59,155 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000
2025-03-26 02:26:59,155 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-26 02:26:59,167 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-26 02:26:59,167 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-26 02:26:59,167 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-26 02:26:59,167 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path =
2025-03-26 02:26:59,170 DEBUG org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-26 02:26:59,173 DEBUG org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-26 02:26:59,178 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-6fbd7dba631f45eb8150e15da234ea51
2025-03-26 02:26:59,387 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-26 02:26:59,391 DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-26 02:26:59,393 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000: duration 0:00.238s
2025-03-26 02:26:59,445 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:59,446 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:59,450 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-26 02:26:59,450 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-26 02:26:59,450 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-26 02:26:59,451 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-26 02:26:59,451 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-26 02:26:59,451 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-26 02:26:59,456 INFO org.apache.spark.deploy.yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
2025-03-26 02:26:59,460 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:9000
2025-03-26 02:26:59,460 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:9000
2025-03-26 02:26:59,460 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:26:59,462 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:9000 from root sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete
2025-03-26 02:26:59,462 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:9000 from root: starting, having connections 2
2025-03-26 02:26:59,466 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:9000 from root got value #2
2025-03-26 02:26:59,466 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: delete took 6ms
2025-03-26 02:26:59,470 INFO org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 02:26:59,471 INFO org.apache.spark.util.ShutdownHookManager: Deleting directory /tmp/spark-84cf0b96-7d11-4b97-94ac-50434944dc76
2025-03-26 02:26:59,472 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (root (auth:SIMPLE))@hdfs://master:9000; URI: hdfs://master:9000; Object Identity Hash: 6cff72bf
2025-03-26 02:26:59,473 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (root (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 51efd314
2025-03-26 02:26:59,473 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 5d40b45a
2025-03-26 02:26:59,473 DEBUG org.apache.hadoop.ipc.Client: stopping client from cache: Client-6fbd7dba631f45eb8150e15da234ea51
2025-03-26 02:26:59,474 DEBUG org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.005 seconds; Timeouts: 0
2025-03-26 02:26:59,489 DEBUG org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
2025-03-26 02:27:00,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093 to 172.20.1.16:9866
2025-03-26 02:27:00,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094 to 172.20.1.16:9866
2025-03-26 02:27:00,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093 src: /172.20.1.15:44536 dest: /172.20.1.16:9866
2025-03-26 02:27:00,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094 src: /172.20.1.15:44534 dest: /172.20.1.16:9866
2025-03-26 02:27:00,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093 (numBytes=3185) to /172.20.1.16:9866
2025-03-26 02:27:00,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094 (numBytes=1717) to /172.20.1.16:9866
2025-03-26 02:27:00,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741917_1093 src: /172.20.1.15:44536 dest: /172.20.1.16:9866 of size 3185
2025-03-26 02:27:00,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741918_1094 src: /172.20.1.15:44534 dest: /172.20.1.16:9866 of size 1717
2025-03-26 02:27:00,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:00,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:00,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:00,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:00,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099 to 172.20.1.16:9866
2025-03-26 02:27:00,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102 to 172.20.1.16:9866
2025-03-26 02:27:00,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099 src: /172.20.1.17:44276 dest: /172.20.1.16:9866
2025-03-26 02:27:00,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102 src: /172.20.1.17:44278 dest: /172.20.1.16:9866
2025-03-26 02:27:00,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099 (numBytes=1610) to /172.20.1.16:9866
2025-03-26 02:27:00,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102 (numBytes=1646) to /172.20.1.16:9866
2025-03-26 02:27:00,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741923_1099 src: /172.20.1.17:44276 dest: /172.20.1.16:9866 of size 1610
2025-03-26 02:27:00,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741926_1102 src: /172.20.1.17:44278 dest: /172.20.1.16:9866 of size 1646
2025-03-26 02:27:03,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100 to 172.20.1.16:9866
2025-03-26 02:27:03,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101 to 172.20.1.16:9866
2025-03-26 02:27:03,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100 src: /172.20.1.15:44562 dest: /172.20.1.16:9866
2025-03-26 02:27:03,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100 (numBytes=1600) to /172.20.1.16:9866
2025-03-26 02:27:03,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741924_1100 src: /172.20.1.15:44562 dest: /172.20.1.16:9866 of size 1600
2025-03-26 02:27:03,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101 (numBytes=2653) to /172.20.1.16:9866
2025-03-26 02:27:03,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101 src: /172.20.1.15:44578 dest: /172.20.1.16:9866 of size 2653
2025-03-26 02:27:03,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741925_1101 src: /172.20.1.15:44578 dest: /172.20.1.16:9866
2025-03-26 02:27:03,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:03,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:03,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:03,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:03,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105 to 172.20.1.16:9866
2025-03-26 02:27:03,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106 to 172.20.1.16:9866
2025-03-26 02:27:03,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106 src: /172.20.1.17:44290 dest: /172.20.1.16:9866
2025-03-26 02:27:03,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106 (numBytes=1863) to /172.20.1.16:9866
2025-03-26 02:27:03,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105 (numBytes=1934) to /172.20.1.16:9866
2025-03-26 02:27:03,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105 src: /172.20.1.17:44292 dest: /172.20.1.16:9866 of size 1934
2025-03-26 02:27:03,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741930_1106 src: /172.20.1.17:44290 dest: /172.20.1.16:9866 of size 1863
2025-03-26 02:27:03,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741929_1105 src: /172.20.1.17:44292 dest: /172.20.1.16:9866
2025-03-26 02:27:06,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107 to 172.20.1.16:9866
2025-03-26 02:27:06,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108 to 172.20.1.16:9866
2025-03-26 02:27:06,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108 src: /172.20.1.15:44598 dest: /172.20.1.16:9866
2025-03-26 02:27:06,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107 (numBytes=1395) to /172.20.1.16:9866
2025-03-26 02:27:06,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108 (numBytes=3904) to /172.20.1.16:9866
2025-03-26 02:27:06,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741932_1108 src: /172.20.1.15:44598 dest: /172.20.1.16:9866 of size 3904
2025-03-26 02:27:06,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107 src: /172.20.1.15:44582 dest: /172.20.1.16:9866 of size 1395
2025-03-26 02:27:06,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741931_1107 src: /172.20.1.15:44582 dest: /172.20.1.16:9866
2025-03-26 02:27:06,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:06,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:06,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:06,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:06,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113 to 172.20.1.16:9866
2025-03-26 02:27:06,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114 to 172.20.1.16:9866
2025-03-26 02:27:06,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113 (numBytes=2654) to /172.20.1.16:9866
2025-03-26 02:27:06,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113 src: /172.20.1.17:44300 dest: /172.20.1.16:9866
2025-03-26 02:27:06,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114 (numBytes=1978) to /172.20.1.16:9866
2025-03-26 02:27:06,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741937_1113 src: /172.20.1.17:44300 dest: /172.20.1.16:9866 of size 2654
2025-03-26 02:27:06,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114 src: /172.20.1.17:44312 dest: /172.20.1.16:9866 of size 1978
2025-03-26 02:27:06,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741938_1114 src: /172.20.1.17:44312 dest: /172.20.1.16:9866
2025-03-26 02:27:08,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.20.1.14
2025-03-26 02:27:08,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 3467
2025-03-26 02:27:08,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 82 Number of transactions batched in Syncs: 757 Number of syncs: 2711 SyncTimes(ms): 951
2025-03-26 02:27:08,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 82 Number of transactions batched in Syncs: 757 Number of syncs: 2712 SyncTimes(ms): 952
2025-03-26 02:27:08,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2025-03-26 02:27:08,401 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468
2025-03-26 02:27:08,414 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3469
2025-03-26 02:27:08,445 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2025-03-26 02:27:08,447 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getimage=1&txid=0&storageInfo=-66:906524901:1742955960730:CID-2767be01-b54b-4379-b603-513d890d5f55&bootstrapstandby=false
2025-03-26 02:27:08,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/fsimage_0000000000000000000, fileSize: 399. Sent total: 399 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:27:08,492 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2025-03-26 02:27:08,492 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 399 bytes.
2025-03-26 02:27:08,499 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getedit=1&startTxId=1&endTxId=3468&storageInfo=-66:906524901:1742955960730:CID-2767be01-b54b-4379-b603-513d890d5f55
2025-03-26 02:27:08,501 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468, fileSize: 478730. Sent total: 478730 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:27:08,505 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 467000.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000003468_0000000000007362441 took 0.00s.
2025-03-26 02:27:08,505 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000003468_0000000000007362441 size 0 bytes.
2025-03-26 02:27:08,541 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:27:08,545 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:27:08,550 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:27:08,554 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/namesecondary/current/fsimage_0000000000000000000
2025-03-26 02:27:08,554 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:27:08,554 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:27:08,558 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2025-03-26 02:27:08,561 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 expecting start txid #1
2025-03-26 02:27:08,562 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 maxTxnsToRead = 9223372036854775807
2025-03-26 02:27:08,757 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded 1 edits file(s) (the last named /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468) of total size 478730.0, total edits 3468.0, total load time 185.0 ms
2025-03-26 02:27:08,779 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 using no compression
2025-03-26 02:27:08,844 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 of size 54040 bytes saved in 0 seconds .
2025-03-26 02:27:08,846 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:27:08,851 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:27:08,872 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2025-03-26 02:27:08,872 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/namesecondary/current/fsimage_0000000000000003468, fileSize: 54040. Sent total: 54040 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:27:08,875 INFO org.apache.hadoop.hdfs.server.namenode.ImageServlet: Rejecting a fsimage due to small time delta and txnid delta. Time since previous checkpoint is 68 expecting at least 2700 txnid delta since previous checkpoint is 3468 expecting at least 1000000
2025-03-26 02:27:08,877 WARN [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:26:07 GMT 2025 Last Checkpoint        : -- (7302 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 54040
2025-03-26 02:27:09,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111 to 172.20.1.16:9866
2025-03-26 02:27:09,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112 to 172.20.1.16:9866
2025-03-26 02:27:09,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111 (numBytes=1885) to /172.20.1.16:9866
2025-03-26 02:27:09,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112 (numBytes=1956) to /172.20.1.16:9866
2025-03-26 02:27:09,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111 src: /172.20.1.15:59418 dest: /172.20.1.16:9866
2025-03-26 02:27:09,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112 src: /172.20.1.15:59432 dest: /172.20.1.16:9866
2025-03-26 02:27:09,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741935_1111 src: /172.20.1.15:59418 dest: /172.20.1.16:9866 of size 1885
2025-03-26 02:27:09,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741936_1112 src: /172.20.1.15:59432 dest: /172.20.1.16:9866 of size 1956
2025-03-26 02:27:09,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:09,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:09,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:09,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:09,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117 to 172.20.1.16:9866
2025-03-26 02:27:09,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120 to 172.20.1.16:9866
2025-03-26 02:27:09,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117 (numBytes=1677) to /172.20.1.16:9866
2025-03-26 02:27:09,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120 (numBytes=1580) to /172.20.1.16:9866
2025-03-26 02:27:09,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120 src: /172.20.1.17:40866 dest: /172.20.1.16:9866 of size 1580
2025-03-26 02:27:09,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117 src: /172.20.1.17:40862 dest: /172.20.1.16:9866
2025-03-26 02:27:09,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741944_1120 src: /172.20.1.17:40866 dest: /172.20.1.16:9866
2025-03-26 02:27:09,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741941_1117 src: /172.20.1.17:40862 dest: /172.20.1.16:9866 of size 1677
2025-03-26 02:27:12,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118 to 172.20.1.16:9866
2025-03-26 02:27:12,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119 to 172.20.1.16:9866
2025-03-26 02:27:12,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118 src: /172.20.1.15:59438 dest: /172.20.1.16:9866
2025-03-26 02:27:12,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118 (numBytes=1343) to /172.20.1.16:9866
2025-03-26 02:27:12,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119 (numBytes=1483) to /172.20.1.16:9866
2025-03-26 02:27:12,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741942_1118 src: /172.20.1.15:59438 dest: /172.20.1.16:9866 of size 1343
2025-03-26 02:27:12,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119 src: /172.20.1.15:59454 dest: /172.20.1.16:9866
2025-03-26 02:27:12,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741943_1119 src: /172.20.1.15:59454 dest: /172.20.1.16:9866 of size 1483
2025-03-26 02:27:12,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:12,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:12,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:12,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:12,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124 to 172.20.1.16:9866
2025-03-26 02:27:12,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125 to 172.20.1.16:9866
2025-03-26 02:27:12,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125 (numBytes=2121) to /172.20.1.16:9866
2025-03-26 02:27:12,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124 (numBytes=2402) to /172.20.1.16:9866
2025-03-26 02:27:12,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124 src: /172.20.1.17:40874 dest: /172.20.1.16:9866
2025-03-26 02:27:12,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125 src: /172.20.1.17:40882 dest: /172.20.1.16:9866
2025-03-26 02:27:12,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741949_1125 src: /172.20.1.17:40882 dest: /172.20.1.16:9866 of size 2121
2025-03-26 02:27:12,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741948_1124 src: /172.20.1.17:40874 dest: /172.20.1.16:9866 of size 2402
2025-03-26 02:27:15,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123 to 172.20.1.16:9866
2025-03-26 02:27:15,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126 to 172.20.1.16:9866
2025-03-26 02:27:15,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123 (numBytes=2936) to /172.20.1.16:9866
2025-03-26 02:27:15,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126 (numBytes=1496) to /172.20.1.16:9866
2025-03-26 02:27:15,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123 src: /172.20.1.15:59458 dest: /172.20.1.16:9866
2025-03-26 02:27:15,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126 src: /172.20.1.15:59474 dest: /172.20.1.16:9866
2025-03-26 02:27:15,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741950_1126 src: /172.20.1.15:59474 dest: /172.20.1.16:9866 of size 1496
2025-03-26 02:27:15,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741947_1123 src: /172.20.1.15:59458 dest: /172.20.1.16:9866 of size 2936
2025-03-26 02:27:15,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:15,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:15,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:15,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:15,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129 to 172.20.1.16:9866
2025-03-26 02:27:15,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132 to 172.20.1.16:9866
2025-03-26 02:27:15,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132 (numBytes=2661) to /172.20.1.16:9866
2025-03-26 02:27:15,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129 src: /172.20.1.17:40888 dest: /172.20.1.16:9866
2025-03-26 02:27:15,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129 (numBytes=1477) to /172.20.1.16:9866
2025-03-26 02:27:15,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741953_1129 src: /172.20.1.17:40888 dest: /172.20.1.16:9866 of size 1477
2025-03-26 02:27:15,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132 src: /172.20.1.17:40894 dest: /172.20.1.16:9866 of size 2661
2025-03-26 02:27:15,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741956_1132 src: /172.20.1.17:40894 dest: /172.20.1.16:9866
2025-03-26 02:27:18,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130 to 172.20.1.16:9866
2025-03-26 02:27:18,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.15:9866, datanodeUuid=7372a77e-76ec-4505-ae05-24bed3ec1154, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131 to 172.20.1.16:9866
2025-03-26 02:27:18,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131 src: /172.20.1.15:45820 dest: /172.20.1.16:9866
2025-03-26 02:27:18,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131 (numBytes=2855) to /172.20.1.16:9866
2025-03-26 02:27:18,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741955_1131 src: /172.20.1.15:45820 dest: /172.20.1.16:9866 of size 2855
2025-03-26 02:27:18,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130 (numBytes=2042) to /172.20.1.16:9866
2025-03-26 02:27:18,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130 src: /172.20.1.15:45826 dest: /172.20.1.16:9866
2025-03-26 02:27:18,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741954_1130 src: /172.20.1.15:45826 dest: /172.20.1.16:9866 of size 2042
2025-03-26 02:27:18,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:18,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:18,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:18,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:18,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135 to 172.20.1.16:9866
2025-03-26 02:27:18,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=95dfd055-2daa-423b-a78c-81d3cae22127, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2767be01-b54b-4379-b603-513d890d5f55;nsid=906524901;c=1742955960730) Starting thread to transfer BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137 to 172.20.1.16:9866
2025-03-26 02:27:18,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135 src: /172.20.1.17:37054 dest: /172.20.1.16:9866
2025-03-26 02:27:18,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137 src: /172.20.1.17:37058 dest: /172.20.1.16:9866
2025-03-26 02:27:18,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135 (numBytes=2591) to /172.20.1.16:9866
2025-03-26 02:27:18,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741959_1135 src: /172.20.1.17:37054 dest: /172.20.1.16:9866 of size 2591
2025-03-26 02:27:18,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137 (numBytes=2841) to /172.20.1.16:9866
2025-03-26 02:27:18,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1131994297-172.20.1.14-1742955960730:blk_1073741961_1137 src: /172.20.1.17:37058 dest: /172.20.1.16:9866 of size 2841
