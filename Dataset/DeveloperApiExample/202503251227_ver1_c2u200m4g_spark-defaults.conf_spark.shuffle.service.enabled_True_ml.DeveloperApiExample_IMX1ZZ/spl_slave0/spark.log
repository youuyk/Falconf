program=ml.DeveloperApiExample
SPARKLORD_MODE=CONFIG_INJECTION
cpu_cores=2
cpu_util=200
memory=4g
config_file_name=spark-defaults.conf
config_key=spark.shuffle.service.enabled
config_value=True

2025-03-25 12:28:39,661 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-25 12:28:39,665 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-25 12:28:39,665 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-25 12:28:39,873 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-25 12:28:39,986 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-25 12:28:39,986 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-25 12:28:39,986 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-25 12:28:39,987 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-25 12:28:39,987 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-25 12:28:40,049 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-25 12:28:40,053 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-25 12:28:40,054 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-25 12:28:40,054 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-25 12:28:40,054 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-25 12:28:40,054 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-25 12:28:40,076 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-25 12:28:40,080 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-25 12:28:40,080 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-25 12:28:40,080 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-25 12:28:40,080 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-25 12:28:40,080 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-25 12:28:40,081 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-25 12:28:40,081 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-25 12:28:40,130 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-25 12:28:40,208 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-25 12:28:40,210 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-25 12:28:40,210 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-25 12:28:40,212 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-25 12:28:40,212 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-25 12:28:40,212 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-25 12:28:40,213 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/container_tokens
2025-03-25 12:28:40,215 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/container_tokens
2025-03-25 12:28:40,215 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-25 12:28:40,216 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3@1522d8a0]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-25 12:28:40,221 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1742905670216_0001_000001
2025-03-25 12:28:40,222 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-25 12:28:40,243 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Starting the user application in a separate Thread
2025-03-25 12:28:40,245 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Waiting for spark context initialization...
2025-03-25 12:28:40,287 INFO [Driver] org.apache.spark.SparkContext: Running Spark version 3.3.2
2025-03-25 12:28:40,303 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-25 12:28:40,304 INFO [Driver] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.driver.
2025-03-25 12:28:40,304 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-25 12:28:40,304 INFO [Driver] org.apache.spark.SparkContext: Submitted application: DeveloperApiExample
2025-03-25 12:28:40,317 INFO [Driver] org.apache.spark.resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-25 12:28:40,321 INFO [Driver] org.apache.spark.resource.ResourceProfile: Limiting resource is cpus at 2 tasks per executor
2025-03-25 12:28:40,322 INFO [Driver] org.apache.spark.resource.ResourceProfileManager: Added ResourceProfile id: 0
2025-03-25 12:28:40,345 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-25 12:28:40,345 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-25 12:28:40,346 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-25 12:28:40,346 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-25 12:28:40,346 INFO [Driver] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-25 12:28:40,383 DEBUG [Driver] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-25 12:28:40,387 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-25 12:28:40,387 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-25 12:28:40,396 DEBUG [Driver] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-25 12:28:40,419 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-25 12:28:40,419 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-25 12:28:40,419 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-25 12:28:40,419 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-25 12:28:40,420 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-25 12:28:40,420 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-25 12:28:40,420 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-25 12:28:40,420 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-25 12:28:40,420 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-25 12:28:40,420 DEBUG [Driver] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-25 12:28:40,421 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/tmp (java.io.tmpdir)
2025-03-25 12:28:40,421 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-25 12:28:40,421 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 3817865216 bytes
2025-03-25 12:28:40,421 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-25 12:28:40,422 DEBUG [Driver] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-25 12:28:40,422 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-25 12:28:40,422 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-25 12:28:40,422 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-25 12:28:40,426 DEBUG [Driver] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-25 12:28:40,436 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-25 12:28:40,436 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-25 12:28:40,438 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-25 12:28:40,455 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1502 (auto-detected)
2025-03-25 12:28:40,456 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-25 12:28:40,456 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-25 12:28:40,457 DEBUG [Driver] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-25 12:28:40,457 DEBUG [Driver] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-25 12:28:40,458 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0b (auto-detected)
2025-03-25 12:28:40,467 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-25 12:28:40,467 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-25 12:28:40,467 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-25 12:28:40,476 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 41187
2025-03-25 12:28:40,481 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'sparkDriver' on port 41187.
2025-03-25 12:28:40,482 DEBUG [Driver] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-25 12:28:40,500 INFO [Driver] org.apache.spark.SparkEnv: Registering MapOutputTracker
2025-03-25 12:28:40,501 DEBUG [Driver] org.apache.spark.MapOutputTrackerMasterEndpoint: init
2025-03-25 12:28:40,524 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMaster
2025-03-25 12:28:40,536 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-25 12:28:40,537 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-03-25 12:28:40,559 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2025-03-25 12:28:40,583 INFO [Driver] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/blockmgr-9e1e2eae-9f33-436d-ba95-538f35b8ef23
2025-03-25 12:28:40,591 DEBUG [Driver] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-25 12:28:40,604 INFO [Driver] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 2004.6 MiB
2025-03-25 12:28:40,657 INFO [Driver] org.apache.spark.SparkEnv: Registering OutputCommitCoordinator
2025-03-25 12:28:40,658 DEBUG [Driver] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: init
2025-03-25 12:28:40,668 DEBUG [Driver] org.apache.spark.SecurityManager: Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2025-03-25 12:28:40,854 DEBUG [Driver] org.apache.spark.ui.JettyUtils: Using requestHeaderSize: 8192
2025-03-25 12:28:40,880 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'SparkUI' on port 45731.
2025-03-25 12:28:40,882 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:40,946 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Created YarnClusterScheduler
2025-03-25 12:28:40,990 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 41745
2025-03-25 12:28:40,990 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41745.
2025-03-25 12:28:40,990 INFO [Driver] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave0:41745
2025-03-25 12:28:40,991 INFO [Driver] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-25 12:28:40,991 INFO [Driver] org.apache.spark.storage.BlockManager: external shuffle service port = 7337
2025-03-25 12:28:40,996 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, slave0, 41745, None)
2025-03-25 12:28:40,998 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave0
2025-03-25 12:28:40,998 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave0:41745 with 2004.6 MiB RAM, BlockManagerId(driver, slave0, 41745, None)
2025-03-25 12:28:41,002 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, slave0, 41745, None)
2025-03-25 12:28:41,003 INFO [Driver] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, slave0, 41745, None)
2025-03-25 12:28:41,102 DEBUG [Driver] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave0:8042/node/containerlogs/container_1742905670216_0001_01_000001/root
2025-03-25 12:28:41,116 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,117 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,118 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,119 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,119 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,120 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,121 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,122 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,122 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,124 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,125 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,126 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,126 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,127 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,128 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,128 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,129 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,131 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,132 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,133 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,133 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,141 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,141 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /api: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,146 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,147 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,152 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:28:41,152 DEBUG [Driver] org.apache.spark.SparkContext: Adding shutdown hook
2025-03-25 12:28:41,158 DEBUG [main] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl entered state INITED
2025-03-25 12:28:41,162 INFO [main] org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8030
2025-03-25 12:28:41,162 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@12dae582]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145)
	at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65)
	at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172)
	at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132)
	at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103)
	at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.serviceStart(AMRMClientImpl.java:193)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:63)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-25 12:28:41,163 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:41,163 DEBUG [main] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationMasterProtocol
2025-03-25 12:28:41,170 DEBUG [main] org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@2611b9a3
2025-03-25 12:28:41,173 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:41,184 DEBUG [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl is started
2025-03-25 12:28:41,185 INFO [main] org.apache.spark.deploy.yarn.YarnRMClient: Registering the ApplicationMaster
2025-03-25 12:28:41,209 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:41,209 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:8030
2025-03-25 12:28:41,209 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:8030
2025-03-25 12:28:41,211 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3ebff828]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy31.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.registerApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy32.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:247)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:234)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:214)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:72)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-25 12:28:41,253 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:41,258 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB info:org.apache.hadoop.yarn.security.SchedulerSecurityInfo$1@2a76b80a
2025-03-25 12:28:41,258 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Looking for a token with service 172.20.1.10:8030
2025-03-25 12:28:41,258 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Token kind is YARN_AM_RM_TOKEN and the token's service name is 172.20.1.10:8030
2025-03-25 12:28:41,260 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:41,261 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ApplicationMasterProtocolPB
2025-03-25 12:28:41,262 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABELuB45D6/////wE=
2025-03-25 12:28:41,262 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:41,262 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:41,263 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABELuB45D6/////wE=\",realm=\"default\",nonce=\"GkxAw0/G+6sIZdc2C+Vb8oKEjRYCqzOax5bL+A6g\",nc=00000001,cnonce=\"kpEVoZuaCNxP3CCu/8ewRajxfjeRqM5rn08z0gQx\",digest-uri=\"/default\",maxbuf=65536,response=f11445d51248e7ff9018c4448783e046,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:41,265 DEBUG [main] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:41,268 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root: starting, having connections 1
2025-03-25 12:28:41,269 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #0 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.registerApplicationMaster
2025-03-25 12:28:41,286 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #0
2025-03-25 12:28:41,286 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: registerApplicationMaster took 98ms
2025-03-25 12:28:41,295 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Preparing Local resources
2025-03-25 12:28:41,329 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742905670216_0001/__spark_conf__.zip
2025-03-25 12:28:41,329 DEBUG [main] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742905670216_0001/__spark_conf__.zip: duration 0:00.001s
2025-03-25 12:28:41,329 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742905670216_0001/__spark_conf__.zip
2025-03-25 12:28:41,329 DEBUG [main] org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-25 12:28:41,334 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,336 DEBUG [main] org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,337 DEBUG [main] org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,338 DEBUG [main] org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,338 DEBUG [main] org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,342 DEBUG [main] org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,345 DEBUG [main] org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,345 DEBUG [main] org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hadoop-client-api-3.3.2.jar
2025-03-25 12:28:41,346 DEBUG [main] org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hive-exec-2.3.9-core.jar
2025-03-25 12:28:41,346 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__2502852711748106473.zip/hive-exec-2.3.9-core.jar
2025-03-25 12:28:41,346 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-25 12:28:41,347 DEBUG [main] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-25 12:28:41,358 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-25 12:28:41,358 DEBUG [main] org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-25 12:28:41,367 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-25 12:28:41,368 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-25 12:28:41,368 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-25 12:28:41,368 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path = 
2025-03-25 12:28:41,370 DEBUG [main] org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-25 12:28:41,372 DEBUG [main] org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-25 12:28:41,375 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:41,509 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-25 12:28:41,513 DEBUG [main] org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-25 12:28:41,514 DEBUG [main] org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742905670216_0001/__spark_conf__.zip: duration 0:00.185s
2025-03-25 12:28:41,516 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:41,517 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:9000
2025-03-25 12:28:41,517 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:9000
2025-03-25 12:28:41,517 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@4b2a30d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy36.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:965)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1739)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1753)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1750)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1765)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4(ApplicationMaster.scala:200)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4$adapted(ApplicationMaster.scala:197)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.deploy.yarn.ApplicationMaster.prepareLocalResources(ApplicationMaster.scala:197)
	at org.apache.spark.deploy.yarn.ApplicationMaster.createAllocator(ApplicationMaster.scala:463)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:523)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-25 12:28:41,517 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:41,518 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector)
2025-03-25 12:28:41,518 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: tokens aren't supported for this protocol or user doesn't have one
2025-03-25 12:28:41,518 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use SIMPLE authentication for protocol ClientNamenodeProtocolPB
2025-03-25 12:28:41,518 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

2025-03-25 12:28:41,518 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root: starting, having connections 2
2025-03-25 12:28:41,518 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2025-03-25 12:28:41,519 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root got value #1
2025-03-25 12:28:41,519 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getFileInfo took 3ms
2025-03-25 12:28:41,537 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:41,571 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: 
===============================================================================
Default YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_YARN_STAGING_DIR -> hdfs://master:9000/user/root/.sparkStaging/application_1742905670216_0001
    SPARK_USER -> root

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx2048m \ 
      '-XX:+IgnoreUnrecognizedVMOptions' \ 
      '--add-opens=java.base/java.lang=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.io=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.net=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.nio=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.security.action=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED' \ 
      '--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED' \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=41187' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.YarnCoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@slave0:41187 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      2 \ 
      --app-id \ 
      application_1742905670216_0001 \ 
      --resourceProfileId \ 
      0 \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __app__.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742905670216_0001/scopt_2.12-3.7.1.jar" } size: 78803 timestamp: 1742905716195 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742905670216_0001/__spark_libs__2502852711748106473.zip" } size: 301733843 timestamp: 1742905716102 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742905670216_0001/__spark_conf__.zip" } size: 946989 timestamp: 1742905716364 type: ARCHIVE visibility: PRIVATE
    spark-examples_2.12-3.3.2.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742905670216_0001/spark-examples_2.12-3.3.2.jar" } size: 1567446 timestamp: 1742905716235 type: FILE visibility: PRIVATE

===============================================================================
2025-03-25 12:28:41,585 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Resource profile 0 doesn't exist, adding it
2025-03-25 12:28:41,602 INFO [main] org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-25 12:28:41,603 INFO [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-25 12:28:41,605 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-25 12:28:41,605 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-25 12:28:41,605 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-25 12:28:41,605 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-25 12:28:41,605 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-25 12:28:41,606 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-25 12:28:41,606 DEBUG [main] org.apache.spark.deploy.yarn.ResourceRequestHelper: Custom resources requested: Map()
2025-03-25 12:28:41,607 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Created resource capability: <memory:2432, vCores:2>
2025-03-25 12:28:41,608 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@slave0:41187)
2025-03-25 12:28:41,610 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:28:41,613 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:28:41,621 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:28:41,621 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:28:41,621 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:28:41,621 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:41,621 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:41,621 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:41,622 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:41,622 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:41,622 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:41,622 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:41,622 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:41,622 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:28:41,622 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:28:41,630 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #2 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:41,636 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #2
2025-03-25 12:28:41,636 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:28:41,644 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
2025-03-25 12:28:41,644 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:41,645 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:41,645 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #3 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:41,647 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #3
2025-03-25 12:28:41,647 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:28:41,851 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200273071/200.
2025-03-25 12:28:41,851 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:41,852 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:41,853 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #4 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:41,854 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #4
2025-03-25 12:28:41,854 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:28:42,255 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400141971/400.
2025-03-25 12:28:42,255 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:42,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:42,257 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #5 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:42,265 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #5
2025-03-25 12:28:42,265 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 9ms
2025-03-25 12:28:42,269 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave1:41289
2025-03-25 12:28:42,270 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave0:41877
2025-03-25 12:28:42,270 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave2:35961
2025-03-25 12:28:42,275 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:28:42,277 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,277 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,277 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,280 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,280 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,280 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,280 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:28:42,281 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:28:42,282 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000002 on host slave1 for executor with ID 1 for ResourceProfile Id 0
2025-03-25 12:28:42,283 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000003 on host slave2 for executor with ID 2 for ResourceProfile Id 0
2025-03-25 12:28:42,284 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:42,284 DEBUG [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:42,285 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:42,286 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:42,286 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:42,286 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:42,294 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000004 on host slave0 for executor with ID 3 for ResourceProfile Id 0
2025-03-25 12:28:42,294 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:42,294 DEBUG [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:42,294 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:42,295 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:42,295 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:42,295 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:42,297 INFO [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:42,298 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:28:42,300 INFO [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:42,300 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:28:42,310 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:42,311 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:28:42,311 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:42,311 DEBUG [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:42,311 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:42,312 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:42,312 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:42,312 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:42,313 INFO [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:42,313 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:28:42,313 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:42,313 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@33fca067]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:42,314 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:42,314 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@755b926f]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:42,314 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:42,310 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:42,314 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@53f3d071]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:42,314 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:42,320 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:42,320 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:42,388 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:42,411 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:42,411 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:28:42,411 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:28:42,411 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@70f73042]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:42,411 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:42,412 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:42,412 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:28:42,412 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:28:42,412 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1f61658a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:42,412 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:42,412 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@34ae2a78
2025-03-25 12:28:42,413 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:42,413 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:42,413 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:42,413 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:28:42,413 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:42,413 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:42,413 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"R3CQnzviggb3d6diddSeDeWM1KJ2ZNuPeyfG1gd7\",nc=00000001,cnonce=\"jtS5wQ/bRHkPrYD0gJZyJxdxQ8C25h9n3GaG5SIl\",digest-uri=\"/default\",maxbuf=65536,response=3db400ad2da12a375a713e0f4ae34ecc,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:42,415 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:42,415 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:28:42,416 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #6 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:42,417 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:42,417 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:28:42,417 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:28:42,418 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@276adf4d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:42,418 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:42,418 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@69fe04a6
2025-03-25 12:28:42,418 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:42,418 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:42,418 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:42,419 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:28:42,419 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:42,419 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:42,419 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"pK9MVlK6wN4Y+FVadsRSsIpDvzCuHDO1/zGxjZDl\",nc=00000001,cnonce=\"pl/Vg+9jjZWbL424pOhLM7jIGnLLrox/g+3aDkKQ\",digest-uri=\"/default\",maxbuf=65536,response=390176bbd16bfb8b1cd8359db32e798c,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:42,422 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #6
2025-03-25 12:28:42,422 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 12ms
2025-03-25 12:28:42,422 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:42,422 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 4
2025-03-25 12:28:42,424 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@6bab21d3
2025-03-25 12:28:42,424 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:42,424 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:42,425 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:42,425 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:28:42,425 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:42,425 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:42,425 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"qITcwO68qglnv6tBkCsU2CfWV5sBvYiXD1Ndh9oC\",nc=00000001,cnonce=\"ANT3TE/4LoT0sgATJLwAzNsoDCnFeF3VgsMwK+cW\",digest-uri=\"/default\",maxbuf=65536,response=5abce49ef3e3d0598013df2f730bb599,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:42,427 ERROR [ContainerLauncher-2] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 3 on container container_1742905670216_0001_01_000004
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000004 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:42,430 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:42,430 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:28:42,431 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #7 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:42,435 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:42,436 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #8 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:42,436 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:28:42,512 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #7
2025-03-25 12:28:42,513 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:42,513 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:28:42,513 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 103ms
2025-03-25 12:28:42,513 ERROR [ContainerLauncher-1] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 2 on container container_1742905670216_0001_01_000003
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000003 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:42,520 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #8
2025-03-25 12:28:42,520 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 103ms
2025-03-25 12:28:42,520 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:42,520 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:28:42,520 ERROR [ContainerLauncher-0] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 1 on container container_1742905670216_0001_01_000002
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000002 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:45,311 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000100525/3000.
2025-03-25 12:28:45,311 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:45,311 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:28:45,312 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:28:45,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:28:45,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:28:45,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:28:45,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:45,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:45,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:45,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:45,313 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:45,313 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:45,313 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:45,313 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:45,313 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:28:45,313 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:28:45,313 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #9 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:45,320 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #9
2025-03-25 12:28:45,321 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 8ms
2025-03-25 12:28:45,323 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:28:45,323 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000003
2025-03-25 12:28:45,325 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000003 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:45,325 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000003. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:45,326 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000002
2025-03-25 12:28:45,326 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000002 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:45,326 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000002. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:45,326 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000004
2025-03-25 12:28:45,326 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000004 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:45,326 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000004. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:45,326 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:28:45,527 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200102624/200.
2025-03-25 12:28:45,527 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:45,527 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:45,527 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #10 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:45,529 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #10
2025-03-25 12:28:45,529 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:28:45,930 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400289906/400.
2025-03-25 12:28:45,930 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:45,931 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:45,933 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #11 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:45,937 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #11
2025-03-25 12:28:45,937 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 5ms
2025-03-25 12:28:46,738 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800067263/800.
2025-03-25 12:28:46,738 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:46,739 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:46,740 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #12 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:46,745 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #12
2025-03-25 12:28:46,745 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:28:46,745 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:28:46,745 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,746 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,746 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,746 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,746 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,746 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,746 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,746 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:46,746 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:28:46,746 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:46,746 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,747 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:46,747 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:28:46,747 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:46,747 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:46,747 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:46,747 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:28:46,747 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:28:46,747 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000005 on host slave2 for executor with ID 4 for ResourceProfile Id 0
2025-03-25 12:28:46,747 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000006 on host slave1 for executor with ID 5 for ResourceProfile Id 0
2025-03-25 12:28:46,747 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:46,747 DEBUG [ContainerLauncher-3] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:46,747 DEBUG [ContainerLauncher-3] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:46,748 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000007 on host slave0 for executor with ID 6 for ResourceProfile Id 0
2025-03-25 12:28:46,748 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:46,748 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:46,748 DEBUG [ContainerLauncher-3] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:46,749 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:46,749 DEBUG [ContainerLauncher-4] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:46,749 DEBUG [ContainerLauncher-4] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:46,750 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:46,750 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:46,750 DEBUG [ContainerLauncher-4] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:46,751 INFO [ContainerLauncher-4] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:46,751 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:28:46,756 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:28:46,756 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:46,757 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@3a7588d0]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:46,757 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:46,757 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1f58feb5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-5] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:46,758 DEBUG [ContainerLauncher-5] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@43e3f6d3
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-5] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:46,759 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"9iBzGSItN1bKQa/oM80/py5Ymgu6Iz7JoRiESQ2F\",nc=00000001,cnonce=\"KWG3oo2aHJWqOSpradAfQgCLG82OGiKvM/Iegzkw\",digest-uri=\"/default\",maxbuf=65536,response=9283d4f23978aa63ebf0ac8514b1c8fd,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:46,760 INFO [ContainerLauncher-5] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:46,760 INFO [ContainerLauncher-3] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:46,761 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:46,761 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:28:46,768 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:28:46,768 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #13 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:46,768 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:46,769 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@4d985488]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:46,769 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:46,769 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:46,769 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:46,769 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:28:46,769 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:28:46,770 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@68b52c10]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:46,770 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:46,770 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:28:46,770 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2d6fcc0d
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"HKD0/G3eBldP0NIMVTFia9OBMI4XlBKF6A2v76QO\",nc=00000001,cnonce=\"AriMHrajC6sp3Gt521/vBYUw0C/ikS44LxPfFCHO\",digest-uri=\"/default\",maxbuf=65536,response=dbda189fe08b5970ef4728472efe1fce,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@6f61dad1]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:46,771 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:46,772 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:46,772 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:28:46,772 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:28:46,772 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:46,772 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@4a4cb616]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:46,772 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:46,773 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@335a008f
2025-03-25 12:28:46,773 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:46,774 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:46,774 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:46,774 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:28:46,774 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:46,774 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:46,775 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"kiVq3UFyDIOYzldWD5d7OTyGEH+gkwMGyHrsFH+r\",nc=00000001,cnonce=\"q0tgA0fzGC3zhnWlTeQsR1TjxjOIyEi6tWUHz/te\",digest-uri=\"/default\",maxbuf=65536,response=8d1a472d5d8be872749b0b8cf086861b,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:46,775 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 5
2025-03-25 12:28:46,776 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:46,780 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #13
2025-03-25 12:28:46,780 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 23ms
2025-03-25 12:28:46,780 ERROR [ContainerLauncher-4] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 5 on container container_1742905670216_0001_01_000006
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000006 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:46,782 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:46,782 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 4
2025-03-25 12:28:46,782 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #14 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:46,784 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #15 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:46,784 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:28:46,785 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #14
2025-03-25 12:28:46,785 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:46,785 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:28:46,785 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 16ms
2025-03-25 12:28:46,785 ERROR [ContainerLauncher-3] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 4 on container container_1742905670216_0001_01_000005
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000005 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:46,786 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #15
2025-03-25 12:28:46,786 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:28:46,786 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:46,786 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:28:46,786 ERROR [ContainerLauncher-5] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 6 on container container_1742905670216_0001_01_000007
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000007 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:49,751 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000103359/3000.
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:28:49,752 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:49,752 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:49,753 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:49,753 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:49,753 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:49,753 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:49,753 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:49,753 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:28:49,753 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:28:49,753 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #16 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:49,755 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #16
2025-03-25 12:28:49,755 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:28:49,756 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:28:49,756 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000005
2025-03-25 12:28:49,756 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000005 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:49,756 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000005. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:49,756 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:28:49,956 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200066174/200.
2025-03-25 12:28:49,956 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:49,957 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:49,957 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #17 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:49,959 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #17
2025-03-25 12:28:49,959 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:28:49,959 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:28:49,959 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000006
2025-03-25 12:28:49,959 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000006 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:49,959 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000006. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:49,959 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000007
2025-03-25 12:28:49,959 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000007 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:49,959 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000007. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:49,959 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:28:50,360 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400102732/400.
2025-03-25 12:28:50,360 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:50,360 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:50,360 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #18 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:50,363 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #18
2025-03-25 12:28:50,363 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,364 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,364 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,364 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:50,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,365 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:50,365 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:28:50,365 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:50,365 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:50,365 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:50,365 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:28:50,365 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:28:50,365 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000008 on host slave1 for executor with ID 7 for ResourceProfile Id 0
2025-03-25 12:28:50,365 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000009 on host slave2 for executor with ID 8 for ResourceProfile Id 0
2025-03-25 12:28:50,365 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:50,365 DEBUG [ContainerLauncher-6] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:50,365 DEBUG [ContainerLauncher-6] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:50,365 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000010 on host slave0 for executor with ID 9 for ResourceProfile Id 0
2025-03-25 12:28:50,366 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:50,366 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:50,366 DEBUG [ContainerLauncher-6] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:50,368 INFO [ContainerLauncher-6] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:50,368 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:50,368 DEBUG [ContainerLauncher-7] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:50,368 DEBUG [ContainerLauncher-7] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:50,368 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:50,368 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:50,368 DEBUG [ContainerLauncher-7] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:50,370 INFO [ContainerLauncher-7] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:50,371 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:28:50,371 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:28:50,371 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:50,372 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@786f514d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:50,372 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:50,372 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:50,373 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:50,373 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:28:50,373 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:28:50,373 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@9a80d2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:50,373 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-8] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-8] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-8] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@6c4ff0e4]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:50,374 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:50,375 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:50,375 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:28:50,375 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:28:50,375 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@49628c46]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:50,375 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:50,375 INFO [ContainerLauncher-8] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:50,375 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:28:50,375 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:50,376 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:50,376 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@a905137]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:50,377 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:50,377 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:50,377 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:50,377 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:28:50,377 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:28:50,378 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@538ec257]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:50,378 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:50,379 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@79aa1d55
2025-03-25 12:28:50,379 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:50,381 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:50,381 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:50,381 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:28:50,381 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:50,381 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:50,381 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"ksdcaFQEzf2lcR8gaGnNJ4u8ez38DXU4qbLu/xj2\",nc=00000001,cnonce=\"d56/ViCBKwOQ+9RXCmbPZ/sfCvCAtGIcBpjys7/N\",digest-uri=\"/default\",maxbuf=65536,response=a29348847da3849368482bf74cd28542,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:50,383 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:50,386 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #21 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:50,386 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@1c0e52fb
2025-03-25 12:28:50,387 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:50,388 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:50,388 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:50,388 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:28:50,388 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:50,388 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"pG+ch5s2N3ManuELS1SavhsQu6vEnVecy+mPIguP\",nc=00000001,cnonce=\"TNrRpdaL2lHSiE1GlPXrQMbezh8CD2YFu+/vv23T\",digest-uri=\"/default\",maxbuf=65536,response=2bf7c5b72a8ddc19ef7680002895a71c,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:50,389 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 5
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@30bcc757
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:50,389 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:50,390 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"2fksaJAdx3XBelpLyLceRvtG286zqg7pKVq4K7iK\",nc=00000001,cnonce=\"XYGefsJRngB6+9FG8qlnhBw2rL5WqTOGhHZsWtNi\",digest-uri=\"/default\",maxbuf=65536,response=7e89d562cee15363ec45d2fc6f073ee3,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:50,390 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:50,391 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:50,392 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 5
2025-03-25 12:28:50,400 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 5
2025-03-25 12:28:50,400 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #19 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:50,402 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #20 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:50,402 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #21
2025-03-25 12:28:50,402 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 25ms
2025-03-25 12:28:50,403 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:50,403 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 4
2025-03-25 12:28:50,403 ERROR [ContainerLauncher-8] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 9 on container container_1742905670216_0001_01_000010
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000010 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:50,405 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #19
2025-03-25 12:28:50,405 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:50,405 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:28:50,405 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #20
2025-03-25 12:28:50,405 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 30ms
2025-03-25 12:28:50,405 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 32ms
2025-03-25 12:28:50,405 ERROR [ContainerLauncher-6] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 7 on container container_1742905670216_0001_01_000008
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000008 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:50,405 ERROR [ContainerLauncher-7] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 8 on container container_1742905670216_0001_01_000009
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000009 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:50,405 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:50,405 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:28:51,518 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root: closed
2025-03-25 12:28:51,518 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root: stopped, remaining connections 1
2025-03-25 12:28:53,371 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000118809/3000.
2025-03-25 12:28:53,371 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:28:53,372 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:53,372 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:28:53,373 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:28:53,373 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #22 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:53,376 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #22
2025-03-25 12:28:53,376 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:28:53,577 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200109058/200.
2025-03-25 12:28:53,577 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:53,577 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:53,577 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #23 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:53,579 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #23
2025-03-25 12:28:53,579 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:28:53,580 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:28:53,580 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000009
2025-03-25 12:28:53,580 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000009 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:53,580 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000009. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:53,580 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000008
2025-03-25 12:28:53,580 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000008 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:53,580 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000008. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:53,580 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000010
2025-03-25 12:28:53,580 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000010 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:53,580 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000010. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:53,580 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:28:53,981 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400109007/400.
2025-03-25 12:28:53,981 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:53,981 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:53,981 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #24 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:53,983 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #24
2025-03-25 12:28:53,983 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:28:54,783 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800110196/800.
2025-03-25 12:28:54,784 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:54,784 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:54,784 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #25 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:54,787 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #25
2025-03-25 12:28:54,787 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:28:54,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:28:54,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,788 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,788 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,788 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:28:54,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:28:54,789 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000011 on host slave1 for executor with ID 10 for ResourceProfile Id 0
2025-03-25 12:28:54,789 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000012 on host slave2 for executor with ID 11 for ResourceProfile Id 0
2025-03-25 12:28:54,789 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:54,789 DEBUG [ContainerLauncher-9] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:54,789 DEBUG [ContainerLauncher-9] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:54,790 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:54,790 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:54,790 DEBUG [ContainerLauncher-9] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:54,791 INFO [ContainerLauncher-9] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:54,791 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000013 on host slave0 for executor with ID 12 for ResourceProfile Id 0
2025-03-25 12:28:54,791 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:54,792 DEBUG [ContainerLauncher-10] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:54,792 DEBUG [ContainerLauncher-10] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:54,792 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:54,792 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:54,792 DEBUG [ContainerLauncher-10] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:54,792 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-11] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-11] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-11] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:54,793 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@3cad2cd]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:54,794 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:54,794 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:54,794 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:54,794 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:28:54,794 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:28:54,794 INFO [ContainerLauncher-11] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:54,794 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:28:54,795 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:54,795 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@2d276724]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:54,795 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:54,795 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:54,796 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:54,796 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:28:54,796 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:28:54,796 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@80a03ab]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:54,796 INFO [ContainerLauncher-10] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:54,796 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:54,795 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@26e7a39f]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:54,796 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:54,797 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:28:54,797 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:54,797 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@29f0bab8]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:54,797 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:54,798 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:54,798 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:54,798 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:28:54,798 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:28:54,798 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@cdddead]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:54,798 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@39c9ce24
2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:54,799 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"ufCkXcOyeSAV2xClYr/wCvDOOpJyrCpNLxRoJGEg\",nc=00000001,cnonce=\"2tIUwRSvdln/joUpL/uVPRcruwbb0cTIN9GnD7sJ\",digest-uri=\"/default\",maxbuf=65536,response=e749daf1863f6df283bc2f51d26018c5,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:54,800 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@63909de5
2025-03-25 12:28:54,800 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:54,800 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:54,800 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:54,800 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:54,801 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:28:54,801 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:54,801 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:54,801 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"Oy16ryLWvKfakmTkUB2+j6lAsFPryFqjPRsf89f+\",nc=00000001,cnonce=\"CA3t6Bjlmo7EX3uM0OzWq3z+Xs56nQDQ81DJtsaB\",digest-uri=\"/default\",maxbuf=65536,response=a10a0208d0cd1d296c6237c73a4e24ea,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@6a593591
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:54,802 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"txM5wj1mNm5jwV4ataTfjv9xy0euGVbZGSBZ1qRa\",nc=00000001,cnonce=\"vAW0HHQBDu28YG0DuT9iHRpTXU7ZsIG60xg7b/Ei\",digest-uri=\"/default\",maxbuf=65536,response=07eb093dab50a40b49b58cdb8cfe8cd6,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:54,803 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:28:54,803 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #26 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:54,803 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:28:54,803 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:54,805 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #27 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:54,806 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:28:54,806 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #28 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:54,807 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #26
2025-03-25 12:28:54,808 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:54,808 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:28:54,808 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:28:54,808 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #27
2025-03-25 12:28:54,808 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:54,808 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:28:54,808 ERROR [ContainerLauncher-9] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 10 on container container_1742905670216_0001_01_000011
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000011 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:54,808 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 12ms
2025-03-25 12:28:54,808 ERROR [ContainerLauncher-11] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 12 on container container_1742905670216_0001_01_000013
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000013 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:54,809 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #28
2025-03-25 12:28:54,809 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 11ms
2025-03-25 12:28:54,809 ERROR [ContainerLauncher-10] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 11 on container container_1742905670216_0001_01_000012
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000012 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:54,809 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:54,809 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000105293/3000.
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:28:57,793 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:28:57,793 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:28:57,794 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:28:57,795 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #29 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:57,797 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #29
2025-03-25 12:28:57,797 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:28:57,797 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:28:57,797 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000011
2025-03-25 12:28:57,797 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000011 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:57,797 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000011. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:57,798 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:28:57,998 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200108666/200.
2025-03-25 12:28:57,998 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:57,998 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:57,998 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #30 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:58,000 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #30
2025-03-25 12:28:58,000 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:28:58,000 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:28:58,000 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000012
2025-03-25 12:28:58,000 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000012 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:58,000 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000012. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:58,000 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000013
2025-03-25 12:28:58,000 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000013 (state: COMPLETE, exit status: -100)
2025-03-25 12:28:58,000 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000013. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:28:58,001 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:28:58,401 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400117246/400.
2025-03-25 12:28:58,401 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:28:58,401 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:28:58,401 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #31 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:28:58,405 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #31
2025-03-25 12:28:58,405 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:28:58,405 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:28:58,405 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,405 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,405 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,405 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,406 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,406 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:28:58,406 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:28:58,406 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000014 on host slave2 for executor with ID 13 for ResourceProfile Id 0
2025-03-25 12:28:58,406 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000015 on host slave1 for executor with ID 14 for ResourceProfile Id 0
2025-03-25 12:28:58,406 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:58,406 DEBUG [ContainerLauncher-12] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:58,406 DEBUG [ContainerLauncher-12] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:58,406 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000016 on host slave0 for executor with ID 15 for ResourceProfile Id 0
2025-03-25 12:28:58,407 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:58,407 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:58,407 DEBUG [ContainerLauncher-12] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:58,408 INFO [ContainerLauncher-12] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:58,408 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:58,408 DEBUG [ContainerLauncher-13] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:58,408 DEBUG [ContainerLauncher-13] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:58,409 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:28:58,409 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:58,409 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:58,409 DEBUG [ContainerLauncher-13] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:58,410 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:28:58,410 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:58,410 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:58,410 DEBUG [ContainerLauncher-14] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:28:58,410 DEBUG [ContainerLauncher-14] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:28:58,411 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:28:58,411 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:28:58,411 DEBUG [ContainerLauncher-14] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:28:58,411 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@eb88c0e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:58,411 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:58,411 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:58,411 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:58,412 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:28:58,412 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:28:58,412 INFO [ContainerLauncher-14] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:58,412 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:28:58,412 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:58,413 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@2b95ecf2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:58,413 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:58,412 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@486a7a54]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:58,413 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2bad3825
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:58,414 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:58,415 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"k8p31MMGhkm+icGVF67pQSpM1V2qDePSEAtVV5Pa\",nc=00000001,cnonce=\"0aS15nKunpXNrda65W/h6EWBvW/hSLO//LrgQq3M\",digest-uri=\"/default\",maxbuf=65536,response=f199f8e1a4363d45574e5e7d29632e84,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:58,415 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:58,415 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:28:58,415 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:28:58,415 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3c03f4a1]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:58,416 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:58,416 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:58,416 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:28:58,418 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4a8c4ce0
2025-03-25 12:28:58,418 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:58,419 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:58,419 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:58,419 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:28:58,419 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:58,419 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:58,420 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"OydLVwq99jB1Ssew5OuoCY9pceUOdJsmw2aJrFTh\",nc=00000001,cnonce=\"qH93p9Ss0sbXCYcQIhkm/L9ewmGkyRs6OzT4pAhN\",digest-uri=\"/default\",maxbuf=65536,response=34cfab26406fdd8dd00878cafe0ed890,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:58,421 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:58,422 INFO [ContainerLauncher-13] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:28:58,422 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #32 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:58,422 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:28:58,422 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:28:58,422 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:58,422 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@49f488ce]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:58,423 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:28:58,423 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:28:58,423 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:28:58,423 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:28:58,423 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:28:58,424 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@5c4fffd3]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:28:58,424 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:28:58,424 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@689768b3
2025-03-25 12:28:58,424 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:28:58,425 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:28:58,425 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:28:58,425 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:28:58,425 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:28:58,425 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:28:58,425 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"xUKJ8a+CxIqI767/GxAm3jG7qqeNwp9/9w4sOrnG\",nc=00000001,cnonce=\"nbIbzdhkoXJlpeyNP6MTJr2SHB34RikZeCu59FR5\",digest-uri=\"/default\",maxbuf=65536,response=d63dbef3c042615051efbcd43458c3c0,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:28:58,426 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #33 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:58,427 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:28:58,428 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #32
2025-03-25 12:28:58,428 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:28:58,428 ERROR [ContainerLauncher-12] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 13 on container container_1742905670216_0001_01_000014
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000014 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:58,429 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #33
2025-03-25 12:28:58,429 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:28:58,430 ERROR [ContainerLauncher-14] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 15 on container container_1742905670216_0001_01_000016
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000016 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:28:58,432 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:58,432 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:28:58,432 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:28:58,432 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #34 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:28:58,434 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #34
2025-03-25 12:28:58,440 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:58,440 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:28:58,440 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:28:58,440 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:28:58,440 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:28:58,440 ERROR [ContainerLauncher-13] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 14 on container container_1742905670216_0001_01_000015
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000015 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:01,409 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000111822/3000.
2025-03-25 12:29:01,409 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:01,409 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:01,409 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:01,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:01,410 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:01,410 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #35 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:01,414 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #35
2025-03-25 12:29:01,414 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:01,414 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:01,414 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000014
2025-03-25 12:29:01,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000014 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:01,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000014. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:01,414 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000015
2025-03-25 12:29:01,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000015 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:01,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000015. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:01,414 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000016
2025-03-25 12:29:01,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000016 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:01,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000016. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:01,415 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:01,615 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200110221/200.
2025-03-25 12:29:01,615 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:01,615 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:01,615 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #36 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:01,618 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #36
2025-03-25 12:29:01,618 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:02,018 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400100377/400.
2025-03-25 12:29:02,018 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:02,018 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:02,019 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #37 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:02,020 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #37
2025-03-25 12:29:02,020 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:29:02,821 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800064735/800.
2025-03-25 12:29:02,821 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:02,821 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:02,821 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #38 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:02,824 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #38
2025-03-25 12:29:02,824 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,825 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,825 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,825 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:02,825 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,826 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:02,826 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:02,826 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:02,826 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:02,826 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:02,826 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:02,826 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:02,826 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000017 on host slave2 for executor with ID 16 for ResourceProfile Id 0
2025-03-25 12:29:02,826 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000018 on host slave1 for executor with ID 17 for ResourceProfile Id 0
2025-03-25 12:29:02,826 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:02,826 DEBUG [ContainerLauncher-15] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:02,826 DEBUG [ContainerLauncher-15] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:02,826 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000019 on host slave0 for executor with ID 18 for ResourceProfile Id 0
2025-03-25 12:29:02,827 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-16] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-16] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-17] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-17] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:02,827 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:02,828 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:02,828 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:02,828 DEBUG [ContainerLauncher-17] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:02,829 DEBUG [ContainerLauncher-16] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:02,830 INFO [ContainerLauncher-16] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:02,830 INFO [ContainerLauncher-17] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:02,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:02,832 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:02,832 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1d07c012]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:02,832 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:02,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:02,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:02,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:02,837 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:02,837 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@50c107b2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:02,837 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:02,837 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:02,837 DEBUG [ContainerLauncher-15] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:02,838 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:02,838 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:02,839 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@712bfc7c]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:02,839 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:02,839 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:02,840 INFO [ContainerLauncher-15] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:02,841 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:02,841 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:02,841 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@3c64fe02
2025-03-25 12:29:02,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:02,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:02,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:02,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:02,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:02,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:02,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"R6COau3KwPoroeUpZivGthv+WuQwxDK8blvFDcz1\",nc=00000001,cnonce=\"DlYs7yw68KebdJgSl3u4c/s/8rIux1c47rhWCzPa\",digest-uri=\"/default\",maxbuf=65536,response=79fafb0d157df2a5659f8d284d4830a0,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:02,844 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:02,844 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:02,844 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:02,846 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@24e66cb2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:02,846 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:02,848 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4057e39b
2025-03-25 12:29:02,848 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:02,848 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:02,848 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:02,848 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:02,848 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:02,848 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:02,849 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"DmIt6tw2H2BGMbys1HGeV9oSRqxSnx+JAdsfQ/dr\",nc=00000001,cnonce=\"6Fjt23KuETzQlbfIARJ9f1pq9zHbbXrF1K9I9aeF\",digest-uri=\"/default\",maxbuf=65536,response=3908d66c8f8644c3078f5c6297691506,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:02,852 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:02,852 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:02,853 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@4483944f]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:02,853 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:02,856 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #40 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:02,860 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:02,861 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:02,862 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:02,862 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:02,862 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:02,862 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@73b7e23c]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:02,862 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:02,862 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:02,863 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #39 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:02,863 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@24349ecd
2025-03-25 12:29:02,863 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:02,863 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:02,863 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:02,863 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:02,863 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:02,863 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:02,864 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"DjmW2vzfjVNsFEtvLKbG9m7pr8j67W8jM8rR3Hdc\",nc=00000001,cnonce=\"rrwq4Z2kEJe3DzcvdwdPaOVon3MWY6dWbELkVnmD\",digest-uri=\"/default\",maxbuf=65536,response=d4b3c646070175fec55fc42838c2f826,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:02,864 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #40
2025-03-25 12:29:02,868 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:02,868 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:02,868 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #39
2025-03-25 12:29:02,869 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 25ms
2025-03-25 12:29:02,869 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:02,874 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:02,874 ERROR [ContainerLauncher-17] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 18 on container container_1742905670216_0001_01_000019
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000019 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:02,875 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 39ms
2025-03-25 12:29:02,875 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:02,875 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:02,875 ERROR [ContainerLauncher-16] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 17 on container container_1742905670216_0001_01_000018
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000018 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:02,875 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #41 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:02,876 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #41
2025-03-25 12:29:02,876 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:02,876 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:02,876 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:02,877 ERROR [ContainerLauncher-15] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 16 on container container_1742905670216_0001_01_000017
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000017 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:05,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000127622/3000.
2025-03-25 12:29:05,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:05,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:05,827 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:05,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:05,828 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:05,829 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #42 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:05,834 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #42
2025-03-25 12:29:05,834 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:05,834 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:29:05,834 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000017
2025-03-25 12:29:05,834 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000017 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:05,834 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000017. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:05,834 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000018
2025-03-25 12:29:05,834 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000018 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:05,834 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000018. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:05,835 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:29:06,035 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200111388/200.
2025-03-25 12:29:06,035 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:06,035 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:06,036 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #43 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:06,037 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #43
2025-03-25 12:29:06,037 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:29:06,037 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:29:06,037 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000019
2025-03-25 12:29:06,037 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000019 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:06,037 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000019. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:06,038 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:29:06,438 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400103375/400.
2025-03-25 12:29:06,438 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:06,438 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:06,438 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #44 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:06,441 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #44
2025-03-25 12:29:06,441 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:06,442 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:06,443 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000020 on host slave2 for executor with ID 19 for ResourceProfile Id 0
2025-03-25 12:29:06,443 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000021 on host slave1 for executor with ID 20 for ResourceProfile Id 0
2025-03-25 12:29:06,443 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:06,443 DEBUG [ContainerLauncher-18] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:06,443 DEBUG [ContainerLauncher-18] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:06,443 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:06,443 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:06,443 DEBUG [ContainerLauncher-18] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:06,444 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000022 on host slave0 for executor with ID 21 for ResourceProfile Id 0
2025-03-25 12:29:06,445 INFO [ContainerLauncher-18] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:06,445 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:06,445 DEBUG [ContainerLauncher-19] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:06,445 DEBUG [ContainerLauncher-19] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:06,445 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:06,445 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:06,445 DEBUG [ContainerLauncher-19] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:06,446 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:06,447 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:06,447 INFO [ContainerLauncher-19] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-20] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-20] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-20] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@23ebd0e5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:06,450 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:06,451 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:06,451 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:06,451 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:06,451 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:06,451 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@6c6b5b3]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:06,452 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:06,454 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:06,454 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:06,454 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@31751e6]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:06,454 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:06,454 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:06,455 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:06,455 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:06,455 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:06,455 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@263a20af]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:06,455 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:06,456 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@3eaeb556
2025-03-25 12:29:06,456 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:06,456 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:06,456 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:06,456 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:06,456 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:06,456 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:06,457 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"WvXxHCG+9qbZ+zoVkhJ2F5W7OxZYF7k/PiJHLDEx\",nc=00000001,cnonce=\"vV55K4ipPdApc22rdKuJvvVAWugb717v1Rok+jat\",digest-uri=\"/default\",maxbuf=65536,response=caf19bf10f1e1125372b18e7c6ad7a27,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:06,457 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@553c977c
2025-03-25 12:29:06,457 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:06,458 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:06,458 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:06,458 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:06,458 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:06,458 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:06,458 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"W3DDCVkaJ35GlOlav7D08GIfkMyTaepdL8M1gGC1\",nc=00000001,cnonce=\"9L+ixBMVihDCwAB6Jrb5432A9/wZxWnurhs39kIC\",digest-uri=\"/default\",maxbuf=65536,response=0eb6f6c28d09a762b75dc31b4348cd4d,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:06,459 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:06,460 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:06,460 INFO [ContainerLauncher-20] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:06,463 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:06,463 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #46 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:06,463 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #45 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:06,464 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:06,464 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:06,464 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@162422b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:06,464 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:06,465 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:06,465 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:06,465 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:06,465 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:06,466 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@244f232c]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:06,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:06,469 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #46
2025-03-25 12:29:06,469 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:06,469 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:06,463 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:06,469 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:06,469 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #45
2025-03-25 12:29:06,469 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 18ms
2025-03-25 12:29:06,469 ERROR [ContainerLauncher-19] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 20 on container container_1742905670216_0001_01_000021
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000021 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:06,469 ERROR [ContainerLauncher-18] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 19 on container container_1742905670216_0001_01_000020
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000020 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:06,469 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:06,469 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:06,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7d0a7104
2025-03-25 12:29:06,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:06,470 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:06,470 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:06,470 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:06,470 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:06,470 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:06,470 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"hbIILtK78/LuC8zbhrTjIyIot3HPx/9BmGlRMpws\",nc=00000001,cnonce=\"sWjcIdvvOKteTcYp9N8RH/P9/U2KL23u/ndN2hh6\",digest-uri=\"/default\",maxbuf=65536,response=2a7089526d59e5c699161388bc8091dc,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:06,471 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:06,471 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 2
2025-03-25 12:29:06,472 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #47 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:06,473 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #47
2025-03-25 12:29:06,473 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 8ms
2025-03-25 12:29:06,474 ERROR [ContainerLauncher-20] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 21 on container container_1742905670216_0001_01_000022
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000022 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:06,474 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:06,474 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:09,446 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000102494/3000.
2025-03-25 12:29:09,446 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:09,446 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:09,447 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:09,447 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:09,447 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:09,448 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #48 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:09,451 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #48
2025-03-25 12:29:09,451 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:09,451 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:29:09,451 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000020
2025-03-25 12:29:09,451 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000020 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:09,451 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000020. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:09,451 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000021
2025-03-25 12:29:09,451 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000021 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:09,451 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000021. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:09,451 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:29:09,652 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200106195/200.
2025-03-25 12:29:09,652 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:09,652 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:09,652 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #49 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:09,653 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #49
2025-03-25 12:29:09,654 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:29:09,654 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:29:09,654 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000022
2025-03-25 12:29:09,654 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000022 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:09,654 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000022. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:09,654 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:29:10,054 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400125603/400.
2025-03-25 12:29:10,054 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:10,054 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:10,055 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #50 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:10,056 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #50
2025-03-25 12:29:10,056 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:29:10,856 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800127762/800.
2025-03-25 12:29:10,856 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:10,857 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:10,857 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #51 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:10,860 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #51
2025-03-25 12:29:10,860 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:10,860 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:10,860 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,860 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,860 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,860 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,860 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,861 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:10,861 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:10,861 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000023 on host slave1 for executor with ID 22 for ResourceProfile Id 0
2025-03-25 12:29:10,861 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000024 on host slave2 for executor with ID 23 for ResourceProfile Id 0
2025-03-25 12:29:10,861 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:10,861 DEBUG [ContainerLauncher-21] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:10,861 DEBUG [ContainerLauncher-21] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:10,862 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:10,862 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:10,862 DEBUG [ContainerLauncher-21] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:10,863 INFO [ContainerLauncher-21] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:10,863 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000025 on host slave0 for executor with ID 24 for ResourceProfile Id 0
2025-03-25 12:29:10,863 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:10,863 DEBUG [ContainerLauncher-22] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:10,863 DEBUG [ContainerLauncher-22] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:10,863 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:10,863 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:10,863 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:10,863 DEBUG [ContainerLauncher-22] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:10,863 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:10,864 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:10,864 INFO [ContainerLauncher-22] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:10,864 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:10,864 DEBUG [ContainerLauncher-23] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:10,864 DEBUG [ContainerLauncher-23] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:10,865 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:10,865 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:10,865 DEBUG [ContainerLauncher-23] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:10,865 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:10,866 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:10,866 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@2feff2a8]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:10,866 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:10,866 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:10,867 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:10,867 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:10,867 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:10,867 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@ac2867e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:10,867 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:10,867 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@7dd4735]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:10,867 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:10,868 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:10,868 INFO [ContainerLauncher-23] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:10,868 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:10,868 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@10e3ed01
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"1DV03EH847AJLQd0SEdK72tcljznX/jnS7X5FEO1\",nc=00000001,cnonce=\"YXe61bJ/bP5U/fUMWpomkxeDVU2abLLSceQntsfE\",digest-uri=\"/default\",maxbuf=65536,response=731ed2e526c8c0919b83490ac9a1cc89,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:10,870 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:10,869 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@72c099b9]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:10,870 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@22f036e5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:10,871 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@57edf6ca]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@5dab1e4
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@39ed2236
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"ujjnIazGXp+0HitCppMmX1otN7Fj/jLkU17q5ded\",nc=00000001,cnonce=\"61u7cuwLpwA350SLOl/6XSyEiowkwDqLKqAEoFcV\",digest-uri=\"/default\",maxbuf=65536,response=173b8c0a5cbb9c4b8a51d2272aefbdd3,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:10,872 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"ydcdyaWLJeq9ofJtfre4A74RQL/dh2DjIA6WKWJZ\",nc=00000001,cnonce=\"nh/9u296umwoiISSqmqWd2ChxD4qirMnOjn0W4KC\",digest-uri=\"/default\",maxbuf=65536,response=fbf5dc8d3d7fb10d27081199e2e87a44,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:10,874 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:10,874 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:10,874 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:10,876 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #53 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:10,880 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #54 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:10,880 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:10,880 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:10,881 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #52 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:10,884 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:10,885 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #52
2025-03-25 12:29:10,885 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #54
2025-03-25 12:29:10,885 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 19ms
2025-03-25 12:29:10,885 ERROR [ContainerLauncher-22] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 23 on container container_1742905670216_0001_01_000024
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000024 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:10,885 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:10,885 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #53
2025-03-25 12:29:10,885 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:10,885 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:10,885 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:29:10,885 ERROR [ContainerLauncher-21] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 22 on container container_1742905670216_0001_01_000023
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000023 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:10,885 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:10,885 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:10,885 ERROR [ContainerLauncher-23] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 24 on container container_1742905670216_0001_01_000025
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000025 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:10,886 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:10,886 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:11,026 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)
2025-03-25 12:29:11,027 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
2025-03-25 12:29:11,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-25 12:29:11,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-25 12:29:11,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-25 12:29:11,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-25 12:29:11,846 INFO [Driver] org.apache.spark.sql.internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.spark.sql.internal.SharedState: Applying other initial session options to HadoopConf: spark.app.name -> DeveloperApiExample
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/spark-warehouse
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/spark-warehouse: duration 0:00.000s
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/spark-warehouse
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-25 12:29:11,847 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-25 12:29:11,848 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/spark-warehouse: duration 0:00.001s
2025-03-25 12:29:11,848 INFO [Driver] org.apache.spark.sql.internal.SharedState: Warehouse path is 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742905670216_0001/container_1742905670216_0001_01_000001/spark-warehouse'.
2025-03-25 12:29:11,857 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:29:11,858 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol http
2025-03-25 12:29:11,858 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol http, delegating to default implementation
2025-03-25 12:29:11,858 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:29:11,859 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:29:11,859 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:29:11,860 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol jar
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting jar
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.jar.impl
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol jar, delegating to default implementation
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol file
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Found implementation of file: class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-25 12:29:11,861 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Using handler for protocol file
2025-03-25 12:29:12,325 DEBUG [Driver] org.apache.spark.sql.catalyst.parser.CatalystSqlParser: Parsing command: spark_grouping_id
2025-03-25 12:29:12,812 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Input schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}}]}
2025-03-25 12:29:12,815 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Expected output schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":false,"metadata":{}}]}
2025-03-25 12:29:12,843 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#0
2025-03-25 12:29:12,866 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#7
2025-03-25 12:29:12,866 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#1
2025-03-25 12:29:13,283 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, double, false],input[1, vector, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-25 12:29:13,294 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-25 12:29:13,427 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 142.948708 ms
2025-03-25 12:29:13,442 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$1
2025-03-25 12:29:13,451 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$1) is now cleaned +++
2025-03-25 12:29:13,463 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$rdd$1
2025-03-25 12:29:13,470 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2025-03-25 12:29:13,486 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$extractLabeledPoints$1
2025-03-25 12:29:13,487 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$extractLabeledPoints$1) is now cleaned +++
2025-03-25 12:29:13,494 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$take$2
2025-03-25 12:29:13,497 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$take$2) is now cleaned +++
2025-03-25 12:29:13,559 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5
2025-03-25 12:29:13,562 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2025-03-25 12:29:13,564 INFO [Driver] org.apache.spark.SparkContext: Starting job: take at DeveloperApiExample.scala:127
2025-03-25 12:29:13,565 DEBUG [Driver] org.apache.spark.scheduler.DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 5 took 0.000641 seconds
2025-03-25 12:29:13,568 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Merging stage rdd profiles: Set()
2025-03-25 12:29:13,575 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Got job 0 (take at DeveloperApiExample.scala:127) with 1 output partitions
2025-03-25 12:29:13,576 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 0 (take at DeveloperApiExample.scala:127)
2025-03-25 12:29:13,576 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()
2025-03-25 12:29:13,577 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Missing parents: List()
2025-03-25 12:29:13,591 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitStage(ResultStage 0 (name=take at DeveloperApiExample.scala:127;jobs=0))
2025-03-25 12:29:13,591 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: missing: List()
2025-03-25 12:29:13,592 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185), which has no missing parents
2025-03-25 12:29:13,592 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitMissingTasks(ResultStage 0)
2025-03-25 12:29:13,640 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.0 KiB, free 2004.6 MiB)
2025-03-25 12:29:13,641 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0 locally took 21 ms
2025-03-25 12:29:13,642 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0 without replication took 22 ms
2025-03-25 12:29:13,661 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2004.6 MiB)
2025-03-25 12:29:13,662 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, slave0, 41745, None)
2025-03-25 12:29:13,663 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on slave0:41745 (size: 9.4 KiB, free: 2004.6 MiB)
2025-03-25 12:29:13,667 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
2025-03-25 12:29:13,667 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Told master about block broadcast_0_piece0
2025-03-25 12:29:13,667 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0_piece0 locally took 7 ms
2025-03-25 12:29:13,667 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0_piece0 without replication took 7 ms
2025-03-25 12:29:13,669 INFO [dag-scheduler-event-loop] org.apache.spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
2025-03-25 12:29:13,682 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185) (first 15 tasks are for partitions Vector(0))
2025-03-25 12:29:13,683 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks resource profile 0
2025-03-25 12:29:13,694 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Epoch for TaskSet 0.0: 0
2025-03-25 12:29:13,697 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Adding pending tasks took 2 ms
2025-03-25 12:29:13,698 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2025-03-25 12:29:13,700 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:13,863 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000105658/3000.
2025-03-25 12:29:13,864 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:13,864 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:13,864 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:13,865 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:13,865 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:13,865 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:13,865 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:13,866 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:13,866 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:13,868 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #55 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:13,874 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #55
2025-03-25 12:29:13,874 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 7ms
2025-03-25 12:29:13,874 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:13,874 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000024
2025-03-25 12:29:13,874 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000024 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:13,874 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000024. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:13,874 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000023
2025-03-25 12:29:13,874 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000023 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:13,874 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000023. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:13,874 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000025
2025-03-25 12:29:13,874 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000025 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:13,874 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000025. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:13,874 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:13,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:14,075 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200171019/200.
2025-03-25 12:29:14,075 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:14,076 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:14,076 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #56 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:14,080 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #56
2025-03-25 12:29:14,080 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:14,480 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400067422/400.
2025-03-25 12:29:14,481 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:14,481 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:14,481 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #57 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:14,484 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #57
2025-03-25 12:29:14,484 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:14,485 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:14,485 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,485 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,485 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,486 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,486 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,486 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,486 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,486 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:14,486 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:14,486 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:14,486 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,486 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:14,486 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:14,487 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:14,487 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:14,487 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:14,487 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:14,487 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:14,487 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000026 on host slave2 for executor with ID 25 for ResourceProfile Id 0
2025-03-25 12:29:14,487 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000027 on host slave1 for executor with ID 26 for ResourceProfile Id 0
2025-03-25 12:29:14,487 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000028 on host slave0 for executor with ID 27 for ResourceProfile Id 0
2025-03-25 12:29:14,487 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:14,488 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:14,488 DEBUG [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:14,488 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:14,488 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:14,488 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:14,488 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:14,489 INFO [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:14,489 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:14,490 DEBUG [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:14,490 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:14,490 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:14,490 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:14,490 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:14,491 INFO [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:14,495 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:14,495 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-24] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-24] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-24] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@38a05110]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:14,496 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:14,497 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:14,497 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@426498d8]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:14,497 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:14,497 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:14,498 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:14,498 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:14,498 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:14,498 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@36ce58bd]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:14,498 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@45ee81c4
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@6e39e2bc]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:14,499 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"ZHuIqv8MnhZC55wRcMUicR+4YH6ivGhvglgz3SDO\",nc=00000001,cnonce=\"Kpw3w3OgB6dT6/w5EB+PUKKt3DRTYOTPWuHeoi5w\",digest-uri=\"/default\",maxbuf=65536,response=3dd6456d54f72dcd0ad789b96728fb59,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7fa6c1ba
2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:14,500 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"Jsq1pYvUsSpWhREVUyNVLnMS+9sGHJwKuUMAR9jK\",nc=00000001,cnonce=\"Nx8oRnDDlQ7DSDGupAuKQ1aj/joLxehRgCqVWDQ2\",digest-uri=\"/default\",maxbuf=65536,response=5aab7693cc62f478bc35caf1ba8cb2fb,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:14,501 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:14,501 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:14,502 INFO [ContainerLauncher-24] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:14,505 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:14,505 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:14,506 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:14,506 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:14,506 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #59 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:14,506 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #58 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:14,507 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@7a42b4d9]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:14,507 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:14,507 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:14,507 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:14,507 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:14,507 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:14,507 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@5f6fcaba]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:14,508 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:14,510 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #59
2025-03-25 12:29:14,510 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:14,510 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:14,512 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 13ms
2025-03-25 12:29:14,512 ERROR [ContainerLauncher-2] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 26 on container container_1742905670216_0001_01_000027
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000027 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:14,513 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7aba4e93
2025-03-25 12:29:14,513 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:14,513 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:14,513 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:14,513 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:14,513 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:14,513 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:14,514 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"HFw4HbYFPpGwmQyc6sIDoJotQUTKiNLEHf6J2R/g\",nc=00000001,cnonce=\"7r+pu1Kr3m5ykAc9vXnlgq/8D7sxeVOFoQrqrths\",digest-uri=\"/default\",maxbuf=65536,response=395eadef9e20a194bafbfeb7f77c9645,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:14,514 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #58
2025-03-25 12:29:14,514 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:29:14,514 ERROR [ContainerLauncher-1] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 27 on container container_1742905670216_0001_01_000028
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000028 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:14,514 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:14,514 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:14,515 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:14,517 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #60 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:14,517 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 2
2025-03-25 12:29:14,518 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #60
2025-03-25 12:29:14,518 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 11ms
2025-03-25 12:29:14,518 ERROR [ContainerLauncher-24] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 25 on container container_1742905670216_0001_01_000026
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000026 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:14,518 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:14,518 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:14,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:15,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:16,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:17,487 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000076306/3000.
2025-03-25 12:29:17,487 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:17,488 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:17,489 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:17,490 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:17,491 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:17,491 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:17,491 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:17,491 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:17,492 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #61 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:17,499 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #61
2025-03-25 12:29:17,499 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 8ms
2025-03-25 12:29:17,499 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:17,499 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000026
2025-03-25 12:29:17,499 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000026 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:17,499 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000026. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:17,499 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000027
2025-03-25 12:29:17,499 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000027 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:17,499 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000027. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:17,499 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000028
2025-03-25 12:29:17,499 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000028 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:17,499 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000028. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:17,499 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:17,699 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200160056/200.
2025-03-25 12:29:17,699 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:17,700 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:17,701 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #62 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:17,704 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #62
2025-03-25 12:29:17,704 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:17,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:18,105 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400106652/400.
2025-03-25 12:29:18,105 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:18,106 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:18,107 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #63 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:18,109 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #63
2025-03-25 12:29:18,109 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:18,910 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800071764/800.
2025-03-25 12:29:18,910 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:18,911 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:18,911 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #64 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:18,914 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #64
2025-03-25 12:29:18,914 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:18,914 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:18,914 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,914 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:18,915 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:18,915 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000029 on host slave2 for executor with ID 28 for ResourceProfile Id 0
2025-03-25 12:29:18,915 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000030 on host slave1 for executor with ID 29 for ResourceProfile Id 0
2025-03-25 12:29:18,915 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000031 on host slave0 for executor with ID 30 for ResourceProfile Id 0
2025-03-25 12:29:18,915 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-4] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-4] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:18,916 DEBUG [ContainerLauncher-4] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:18,917 INFO [ContainerLauncher-4] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:18,917 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:18,917 DEBUG [ContainerLauncher-3] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:18,917 DEBUG [ContainerLauncher-3] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:18,918 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:18,918 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:18,918 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@16a78ef6]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:18,919 INFO [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-3] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:18,919 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:18,920 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@2faad3de]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:18,920 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:18,920 INFO [ContainerLauncher-3] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:18,920 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:18,920 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:18,921 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@54a4145f]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:18,921 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:18,921 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:18,921 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:18,921 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:18,921 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:18,922 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@387af0ca]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:18,922 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:18,922 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:18,922 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:18,923 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@37e283d8]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:18,923 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:18,923 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:18,923 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:18,923 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:18,923 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4d476243
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"HPRSKbiqL7Ju4kBSiMtKe20LcVT0vpbITlxVfQHW\",nc=00000001,cnonce=\"P7rAsh+W4tyFkQFrvMk473HwvVRNj/8ma0anktCi\",digest-uri=\"/default\",maxbuf=65536,response=94f04b9080e1aa63bb4cb157f8e68451,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@43bb914e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:18,928 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7c552b3
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7e2bb788
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"4nwFCG6IEq5RkPHcH+ByjbfW4xiomu+La6h96X4O\",nc=00000001,cnonce=\"AiRTrsBywf038F6RTOvn9pIlSuyuf4z4U71xjnid\",digest-uri=\"/default\",maxbuf=65536,response=1a36d973902045b4e4d2ae7463226ab1,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:18,929 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"zaaQAvlpq85pszTtSujq3iEr18dMP4WEEQYqM/IH\",nc=00000001,cnonce=\"ILu6HhYQQU3+L9CjIHJejB7RjeH2zxmnutFQJSwt\",digest-uri=\"/default\",maxbuf=65536,response=d99b8b772f612d201cb23a53dca2e539,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:18,930 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:18,930 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:18,930 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:18,935 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #65 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:18,935 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #67 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:18,936 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:18,937 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #65
2025-03-25 12:29:18,938 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:18,938 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:18,938 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 19ms
2025-03-25 12:29:18,938 ERROR [ContainerLauncher-4] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 29 on container container_1742905670216_0001_01_000030
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000030 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:18,937 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:18,939 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #66 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:18,939 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #67
2025-03-25 12:29:18,939 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 16ms
2025-03-25 12:29:18,939 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:18,939 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:18,939 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 2
2025-03-25 12:29:18,939 ERROR [ContainerLauncher-3] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 30 on container container_1742905670216_0001_01_000031
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000031 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:18,941 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #66
2025-03-25 12:29:18,941 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 20ms
2025-03-25 12:29:18,941 ERROR [ContainerLauncher-0] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 28 on container container_1742905670216_0001_01_000029
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000029 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:18,941 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:18,941 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:18,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:19,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:20,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:21,916 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000219097/3000.
2025-03-25 12:29:21,916 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:21,916 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:21,917 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:21,917 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:21,917 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:21,917 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:21,918 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:21,918 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:21,920 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #68 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:21,925 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #68
2025-03-25 12:29:21,925 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:21,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:22,126 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200110532/200.
2025-03-25 12:29:22,126 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:22,126 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:22,127 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #69 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:22,135 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #69
2025-03-25 12:29:22,135 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 8ms
2025-03-25 12:29:22,136 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:22,136 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,136 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,136 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,136 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,137 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,137 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:22,137 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:22,137 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000032 on host slave2 for executor with ID 31 for ResourceProfile Id 0
2025-03-25 12:29:22,137 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000033 on host slave1 for executor with ID 32 for ResourceProfile Id 0
2025-03-25 12:29:22,137 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:22,137 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000034 on host slave0 for executor with ID 33 for ResourceProfile Id 0
2025-03-25 12:29:22,137 DEBUG [ContainerLauncher-5] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:22,138 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:22,138 DEBUG [ContainerLauncher-5] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:22,138 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:22,138 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000029
2025-03-25 12:29:22,138 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000029 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:22,138 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000029. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:22,138 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000030
2025-03-25 12:29:22,138 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000030 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:22,138 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000030. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:22,138 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000031
2025-03-25 12:29:22,138 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000031 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:22,138 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000031. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:22,138 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:22,138 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:22,138 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:22,138 DEBUG [ContainerLauncher-5] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:22,138 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:22,138 DEBUG [ContainerLauncher-8] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:22,138 DEBUG [ContainerLauncher-8] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:22,139 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:22,139 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:22,139 DEBUG [ContainerLauncher-8] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:22,139 INFO [ContainerLauncher-5] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:22,139 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:22,140 DEBUG [ContainerLauncher-6] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:22,140 DEBUG [ContainerLauncher-6] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:22,140 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:22,140 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:22,140 INFO [ContainerLauncher-8] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:22,140 DEBUG [ContainerLauncher-6] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:22,141 INFO [ContainerLauncher-6] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:22,141 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:22,141 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:22,142 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@751fcd49]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:22,142 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:22,142 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:22,142 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:22,142 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:22,142 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:22,143 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1e8cbb83]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:22,143 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:22,144 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:22,144 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:22,144 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1e7e49de]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:22,144 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:22,144 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:22,145 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:22,145 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:22,145 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:22,145 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@130d8e31]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:22,145 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:22,145 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@70c4ad12
2025-03-25 12:29:22,146 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:22,146 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:22,146 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:22,146 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:22,146 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:22,146 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:22,146 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"59ei7MdO6rUq+fNwpApXLj6zkoU2xdjwhP9IcRL6\",nc=00000001,cnonce=\"l3rODeZcu8eOdY6xqbsawf+9oZ4C2Eu3gLICpNdT\",digest-uri=\"/default\",maxbuf=65536,response=eb537960781acc9867df63c922c65e65,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7344bf57
2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:22,147 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"RT1iZtIR7esaA30HXI7jX/CC5EJZiTenBaTSY8+s\",nc=00000001,cnonce=\"dPvxwPpsngNG+4vio8qkYvZCqdW0puiFM8CdhyVn\",digest-uri=\"/default\",maxbuf=65536,response=23782c777670d393194ab15a8a20826f,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:22,148 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:22,148 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:22,148 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:22,148 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@38725d1c]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:22,148 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:22,148 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:22,148 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:22,149 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:22,149 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:22,152 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:22,152 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:22,152 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1e4585fd]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:22,152 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:22,153 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:22,153 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #71 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:22,153 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4f55f855
2025-03-25 12:29:22,153 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:22,154 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:22,154 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:22,154 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:22,154 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:22,154 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:22,154 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"6q+6vjxggMURh6xN9BMVa41dAsbzdL4qK0Ap2Ltg\",nc=00000001,cnonce=\"pKeMlryxADGEv46VN5IPL7ke7BuiJGTAp7Aln0oi\",digest-uri=\"/default\",maxbuf=65536,response=e58e264cb21a3f8f2049859bda6f59fd,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:22,154 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #70 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:22,155 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:22,155 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #71
2025-03-25 12:29:22,155 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 10ms
2025-03-25 12:29:22,155 ERROR [ContainerLauncher-8] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 32 on container container_1742905670216_0001_01_000033
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000033 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:22,156 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #70
2025-03-25 12:29:22,156 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:22,156 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:22,156 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:22,156 ERROR [ContainerLauncher-5] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 31 on container container_1742905670216_0001_01_000032
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000032 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:22,156 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #72 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:22,156 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:22,157 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:22,157 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:22,158 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #72
2025-03-25 12:29:22,158 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 9ms
2025-03-25 12:29:22,158 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:22,158 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:22,158 ERROR [ContainerLauncher-6] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 33 on container container_1742905670216_0001_01_000034
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000034 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:22,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:23,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:24,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:25,138 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000156510/3000.
2025-03-25 12:29:25,139 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:25,139 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:25,139 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:25,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:25,140 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:25,141 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #73 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:25,147 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #73
2025-03-25 12:29:25,147 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:25,348 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200127325/200.
2025-03-25 12:29:25,348 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:25,348 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:25,348 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #74 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:25,350 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #74
2025-03-25 12:29:25,350 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:29:25,350 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:25,350 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000032
2025-03-25 12:29:25,351 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000032 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:25,351 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000032. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:25,351 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000033
2025-03-25 12:29:25,351 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000033 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:25,351 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000033. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:25,351 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000034
2025-03-25 12:29:25,351 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000034 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:25,351 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000034. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:25,351 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:25,751 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400108943/400.
2025-03-25 12:29:25,751 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:25,752 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:25,753 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #75 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:25,756 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #75
2025-03-25 12:29:25,756 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:25,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:26,557 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800163382/800.
2025-03-25 12:29:26,557 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:26,557 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:26,558 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #76 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:26,565 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #76
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 7ms
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:26,566 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:26,566 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:26,566 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:26,566 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:26,566 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:26,566 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:26,566 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000035 on host slave1 for executor with ID 34 for ResourceProfile Id 0
2025-03-25 12:29:26,566 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:26,566 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000036 on host slave2 for executor with ID 35 for ResourceProfile Id 0
2025-03-25 12:29:26,567 DEBUG [ContainerLauncher-7] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:26,567 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000037 on host slave0 for executor with ID 36 for ResourceProfile Id 0
2025-03-25 12:29:26,567 DEBUG [ContainerLauncher-7] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:26,567 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:26,568 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:26,568 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:26,568 DEBUG [ContainerLauncher-7] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:26,572 INFO [ContainerLauncher-7] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:26,572 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:26,573 DEBUG [ContainerLauncher-11] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:26,573 DEBUG [ContainerLauncher-11] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:26,574 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:26,574 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:26,574 DEBUG [ContainerLauncher-11] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:26,576 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:26,576 DEBUG [ContainerLauncher-9] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:26,576 DEBUG [ContainerLauncher-9] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:26,577 INFO [ContainerLauncher-11] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:26,577 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:26,577 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:26,578 DEBUG [ContainerLauncher-9] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:26,580 INFO [ContainerLauncher-9] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:26,580 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:26,580 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:26,581 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@345c024a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:26,581 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:26,582 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:26,582 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:26,582 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:26,582 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:26,583 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3b4e7621]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:26,583 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:26,583 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:26,583 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:26,584 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:26,584 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:26,584 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@22d276d5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:26,584 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:26,584 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:26,585 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:26,585 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:26,585 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:26,585 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@71efaa8b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:26,585 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@5e7ef8f0
2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:26,586 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"10+rl5Pr2caaQkAJ2LdzmGsvpYSEyrEsASeRDPt6\",nc=00000001,cnonce=\"OuF79AUfQXe2SILfa9S4+BzPkzX4btEQOSFnEqe1\",digest-uri=\"/default\",maxbuf=65536,response=bd602dfe8ccc21131fa52c471d5f7318,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:26,587 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@4957d59c]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:26,587 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:26,587 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:26,587 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:26,587 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@69eab0da
2025-03-25 12:29:26,587 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:26,588 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:26,588 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:26,588 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:26,588 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:26,588 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:26,588 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"W6jmAlOivB1eEoD46xrX6z8SzNoz6zZcm5xCPoFk\",nc=00000001,cnonce=\"FbklnTAsCQ+Ig9MoqgWDtx+zA7jlNUCPEqErzGYD\",digest-uri=\"/default\",maxbuf=65536,response=e4df6982547272bac2d46b1adb69887a,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:26,591 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:26,591 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:26,591 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:26,593 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #78 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@76fc93e5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2edfedf7
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:26,594 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:26,595 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"ATbPoUWCYkZnd6XFT+tZiJGnQD9zgqYY8qHOTbwK\",nc=00000001,cnonce=\"01wWmZMVy9QOf6GAgF7tdyKx6E71FC8stCg5yuGU\",digest-uri=\"/default\",maxbuf=65536,response=a88fafe0b4133c306c6a98da22c841f6,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:26,595 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:26,600 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #77 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:26,600 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:26,600 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #78
2025-03-25 12:29:26,601 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:26,601 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:26,601 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 16ms
2025-03-25 12:29:26,601 ERROR [ContainerLauncher-9] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 35 on container container_1742905670216_0001_01_000036
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000036 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:26,601 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #79 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:26,601 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:26,601 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:26,604 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #79
2025-03-25 12:29:26,604 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:29:26,604 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #77
2025-03-25 12:29:26,604 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 22ms
2025-03-25 12:29:26,604 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:26,604 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:26,604 ERROR [ContainerLauncher-11] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 36 on container container_1742905670216_0001_01_000037
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000037 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:26,604 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:26,604 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:26,604 ERROR [ContainerLauncher-7] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 34 on container container_1742905670216_0001_01_000035
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000035 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:26,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:27,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:28,699 WARN [task-starvation-timer] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
2025-03-25 12:29:28,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:29,567 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000156998/3000.
2025-03-25 12:29:29,568 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:29,568 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:29,568 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:29,569 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:29,569 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:29,569 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:29,569 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:29,569 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:29,569 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:29,569 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:29,570 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:29,570 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:29,570 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:29,570 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:29,570 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:29,570 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:29,571 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #80 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:29,577 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #80
2025-03-25 12:29:29,577 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 7ms
2025-03-25 12:29:29,577 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:29,577 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000036
2025-03-25 12:29:29,577 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000036 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:29,577 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000036. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:29,577 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000035
2025-03-25 12:29:29,577 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000035 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:29,577 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000035. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:29,577 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000037
2025-03-25 12:29:29,577 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000037 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:29,577 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000037. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:29,578 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:29,778 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200112253/200.
2025-03-25 12:29:29,778 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:29,778 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:29,780 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #81 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:29,782 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #81
2025-03-25 12:29:29,782 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:29,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:30,183 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400157162/400.
2025-03-25 12:29:30,184 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:30,184 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:30,185 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #82 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:30,193 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #82
2025-03-25 12:29:30,193 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 9ms
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:30,194 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:30,194 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000038 on host slave2 for executor with ID 37 for ResourceProfile Id 0
2025-03-25 12:29:30,194 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:30,194 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000039 on host slave1 for executor with ID 38 for ResourceProfile Id 0
2025-03-25 12:29:30,194 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000040 on host slave0 for executor with ID 39 for ResourceProfile Id 0
2025-03-25 12:29:30,194 DEBUG [ContainerLauncher-10] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:30,194 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:30,194 DEBUG [ContainerLauncher-10] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-10] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-12] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-12] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-12] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-14] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-14] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:30,195 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:30,196 DEBUG [ContainerLauncher-14] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:30,197 INFO [ContainerLauncher-10] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:30,198 INFO [ContainerLauncher-14] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:30,200 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:30,200 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:30,201 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:30,201 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:30,202 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@304a15a2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:30,202 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@335199f1]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:30,202 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:30,202 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:30,203 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:30,203 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:30,203 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:30,204 INFO [ContainerLauncher-12] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:30,205 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:30,205 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3ac6a3d9]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:30,205 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:30,206 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:30,206 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:30,206 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:30,206 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@d328361
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@2b6b19d4]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:30,207 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:30,205 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"2h9b10Wp9fIkPz+e5w/bPAyOW+97ckJcII3vRrJd\",nc=00000001,cnonce=\"VlXr131LmzoxAJvXe/F2/V3oI44SaagUWDo5BebJ\",digest-uri=\"/default\",maxbuf=65536,response=05baf3b06e4efee2616c78179656f8cd,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4b37286c
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@7ea3455b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:30,208 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:30,209 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:30,209 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:30,209 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:30,209 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@26642a54]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:30,209 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:30,210 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"OnUY4Bg094DXZRONLAl9oaKpvkBjdPXuWeoxDhcr\",nc=00000001,cnonce=\"D+6xUpBJ0RgKkyEkGDnMyo474nevLFz7xS2H0BIJ\",digest-uri=\"/default\",maxbuf=65536,response=fdd9fa734eee50655caa08243eede6d2,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:30,211 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@3b9e472d
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"V4F8OruMXuO4KhgWg4Z7qU1TnXChSxWgI6/RsntP\",nc=00000001,cnonce=\"SleyNYojcNJCxznpPrwCr/2o9MZ9c2Viq3rVwF7I\",digest-uri=\"/default\",maxbuf=65536,response=813dadcde78ccccc99086532f8621126,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:30,212 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:30,213 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:30,213 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:30,213 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:30,214 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #84 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:30,214 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #83 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:30,216 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #85 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:30,216 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:30,222 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #84
2025-03-25 12:29:30,222 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #83
2025-03-25 12:29:30,222 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 19ms
2025-03-25 12:29:30,222 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 16ms
2025-03-25 12:29:30,222 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:30,222 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:30,222 ERROR [ContainerLauncher-14] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 39 on container container_1742905670216_0001_01_000040
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000040 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:30,222 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:30,222 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:30,222 ERROR [ContainerLauncher-10] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 37 on container container_1742905670216_0001_01_000038
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000038 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:30,223 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #85
2025-03-25 12:29:30,223 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:30,223 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:30,223 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:30,223 ERROR [ContainerLauncher-12] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 38 on container container_1742905670216_0001_01_000039
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000039 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:30,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:31,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:32,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:33,195 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000157073/3000.
2025-03-25 12:29:33,195 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:33,195 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:33,196 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:33,196 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:33,196 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:33,196 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:33,196 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:33,196 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:33,196 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:33,196 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:33,197 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:33,197 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:33,197 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:33,197 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:33,197 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:33,197 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:33,199 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #86 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:33,204 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #86
2025-03-25 12:29:33,204 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:33,405 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200174869/200.
2025-03-25 12:29:33,405 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:33,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:33,406 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #87 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:33,409 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #87
2025-03-25 12:29:33,409 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:33,410 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:33,410 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000038
2025-03-25 12:29:33,410 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000038 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:33,410 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000038. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:33,410 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000039
2025-03-25 12:29:33,411 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000039 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:33,411 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000039. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:33,411 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000040
2025-03-25 12:29:33,411 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000040 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:33,411 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000040. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:33,411 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:33,812 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400157176/400.
2025-03-25 12:29:33,812 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:33,812 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:33,813 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #88 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:33,816 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #88
2025-03-25 12:29:33,816 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:33,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:34,617 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800183207/800.
2025-03-25 12:29:34,617 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:34,617 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:34,618 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #89 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:34,624 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #89
2025-03-25 12:29:34,624 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:34,624 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:34,624 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,624 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,624 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,625 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,625 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,625 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:34,625 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:34,626 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:34,626 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:34,626 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:34,626 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000041 on host slave2 for executor with ID 40 for ResourceProfile Id 0
2025-03-25 12:29:34,627 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:34,627 DEBUG [ContainerLauncher-13] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:34,628 DEBUG [ContainerLauncher-13] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:34,629 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:34,629 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:34,629 DEBUG [ContainerLauncher-13] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:34,632 INFO [ContainerLauncher-13] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:34,632 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000042 on host slave1 for executor with ID 41 for ResourceProfile Id 0
2025-03-25 12:29:34,633 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:34,633 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000043 on host slave0 for executor with ID 42 for ResourceProfile Id 0
2025-03-25 12:29:34,633 DEBUG [ContainerLauncher-17] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:34,633 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:34,633 DEBUG [ContainerLauncher-17] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:34,634 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:34,634 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:34,634 DEBUG [ContainerLauncher-17] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:34,636 INFO [ContainerLauncher-17] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:34,636 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:34,636 DEBUG [ContainerLauncher-16] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:34,636 DEBUG [ContainerLauncher-16] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:34,637 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:34,637 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:34,637 DEBUG [ContainerLauncher-16] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:34,637 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:34,638 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:34,638 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1006220b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:34,638 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:34,639 INFO [ContainerLauncher-16] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:34,639 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:34,639 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:34,639 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:34,639 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:34,640 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:34,640 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:34,640 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@45c5b43e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:34,640 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:34,641 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:34,641 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:34,641 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:34,641 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:34,641 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@27296f74]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:34,642 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:34,642 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:34,642 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:34,642 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@13e61e7a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:34,642 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:34,642 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:34,643 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:34,643 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:34,643 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:34,643 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@175e28b2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:34,643 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4a04e370
2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:34,644 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"gNcqkGRSGNB8KNjzVFsggar6GJTsF8Txn5nvJw04\",nc=00000001,cnonce=\"iSM6Ic3BVV7/sX1g639re9Q8z5P791WnItNs9HrU\",digest-uri=\"/default\",maxbuf=65536,response=6574d5aaf35770140da327ff491f59ed,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:34,645 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:34,640 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@32d87a96]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@25bb61b8
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@375f9ce0
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"mivbMCHhOMIZHjQeETQhXRODwtie4ICWGAwP9x5x\",nc=00000001,cnonce=\"rNcmvd1Lc4xdn9sB6FjroGY3BYFaRI5qZfI/tIXT\",digest-uri=\"/default\",maxbuf=65536,response=f02fa0750565be778ce3d167b9ff95d8,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:34,646 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"M5W3X2021cF8hDI12tvwpMcmAbXgBMTCrRyHGh1M\",nc=00000001,cnonce=\"OJNUZx2iMH8ijNlcKniaV6mw99Jd88q7uHyYUT1K\",digest-uri=\"/default\",maxbuf=65536,response=11f547c27ce5c57c1a71e33a5780eaf8,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:34,647 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:34,647 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:34,647 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:34,652 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #92 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:34,652 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:34,652 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #91 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:34,654 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #92
2025-03-25 12:29:34,654 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:34,654 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:34,654 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 12ms
2025-03-25 12:29:34,654 ERROR [ContainerLauncher-16] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 42 on container container_1742905670216_0001_01_000043
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000043 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:34,655 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #90 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:34,655 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:34,656 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #91
2025-03-25 12:29:34,656 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:34,656 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:34,656 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 15ms
2025-03-25 12:29:34,656 ERROR [ContainerLauncher-13] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 40 on container container_1742905670216_0001_01_000041
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000041 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:34,656 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #90
2025-03-25 12:29:34,656 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:29:34,656 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:34,656 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:34,656 ERROR [ContainerLauncher-17] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 41 on container container_1742905670216_0001_01_000042
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000042 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:34,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:35,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:36,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:37,633 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000290878/3000.
2025-03-25 12:29:37,634 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:37,634 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:37,635 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:37,635 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:37,635 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:37,635 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:37,635 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:37,635 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:37,636 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:37,636 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:37,636 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:37,636 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:37,636 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:37,636 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:37,636 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:37,636 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:37,637 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #93 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:37,642 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #93
2025-03-25 12:29:37,642 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 5ms
2025-03-25 12:29:37,642 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:37,643 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000041
2025-03-25 12:29:37,643 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000041 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:37,643 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000041. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:37,643 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000042
2025-03-25 12:29:37,643 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000042 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:37,643 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000042. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:37,643 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000043
2025-03-25 12:29:37,643 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000043 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:37,643 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000043. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:37,643 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:37,844 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200227788/200.
2025-03-25 12:29:37,844 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:37,844 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:37,845 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #94 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:37,847 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #94
2025-03-25 12:29:37,848 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:37,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:38,248 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400195228/400.
2025-03-25 12:29:38,249 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:38,249 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:38,250 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #95 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:38,255 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #95
2025-03-25 12:29:38,255 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:38,256 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:38,256 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000044 on host slave2 for executor with ID 43 for ResourceProfile Id 0
2025-03-25 12:29:38,256 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000045 on host slave1 for executor with ID 44 for ResourceProfile Id 0
2025-03-25 12:29:38,256 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:38,256 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000046 on host slave0 for executor with ID 45 for ResourceProfile Id 0
2025-03-25 12:29:38,256 DEBUG [ContainerLauncher-15] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:38,256 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:38,256 DEBUG [ContainerLauncher-15] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:38,257 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:38,257 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:38,257 DEBUG [ContainerLauncher-15] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:38,258 INFO [ContainerLauncher-15] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-18] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-18] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-18] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:38,258 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@403fe269]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:38,259 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:38,259 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:38,260 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:38,260 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:38,260 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:38,260 INFO [ContainerLauncher-18] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:38,260 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:38,260 DEBUG [ContainerLauncher-19] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:38,261 DEBUG [ContainerLauncher-19] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:38,261 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@43e7c28d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:38,261 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:38,261 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:38,261 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:38,261 DEBUG [ContainerLauncher-19] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:38,264 INFO [ContainerLauncher-19] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:38,264 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:38,264 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:38,264 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:38,264 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:38,265 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@6fd2b7ba]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:38,265 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@46518e79]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:38,265 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:38,265 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@f86212b
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:38,265 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:38,266 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:38,267 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:38,267 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:38,267 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:38,267 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@6d68da87]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:38,267 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2cdb66e9
2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:38,268 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"p7mmgqS3oLASdVwLOczfATCw2xgmCyImnVURrl58\",nc=00000001,cnonce=\"bK1NYHeFJROhoS81z5fJjuWkBfTO+qqpl+Tv3PAy\",digest-uri=\"/default\",maxbuf=65536,response=b0e2f05fe548f0c9682a00abe36a50ff,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:38,270 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:38,270 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"tlUJU/m7gwPuYn8ei4torbkZXvk9brRPsoss7ULL\",nc=00000001,cnonce=\"JePhB+HNTKSw8Zguu/97PHdr1dv2A6KxruWjtQWe\",digest-uri=\"/default\",maxbuf=65536,response=546464ebea38738634365c5d2a262317,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:38,270 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:38,267 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@ec59e40]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:38,271 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:38,271 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:38,271 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2afdd561
2025-03-25 12:29:38,271 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:38,272 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:38,272 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:38,272 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:38,272 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:38,272 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:38,272 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"A9DwlebB06E1iFXiv5bSrYwQ4B2OBffd3P/Sp62G\",nc=00000001,cnonce=\"/vlbLwjz4ErJyu7bAl/ymjQDF0ghDA/wdEfOhmew\",digest-uri=\"/default\",maxbuf=65536,response=d48f3e51ae2265b12bfa4831ff00e28c,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:38,272 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:38,272 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #97 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:38,273 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:38,273 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:38,273 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #96 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:38,274 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #98 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:38,274 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #97
2025-03-25 12:29:38,274 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 8ms
2025-03-25 12:29:38,274 ERROR [ContainerLauncher-19] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 45 on container container_1742905670216_0001_01_000046
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000046 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:38,275 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #96
2025-03-25 12:29:38,275 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:38,275 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:38,275 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 15ms
2025-03-25 12:29:38,275 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:38,275 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:38,275 ERROR [ContainerLauncher-15] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 43 on container container_1742905670216_0001_01_000044
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000044 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:38,275 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #98
2025-03-25 12:29:38,275 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 8ms
2025-03-25 12:29:38,275 ERROR [ContainerLauncher-18] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 44 on container container_1742905670216_0001_01_000045
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000045 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:38,276 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:38,276 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:38,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:39,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:40,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:41,257 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000174059/3000.
2025-03-25 12:29:41,257 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:41,257 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:41,258 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:41,259 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:41,259 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:41,259 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:41,259 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:41,259 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:41,259 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:41,259 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:41,260 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:41,260 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:41,260 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:41,260 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:41,260 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:41,260 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:41,261 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #99 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:41,264 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #99
2025-03-25 12:29:41,264 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:41,465 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200158492/200.
2025-03-25 12:29:41,465 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:41,466 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:41,466 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #100 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:41,469 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #100
2025-03-25 12:29:41,469 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:41,470 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:41,470 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000044
2025-03-25 12:29:41,471 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000044 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:41,471 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000044. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:41,471 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000045
2025-03-25 12:29:41,471 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000045 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:41,471 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000045. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:41,471 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000046
2025-03-25 12:29:41,471 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000046 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:41,471 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000046. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:41,471 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:41,872 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400278125/400.
2025-03-25 12:29:41,872 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:41,872 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:41,873 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #101 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:41,876 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #101
2025-03-25 12:29:41,876 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:41,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:42,677 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800170197/800.
2025-03-25 12:29:42,677 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:42,677 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:42,679 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #102 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:42,684 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #102
2025-03-25 12:29:42,684 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:42,684 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:42,684 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,684 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,684 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,685 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,685 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,685 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:42,685 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:42,686 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000047 on host slave2 for executor with ID 46 for ResourceProfile Id 0
2025-03-25 12:29:42,686 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000048 on host slave1 for executor with ID 47 for ResourceProfile Id 0
2025-03-25 12:29:42,686 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:42,686 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000049 on host slave0 for executor with ID 48 for ResourceProfile Id 0
2025-03-25 12:29:42,686 DEBUG [ContainerLauncher-20] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:42,686 DEBUG [ContainerLauncher-20] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:42,686 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:42,687 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:42,687 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:42,688 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:42,688 DEBUG [ContainerLauncher-20] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:42,688 DEBUG [ContainerLauncher-21] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:42,688 DEBUG [ContainerLauncher-21] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:42,689 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:42,689 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:42,689 DEBUG [ContainerLauncher-21] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:42,691 INFO [ContainerLauncher-20] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:42,692 INFO [ContainerLauncher-21] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:42,696 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:42,696 DEBUG [ContainerLauncher-22] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:42,696 DEBUG [ContainerLauncher-22] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:42,697 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:42,697 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:42,697 DEBUG [ContainerLauncher-22] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:42,699 INFO [ContainerLauncher-22] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:42,699 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:42,699 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:42,700 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1c211f83]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:42,700 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:42,701 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:42,701 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:42,701 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:42,701 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:42,702 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:42,702 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:42,702 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@972ffc9]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:42,702 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:42,703 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:42,703 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:42,703 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@6217013]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:42,703 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:42,703 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:42,703 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:42,703 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@5179b10e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2efe27a9
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@59212975]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:42,704 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"BIZwCCiTZA384VDTOCQfN1OnnHt9sceTcvCTFSSb\",nc=00000001,cnonce=\"TAn40njU79p4ly63rwYf7FnPUzq+Lj1KMxGFfp0u\",digest-uri=\"/default\",maxbuf=65536,response=d943c78aa56da250df85799087c1846e,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@72c8a60d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@6df6200e
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:42,705 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"B2fvHFfCwoP+pQQoq6Nt9okNE+uZN1GUUx/mRQTd\",nc=00000001,cnonce=\"reCs5MqXxq3bwxrqlLXECmKBvLkfoipCTjGAvFNv\",digest-uri=\"/default\",maxbuf=65536,response=0570eed59bde52ea9c29f8de5fc56d62,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@490f279b
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:42,706 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"qj198pl4hP2EJ6VIT+WAlW1jGhdlRAtDk46FM3fk\",nc=00000001,cnonce=\"hCq0iASjVAKrjEy0WmdFC8nzpI5tX7ztzuV94XcP\",digest-uri=\"/default\",maxbuf=65536,response=b832e21f87e512fdca701d9467e10034,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:42,707 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:42,708 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #103 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:42,708 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:42,708 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:42,708 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:42,709 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:42,711 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:42,713 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #105 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:42,715 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #104 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:42,715 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #103
2025-03-25 12:29:42,715 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:42,715 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:42,715 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:42,715 ERROR [ContainerLauncher-21] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 48 on container container_1742905670216_0001_01_000049
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000049 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:42,717 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #104
2025-03-25 12:29:42,717 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #105
2025-03-25 12:29:42,717 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 12ms
2025-03-25 12:29:42,717 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:42,717 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:42,717 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:42,717 ERROR [ContainerLauncher-22] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 47 on container container_1742905670216_0001_01_000048
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000048 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:42,717 ERROR [ContainerLauncher-20] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 46 on container container_1742905670216_0001_01_000047
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000047 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:42,718 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:42,718 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:42,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:43,698 WARN [task-starvation-timer] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
2025-03-25 12:29:43,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:44,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:45,687 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000173385/3000.
2025-03-25 12:29:45,687 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:45,687 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:45,688 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:45,688 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:45,689 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:45,689 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:45,691 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #106 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:45,693 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #106
2025-03-25 12:29:45,693 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:45,694 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:29:45,694 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000047
2025-03-25 12:29:45,694 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000047 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:45,694 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000047. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:45,695 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000048
2025-03-25 12:29:45,695 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000048 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:45,695 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000048. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:45,695 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:29:45,896 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200158597/200.
2025-03-25 12:29:45,896 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:45,896 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:45,897 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #107 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:45,899 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #107
2025-03-25 12:29:45,900 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:45,900 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:29:45,900 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000049
2025-03-25 12:29:45,901 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000049 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:45,901 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000049. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:45,901 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:29:45,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:46,302 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400223368/400.
2025-03-25 12:29:46,302 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:46,302 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:46,303 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #108 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:46,306 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #108
2025-03-25 12:29:46,307 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 5ms
2025-03-25 12:29:46,307 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:46,307 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,307 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,307 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,308 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,308 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,308 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,308 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,308 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:46,308 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:46,308 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:46,308 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,308 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:46,308 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:46,309 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:46,309 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:46,309 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:46,309 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:46,309 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:46,309 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000050 on host slave1 for executor with ID 49 for ResourceProfile Id 0
2025-03-25 12:29:46,309 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000051 on host slave2 for executor with ID 50 for ResourceProfile Id 0
2025-03-25 12:29:46,309 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000052 on host slave0 for executor with ID 51 for ResourceProfile Id 0
2025-03-25 12:29:46,309 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:46,310 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:46,310 DEBUG [ContainerLauncher-23] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:46,310 DEBUG [ContainerLauncher-23] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:46,310 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:46,310 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:46,311 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:46,311 DEBUG [ContainerLauncher-23] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:46,311 DEBUG [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:46,311 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:46,311 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:46,311 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:46,312 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:46,313 INFO [ContainerLauncher-23] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:46,314 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:46,314 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:46,314 INFO [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:46,315 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:46,315 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:46,315 DEBUG [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:46,315 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:46,316 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:46,316 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:46,316 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:46,317 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1eaaeaf2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:46,317 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:46,318 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:46,318 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:46,319 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@5f2edb02]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:46,319 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:46,319 INFO [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:46,320 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:46,320 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:46,320 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:46,320 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:46,320 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:46,320 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:46,320 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@5a3b0d1a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:46,321 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:46,321 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@10f305e3]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:46,321 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:46,321 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:46,321 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:46,322 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:46,322 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:46,322 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@54b9d1b7]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:46,322 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:46,323 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@49748d5a
2025-03-25 12:29:46,323 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:46,323 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:46,323 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"ZzOd1UFOyhyNjkusJkspXvVYcahu9VyUzaoFUiPd\",nc=00000001,cnonce=\"B4xlTNStNHqPSxlXlE4GvqzkjGzxyXmggAWvPVEc\",digest-uri=\"/default\",maxbuf=65536,response=92cb0095d5cac5f22956bf8bd7e4b9fb,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:46,324 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3ab5a970]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@3871dace
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:46,325 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:46,326 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"okIVj+ASi58qdKe937QOh2FHXHQnfuQdG57dXwHb\",nc=00000001,cnonce=\"ncixcIIAuOZycE6MxgyOG5exFjLfD4auZd691yP8\",digest-uri=\"/default\",maxbuf=65536,response=6ef23993e53c4e4113c7322d857c92a2,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:46,328 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #110 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2587bb64
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:46,328 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:46,329 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"lnGeYEyVhbodz5DhnEOgfQu0SqvSoPEB0X5JHgmQ\",nc=00000001,cnonce=\"XRgdcfIAoaEvNtT9KA2IzThjeIaXb+RlfGsfWMRA\",digest-uri=\"/default\",maxbuf=65536,response=8eb3890b66353b7872296a1464afbdd2,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:46,330 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:46,331 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #111 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:46,331 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:46,331 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:46,331 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:46,336 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #109 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:46,340 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #109
2025-03-25 12:29:46,340 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #110
2025-03-25 12:29:46,340 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 19ms
2025-03-25 12:29:46,340 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #111
2025-03-25 12:29:46,340 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:46,340 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:46,340 ERROR [ContainerLauncher-2] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 50 on container container_1742905670216_0001_01_000051
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000051 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:46,340 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 16ms
2025-03-25 12:29:46,340 ERROR [ContainerLauncher-23] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 49 on container container_1742905670216_0001_01_000050
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000050 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:46,341 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 21ms
2025-03-25 12:29:46,341 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:46,341 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:46,341 ERROR [ContainerLauncher-1] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 51 on container container_1742905670216_0001_01_000052
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000052 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:46,341 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:46,341 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:46,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:47,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:48,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:49,310 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000160550/3000.
2025-03-25 12:29:49,310 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:49,310 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:49,311 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:49,311 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:49,311 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:49,312 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:49,312 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:49,313 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #112 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:49,318 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #112
2025-03-25 12:29:49,319 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:49,319 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:29:49,319 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000051
2025-03-25 12:29:49,319 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000051 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:49,319 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000051. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:49,319 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000050
2025-03-25 12:29:49,319 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000050 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:49,319 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000050. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:49,319 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000052
2025-03-25 12:29:49,319 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000052 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:49,319 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000052. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:49,319 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:29:49,519 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200106853/200.
2025-03-25 12:29:49,520 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:49,520 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:49,520 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #113 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:49,521 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #113
2025-03-25 12:29:49,521 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:29:49,922 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400261421/400.
2025-03-25 12:29:49,922 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:49,922 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:49,923 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #114 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:49,925 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #114
2025-03-25 12:29:49,925 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:49,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:50,726 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800189946/800.
2025-03-25 12:29:50,726 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:50,727 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:50,728 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #115 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:50,733 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #115
2025-03-25 12:29:50,733 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:50,734 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:50,734 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000053 on host slave1 for executor with ID 52 for ResourceProfile Id 0
2025-03-25 12:29:50,734 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000054 on host slave0 for executor with ID 53 for ResourceProfile Id 0
2025-03-25 12:29:50,734 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:50,734 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000055 on host slave2 for executor with ID 54 for ResourceProfile Id 0
2025-03-25 12:29:50,734 DEBUG [ContainerLauncher-24] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:50,734 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:50,734 DEBUG [ContainerLauncher-24] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:50,735 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:50,735 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:50,735 DEBUG [ContainerLauncher-24] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:50,736 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:50,736 DEBUG [ContainerLauncher-4] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:50,736 DEBUG [ContainerLauncher-4] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:50,737 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:50,737 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:50,737 DEBUG [ContainerLauncher-4] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:50,738 INFO [ContainerLauncher-24] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:50,738 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:50,738 DEBUG [ContainerLauncher-3] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:50,738 DEBUG [ContainerLauncher-3] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:50,738 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:50,738 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:50,738 DEBUG [ContainerLauncher-3] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:50,738 INFO [ContainerLauncher-4] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:50,739 INFO [ContainerLauncher-3] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@68e73f5d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@362966e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@432007f]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:50,739 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1f79d3]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:50,740 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@4c2fae66]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@227f24d7
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-4] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"RFGzqoXkr5AZXXZvcfR0K9cmAd0GgunzipWhKP92\",nc=00000001,cnonce=\"6MTu0/oyqb+bgETUW85TJc8nBEeYaNC95jwlg007\",digest-uri=\"/default\",maxbuf=65536,response=0a67809b5cdcece763b434a33efe26ab,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@12e04688
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:50,741 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:50,742 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:50,742 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:50,742 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:50,742 DEBUG [ContainerLauncher-24] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"LLpxHVAYmxZG9NWoCWMcsqOUBJAN9lYbJp2HCm80\",nc=00000001,cnonce=\"KZiZVlgvdVWgurKrS+WM46bd2rpZUncxTHiCb0Nm\",digest-uri=\"/default\",maxbuf=65536,response=c4fa6a0c9f58ffd375505911125492d7,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:50,742 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@2cf4a3d5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:50,742 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:50,743 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #118 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@51969887
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:50,743 DEBUG [ContainerLauncher-3] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"7vAwNktk3prgzXJWepGS7BpmkrszoUWg+68TpPsF\",nc=00000001,cnonce=\"G8jEL7fdiB3D5nD+zutwteP9TLGAk/vPBNgc/C2C\",digest-uri=\"/default\",maxbuf=65536,response=49e7fa5b86a9b7aac0dc826f9b7c4920,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:50,744 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:50,744 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #116 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:50,744 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:50,746 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #118
2025-03-25 12:29:50,746 DEBUG [ContainerLauncher-24] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 6ms
2025-03-25 12:29:50,746 ERROR [ContainerLauncher-24] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 52 on container container_1742905670216_0001_01_000053
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000053 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:50,746 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:50,746 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:50,748 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #117 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:50,748 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:50,749 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:50,749 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #116
2025-03-25 12:29:50,749 DEBUG [ContainerLauncher-4] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 9ms
2025-03-25 12:29:50,749 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #117
2025-03-25 12:29:50,749 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:50,749 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:50,749 DEBUG [ContainerLauncher-3] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 9ms
2025-03-25 12:29:50,749 ERROR [ContainerLauncher-3] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 54 on container container_1742905670216_0001_01_000055
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000055 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:50,750 ERROR [ContainerLauncher-4] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 53 on container container_1742905670216_0001_01_000054
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000054 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:50,750 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:50,750 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:50,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:51,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:52,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:53,735 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000153945/3000.
2025-03-25 12:29:53,735 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:53,735 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:53,735 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:53,736 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:53,736 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:53,736 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:53,736 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:53,736 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:53,736 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:53,736 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:53,737 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:53,737 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:53,737 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:53,737 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:53,737 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:53,737 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:53,738 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #119 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:53,740 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #119
2025-03-25 12:29:53,740 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:53,741 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:29:53,741 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000053
2025-03-25 12:29:53,741 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000053 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:53,741 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000053. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:53,741 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:29:53,941 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200245436/200.
2025-03-25 12:29:53,941 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:53,942 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:53,943 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #120 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:53,946 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #120
2025-03-25 12:29:53,946 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:53,946 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:29:53,946 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000055
2025-03-25 12:29:53,947 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000055 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:53,947 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000055. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:53,947 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000054
2025-03-25 12:29:53,947 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000054 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:53,947 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000054. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:53,947 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:29:53,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:54,347 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400151417/400.
2025-03-25 12:29:54,347 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:54,348 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:54,348 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #121 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:54,355 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #121
2025-03-25 12:29:54,355 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 7ms
2025-03-25 12:29:54,356 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:54,356 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,356 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,356 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,357 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,357 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,357 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:54,358 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:54,358 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000056 on host slave1 for executor with ID 55 for ResourceProfile Id 0
2025-03-25 12:29:54,359 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:54,359 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000057 on host slave0 for executor with ID 56 for ResourceProfile Id 0
2025-03-25 12:29:54,359 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:54,359 DEBUG [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:54,359 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:54,359 DEBUG [ContainerLauncher-8] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:54,359 DEBUG [ContainerLauncher-8] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:54,359 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000058 on host slave2 for executor with ID 57 for ResourceProfile Id 0
2025-03-25 12:29:54,360 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:54,360 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:54,360 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:54,360 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:54,360 DEBUG [ContainerLauncher-5] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:54,360 DEBUG [ContainerLauncher-5] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:54,361 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:54,361 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:54,361 DEBUG [ContainerLauncher-5] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:54,363 INFO [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:54,364 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:54,364 INFO [ContainerLauncher-5] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:54,365 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:54,365 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:54,365 DEBUG [ContainerLauncher-8] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:54,367 INFO [ContainerLauncher-8] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:54,367 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:54,368 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:54,368 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:54,368 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:54,368 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@290d46f5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:54,368 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:54,368 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@315bf66d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@23a83149]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:54,369 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1753d09a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@20c5346e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@179107fb
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:54,370 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3a4c2d2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"PzTHKYnMo8/PAwyy9mv6BBpMUsW6XIn5BRJX1Fu9\",nc=00000001,cnonce=\"KXp/Dch+Op11whhNMQOPfaO+6/hS04dt5gZfVDLW\",digest-uri=\"/default\",maxbuf=65536,response=9db9f14157a81a15ed309276b078ae07,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7c88a524
2025-03-25 12:29:54,371 DEBUG [ContainerLauncher-8] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@5009188e
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-8] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"7nOdKaI3jrhvxflxSYhBD61mArldQ1Su6YKz/0HJ\",nc=00000001,cnonce=\"lJLthfUsvFoq4CT7VK2sV9dFpk2j5e7uk8bvNe+c\",digest-uri=\"/default\",maxbuf=65536,response=42585781285c6b3c67f20f12bd4b007c,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-5] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"xg6yq3jOkWs4QOecgWjupQWuZvWYR3JzwlFxzDnx\",nc=00000001,cnonce=\"Ec+8RXHb5Q4aLvq2NcTLLrjU3YPFfZjpb79RJPgy\",digest-uri=\"/default\",maxbuf=65536,response=13d9915f053951ffc07127b85e58e1f4,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:54,372 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:54,373 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:54,373 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:54,373 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:54,374 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:54,374 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #122 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:54,376 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #123 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:54,380 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #124 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:54,382 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #122
2025-03-25 12:29:54,382 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 13ms
2025-03-25 12:29:54,382 ERROR [ContainerLauncher-0] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 55 on container container_1742905670216_0001_01_000056
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000056 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:54,382 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:54,382 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:54,384 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:29:54,384 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #123
2025-03-25 12:29:54,384 DEBUG [ContainerLauncher-5] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 15ms
2025-03-25 12:29:54,384 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:54,384 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:54,384 ERROR [ContainerLauncher-5] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 57 on container container_1742905670216_0001_01_000058
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000058 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:54,384 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #124
2025-03-25 12:29:54,384 DEBUG [ContainerLauncher-8] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:54,385 ERROR [ContainerLauncher-8] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 56 on container container_1742905670216_0001_01_000057
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000057 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:54,385 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:54,385 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:54,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:55,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:56,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:57,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000095203/3000.
2025-03-25 12:29:57,364 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:57,365 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:29:57,365 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:29:57,366 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:29:57,366 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:29:57,368 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #125 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:57,372 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #125
2025-03-25 12:29:57,372 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 5ms
2025-03-25 12:29:57,373 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:29:57,373 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000056
2025-03-25 12:29:57,373 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000056 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:57,373 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000056. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:57,373 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:29:57,573 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200147788/200.
2025-03-25 12:29:57,574 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:57,574 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:57,575 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #126 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:57,578 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #126
2025-03-25 12:29:57,578 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:29:57,579 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:29:57,579 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000058
2025-03-25 12:29:57,579 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000058 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:57,579 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000058. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:57,579 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000057
2025-03-25 12:29:57,579 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000057 (state: COMPLETE, exit status: -100)
2025-03-25 12:29:57,579 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000057. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:29:57,580 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:29:57,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:57,980 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400186085/400.
2025-03-25 12:29:57,981 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:57,981 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:57,982 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #127 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:57,985 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #127
2025-03-25 12:29:57,985 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:29:58,698 WARN [task-starvation-timer] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
2025-03-25 12:29:58,786 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800067807/800.
2025-03-25 12:29:58,786 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:29:58,786 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:29:58,786 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #128 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:29:58,788 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #128
2025-03-25 12:29:58,788 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:29:58,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:29:58,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,788 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,789 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,789 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,789 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:29:58,789 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:29:58,789 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000059 on host slave1 for executor with ID 58 for ResourceProfile Id 0
2025-03-25 12:29:58,789 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000060 on host slave0 for executor with ID 59 for ResourceProfile Id 0
2025-03-25 12:29:58,789 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000061 on host slave2 for executor with ID 60 for ResourceProfile Id 0
2025-03-25 12:29:58,789 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:29:58,789 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:58,789 DEBUG [ContainerLauncher-6] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:58,789 DEBUG [ContainerLauncher-6] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:58,790 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:58,790 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:58,790 DEBUG [ContainerLauncher-6] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:58,791 INFO [ContainerLauncher-6] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:58,791 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:29:58,792 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:58,792 DEBUG [ContainerLauncher-9] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:58,792 DEBUG [ContainerLauncher-9] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:58,792 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:58,810 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:58,810 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:58,810 DEBUG [ContainerLauncher-9] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:58,811 INFO [ContainerLauncher-9] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:58,811 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:58,812 DEBUG [ContainerLauncher-11] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:29:58,812 DEBUG [ContainerLauncher-11] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:29:58,812 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:29:58,812 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:29:58,812 DEBUG [ContainerLauncher-11] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:29:58,812 INFO [ContainerLauncher-11] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:29:58,813 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@5af71365]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:58,813 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:58,813 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:58,813 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:58,813 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:29:58,813 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:29:58,814 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@ce5deec]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:58,814 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:58,814 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:29:58,814 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:58,814 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@50afce7b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:58,814 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:58,815 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:58,815 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:58,815 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:29:58,815 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:29:58,815 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@5da1513b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:58,815 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@321c75e8]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:29:58,816 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@532dac0a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@630b119d
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:58,817 DEBUG [ContainerLauncher-9] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"YpfqiDZ3LvyTJd3Az4+1+GK40M1GzqusY9xsJhZL\",nc=00000001,cnonce=\"EdZ6uBuSGVBXURAOXrtCqyZ9njOnMHYlPBoVfCv+\",digest-uri=\"/default\",maxbuf=65536,response=8700c66d161bc9d9616ec7b2be95bf75,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@6b6eb016
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-11] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"h9XWOmQJWNwS3M4P7lMTSnICvqrReyU/l45ayCfn\",nc=00000001,cnonce=\"beZ6xXF0pdyqAy8fk2yQtWZVsa4H9XM0lddvHC5k\",digest-uri=\"/default\",maxbuf=65536,response=9267a592aa010c93e6948d9aff48a261,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@17f326e1
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-6] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"29RQZ8ac8NXsKSMg87s4KtvL9mCXo/Hmq69CCD7A\",nc=00000001,cnonce=\"SRJtvwWHnYoAyk58IZzV1hQe+gWc5EMkaZHKr/KG\",digest-uri=\"/default\",maxbuf=65536,response=c66082d0274ffe111510fc868117e61f,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:29:58,819 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:58,820 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:58,821 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:29:58,824 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #130 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:58,827 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:58,827 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:58,827 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:29:58,828 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #131 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:58,828 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #129 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:29:58,829 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #130
2025-03-25 12:29:58,829 DEBUG [ContainerLauncher-9] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:58,829 ERROR [ContainerLauncher-9] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 59 on container container_1742905670216_0001_01_000060
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000060 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #131
2025-03-25 12:29:58,830 DEBUG [ContainerLauncher-11] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:29:58,830 ERROR [ContainerLauncher-11] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 60 on container container_1742905670216_0001_01_000061
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000061 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #129
2025-03-25 12:29:58,830 DEBUG [ContainerLauncher-6] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:29:58,830 ERROR [ContainerLauncher-6] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 58 on container container_1742905670216_0001_01_000059
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000059 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:29:58,830 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:29:58,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:29:59,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:00,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:01,789 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000106878/3000.
2025-03-25 12:30:01,790 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:01,790 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:30:01,790 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:01,791 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:30:01,791 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:30:01,793 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #132 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:01,795 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #132
2025-03-25 12:30:01,795 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:30:01,796 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:30:01,796 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000061
2025-03-25 12:30:01,796 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000061 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:01,796 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000061. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:01,796 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000059
2025-03-25 12:30:01,796 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000059 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:01,796 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000059. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:01,796 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000060
2025-03-25 12:30:01,796 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000060 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:01,796 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000060. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:01,796 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:30:01,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:01,997 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200156869/200.
2025-03-25 12:30:01,997 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:01,997 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:01,998 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #133 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:02,000 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #133
2025-03-25 12:30:02,001 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:30:02,401 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400092560/400.
2025-03-25 12:30:02,401 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:02,402 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:02,402 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #134 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:02,406 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #134
2025-03-25 12:30:02,406 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-25 12:30:02,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:30:02,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,406 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,409 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,409 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,409 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,409 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,409 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:02,409 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:30:02,410 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:30:02,410 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000062 on host slave1 for executor with ID 61 for ResourceProfile Id 0
2025-03-25 12:30:02,410 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:02,410 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000063 on host slave0 for executor with ID 62 for ResourceProfile Id 0
2025-03-25 12:30:02,410 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000064 on host slave2 for executor with ID 63 for ResourceProfile Id 0
2025-03-25 12:30:02,410 DEBUG [ContainerLauncher-7] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:02,411 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:30:02,411 DEBUG [ContainerLauncher-7] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:02,411 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:02,411 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:02,411 DEBUG [ContainerLauncher-7] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:02,412 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:02,412 DEBUG [ContainerLauncher-14] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:02,412 DEBUG [ContainerLauncher-14] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:02,413 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:02,413 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:02,413 DEBUG [ContainerLauncher-14] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:02,415 INFO [ContainerLauncher-7] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:02,415 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:02,415 DEBUG [ContainerLauncher-10] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:02,415 DEBUG [ContainerLauncher-10] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:02,416 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:02,416 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:02,416 DEBUG [ContainerLauncher-10] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:02,416 INFO [ContainerLauncher-14] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:02,419 INFO [ContainerLauncher-10] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:02,421 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:30:02,421 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:02,422 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@4d947d67]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:02,422 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:02,422 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:02,423 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:02,423 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:30:02,423 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:30:02,424 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:30:02,425 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:02,425 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@bb7f373]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:02,425 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:02,425 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:02,426 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:30:02,426 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:02,426 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@30988861]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:02,427 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:02,427 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1965dacc]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:30:02,428 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@45854a08]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@7f4c620a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2851ef8b
2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-7] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:02,429 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:02,430 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:30:02,430 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:02,430 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:02,430 DEBUG [ContainerLauncher-7] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"6o1QU9s9rT2kwg2s8C1LXu7TGM+nR7vOZ+kJ+lPA\",nc=00000001,cnonce=\"SKjhw42gMtaFTZDfVZvAPmFW/ohE5AUwlaZVasXB\",digest-uri=\"/default\",maxbuf=65536,response=bc39a7a54d8bbdd724e02c69d3792306,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:02,431 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:02,431 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #137 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:02,431 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4e75f372
2025-03-25 12:30:02,431 DEBUG [ContainerLauncher-10] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:02,431 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:02,432 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:02,432 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:30:02,432 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:02,432 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:02,432 DEBUG [ContainerLauncher-10] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"8/4MH996h13H11IQ7UEZEJDATITxFs4P3Of8ymf4\",nc=00000001,cnonce=\"Zu0OXdyOA3U/cwNcooCI6a+PTaUxIVpQFHasUjp4\",digest-uri=\"/default\",maxbuf=65536,response=39a65530117f832069e6fa7fc273dbc5,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:02,433 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:02,436 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #136 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:02,436 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:02,436 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4c358345
2025-03-25 12:30:02,436 DEBUG [ContainerLauncher-14] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:02,436 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:02,437 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:02,437 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:30:02,437 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:02,437 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:02,437 DEBUG [ContainerLauncher-14] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"zvPgEUpZmPq54MUioqnVA5QgGIsrgW1+m8s47eZO\",nc=00000001,cnonce=\"evFlm7UWR9E4rn3B9aru9NRtMXmG0vKVPUnspkJs\",digest-uri=\"/default\",maxbuf=65536,response=c42866fa39a067f53d7436931c9a03fb,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:02,438 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:02,438 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #137
2025-03-25 12:30:02,438 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:02,438 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:30:02,438 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:30:02,444 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:30:02,444 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #136
2025-03-25 12:30:02,444 DEBUG [ContainerLauncher-10] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 18ms
2025-03-25 12:30:02,444 ERROR [ContainerLauncher-10] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 63 on container container_1742905670216_0001_01_000064
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000064 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:02,444 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:02,449 DEBUG [ContainerLauncher-7] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 22ms
2025-03-25 12:30:02,449 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #135 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:02,450 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:30:02,450 ERROR [ContainerLauncher-7] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 61 on container container_1742905670216_0001_01_000062
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000062 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:02,453 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #135
2025-03-25 12:30:02,453 DEBUG [ContainerLauncher-14] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 30ms
2025-03-25 12:30:02,453 ERROR [ContainerLauncher-14] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 62 on container container_1742905670216_0001_01_000063
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000063 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:02,453 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:02,453 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:30:02,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:03,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:04,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000109380/3000.
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:30:05,411 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:05,411 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:05,412 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:05,412 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:05,412 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:05,412 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:30:05,412 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:30:05,412 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #138 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:05,413 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #138
2025-03-25 12:30:05,413 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:30:05,414 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-25 12:30:05,414 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000062
2025-03-25 12:30:05,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000062 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:05,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000062. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:05,414 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000063
2025-03-25 12:30:05,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000063 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:05,414 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000063. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:05,414 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 0.
2025-03-25 12:30:05,614 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200071096/200.
2025-03-25 12:30:05,614 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:05,614 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:05,615 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #139 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:05,617 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #139
2025-03-25 12:30:05,617 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:30:05,618 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 1 containers
2025-03-25 12:30:05,618 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000064
2025-03-25 12:30:05,618 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000064 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:05,618 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000064. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:05,618 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 1 completed containers. Current running executor count: 0.
2025-03-25 12:30:05,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:06,019 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400186246/400.
2025-03-25 12:30:06,019 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:06,019 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:06,020 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #140 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:06,022 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #140
2025-03-25 12:30:06,022 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:30:06,823 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800134871/800.
2025-03-25 12:30:06,823 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:06,823 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:06,824 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #141 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:06,826 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #141
2025-03-25 12:30:06,826 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:06,827 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:06,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:30:06,828 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:30:06,828 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000065 on host slave1 for executor with ID 64 for ResourceProfile Id 0
2025-03-25 12:30:06,828 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000066 on host slave2 for executor with ID 65 for ResourceProfile Id 0
2025-03-25 12:30:06,828 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000067 on host slave0 for executor with ID 66 for ResourceProfile Id 0
2025-03-25 12:30:06,828 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:30:06,828 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:06,828 DEBUG [ContainerLauncher-12] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:06,828 DEBUG [ContainerLauncher-12] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:06,828 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:06,828 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:06,828 DEBUG [ContainerLauncher-12] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:06,829 INFO [ContainerLauncher-12] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:06,829 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:06,829 DEBUG [ContainerLauncher-16] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:06,829 DEBUG [ContainerLauncher-16] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:06,830 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:06,830 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:06,830 DEBUG [ContainerLauncher-16] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:06,830 INFO [ContainerLauncher-16] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:06,830 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:30:06,830 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1a3f2c6a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:30:06,831 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@378c7a24]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:06,832 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:06,832 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:06,832 DEBUG [ContainerLauncher-13] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:06,832 DEBUG [ContainerLauncher-13] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:06,832 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:06,832 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:06,832 DEBUG [ContainerLauncher-13] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:06,833 INFO [ContainerLauncher-13] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:06,833 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@4c5f44c8]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:06,833 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:06,833 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@44469809]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:06,833 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1b7a24e1]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:06,834 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@2f82f5c7]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:06,833 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@65defaa
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@500b580d
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-16] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:06,835 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@39af3df6
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-16] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"8b7D3DCGzg3cTrcpU9Ls+cNnlsT74zfa95PUb6q0\",nc=00000001,cnonce=\"hdp58AN+DuqYmk/YOwzgW6DVqVFN3wguLNDdsipW\",digest-uri=\"/default\",maxbuf=65536,response=19d555df6f2eb4d8e01c19908db400b8,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-12] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"XKGCWVORc7RX08ygnvIdWhRwkYqYpzWyLbjPl9+3\",nc=00000001,cnonce=\"j/xGkE6rRSZxmzVgoWfaqVzx3qOwK4q3ykpnRNXr\",digest-uri=\"/default\",maxbuf=65536,response=1e37d17f13a18ae0ddb2db337f1ad174,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:06,836 DEBUG [ContainerLauncher-13] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"pnG9Isv8s9CWNHuc6v5F5NvD+t86cXUZJKmyP9pk\",nc=00000001,cnonce=\"iP/9ALDRvydzD8IjVxPqjpC3x3aFZC5xj+B8Qvsc\",digest-uri=\"/default\",maxbuf=65536,response=5f84b1fb7a88a6203b0ee93151f20161,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:06,837 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:06,838 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #143 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:06,839 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:06,839 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:06,839 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #142 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:06,839 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:06,839 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:06,839 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:06,840 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #143
2025-03-25 12:30:06,840 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:06,840 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:30:06,840 DEBUG [ContainerLauncher-12] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 7ms
2025-03-25 12:30:06,840 ERROR [ContainerLauncher-12] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 64 on container container_1742905670216_0001_01_000065
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000065 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:06,841 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #144 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:06,841 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #142
2025-03-25 12:30:06,841 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:06,841 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:30:06,842 DEBUG [ContainerLauncher-16] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 11ms
2025-03-25 12:30:06,842 ERROR [ContainerLauncher-16] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 65 on container container_1742905670216_0001_01_000066
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000066 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:06,843 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #144
2025-03-25 12:30:06,843 DEBUG [ContainerLauncher-13] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 8ms
2025-03-25 12:30:06,843 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:06,843 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:30:06,843 ERROR [ContainerLauncher-13] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 66 on container container_1742905670216_0001_01_000067
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000067 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:06,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:07,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:08,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:09,828 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000088326/3000.
2025-03-25 12:30:09,828 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:09,828 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:30:09,829 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:30:09,829 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:09,830 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:30:09,830 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:30:09,831 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #145 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:09,835 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #145
2025-03-25 12:30:09,836 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 5ms
2025-03-25 12:30:09,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:10,037 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200111176/200.
2025-03-25 12:30:10,037 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:10,037 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:10,037 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #146 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:10,038 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #146
2025-03-25 12:30:10,038 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:30:10,038 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:30:10,038 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000066
2025-03-25 12:30:10,038 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000066 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:10,038 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000066. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:10,038 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000065
2025-03-25 12:30:10,038 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000065 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:10,038 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000065. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:10,038 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000067
2025-03-25 12:30:10,038 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000067 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:10,038 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000067. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:10,038 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:30:10,439 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400136090/400.
2025-03-25 12:30:10,439 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:10,439 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:10,439 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #147 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:10,442 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #147
2025-03-25 12:30:10,442 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-25 12:30:10,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:30:10,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,442 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,443 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,443 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,443 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:30:10,443 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:30:10,443 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000068 on host slave1 for executor with ID 67 for ResourceProfile Id 0
2025-03-25 12:30:10,443 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000069 on host slave2 for executor with ID 68 for ResourceProfile Id 0
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-19] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-17] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-19] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-17] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:10,443 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000070 on host slave0 for executor with ID 69 for ResourceProfile Id 0
2025-03-25 12:30:10,443 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:10,443 DEBUG [ContainerLauncher-17] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:10,444 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:10,444 DEBUG [ContainerLauncher-15] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:10,444 DEBUG [ContainerLauncher-15] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:10,444 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:10,444 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:10,444 DEBUG [ContainerLauncher-15] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:10,444 INFO [ContainerLauncher-17] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:10,445 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:30:10,445 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:10,445 INFO [ContainerLauncher-15] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:10,445 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:30:10,445 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:10,445 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@7061ae58]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:10,445 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-19] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:30:10,446 INFO [ContainerLauncher-19] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@35a84c73]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@12db9e3]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@6cf517e4]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@48e5739d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:10,446 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@46d9ec8e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:10,447 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7c3a47a0
2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:10,448 DEBUG [ContainerLauncher-17] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"CK7Ow4qTm1miX3Vu5zGJtCsPiHWVR5u7oZG5wv4Y\",nc=00000001,cnonce=\"eIkT8HkXKW7sWD0foAfUbZ7PlLPNtJVF2aQCFmki\",digest-uri=\"/default\",maxbuf=65536,response=aad948c9b4e113d95378af0dda979877,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@7923f172
2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-19] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:10,449 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-19] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"dLC0gVBhaqIC2kXRt6aNRZVMT8F7VK3W6NL6Xog6\",nc=00000001,cnonce=\"6Gz0PVZJsZzWrULiSr4IR8yZR41MoRlOAn/TKbe4\",digest-uri=\"/default\",maxbuf=65536,response=b0ce7102c98f054f107277a18b6f59da,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@67332040
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:10,450 DEBUG [ContainerLauncher-15] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"rkUc0ji7b/gJrT2gb6cZ4VGwkeGMK+QWoCmRwBvO\",nc=00000001,cnonce=\"Zs8+meAXLOSpNQGJOj4hLzUWk6AjZWdI4UOlb6CM\",digest-uri=\"/default\",maxbuf=65536,response=4f144b4e22a1cff4c0e1e1921cfc05f2,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:10,460 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #149 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:10,460 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:10,460 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:10,460 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:10,461 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:10,462 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:10,462 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #148 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:10,462 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #150 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:10,462 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #149
2025-03-25 12:30:10,462 DEBUG [ContainerLauncher-17] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 15ms
2025-03-25 12:30:10,462 ERROR [ContainerLauncher-17] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 67 on container container_1742905670216_0001_01_000068
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000068 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:10,463 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #150
2025-03-25 12:30:10,463 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:10,463 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:30:10,464 DEBUG [ContainerLauncher-19] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:30:10,464 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:10,464 ERROR [ContainerLauncher-19] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 68 on container container_1742905670216_0001_01_000069
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000069 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:10,464 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:30:10,464 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #148
2025-03-25 12:30:10,464 DEBUG [ContainerLauncher-15] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 18ms
2025-03-25 12:30:10,464 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:10,464 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:30:10,464 ERROR [ContainerLauncher-15] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 69 on container container_1742905670216_0001_01_000070
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000070 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:10,955 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:11,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:12,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000104902/3000.
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:30:13,444 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:13,444 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:30:13,444 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:30:13,444 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #151 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:13,446 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #151
2025-03-25 12:30:13,446 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:30:13,446 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:30:13,446 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000069
2025-03-25 12:30:13,446 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000069 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:13,446 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000069. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:13,446 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000068
2025-03-25 12:30:13,446 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000068 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:13,446 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000068. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:13,446 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000070
2025-03-25 12:30:13,446 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000070 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:13,446 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000070. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:13,446 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:30:13,647 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200108831/200.
2025-03-25 12:30:13,647 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:13,647 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:13,647 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #152 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:13,648 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #152
2025-03-25 12:30:13,648 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:30:13,698 WARN [task-starvation-timer] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
2025-03-25 12:30:13,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:14,048 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400107642/400.
2025-03-25 12:30:14,049 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:14,049 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:14,049 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #153 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:14,050 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #153
2025-03-25 12:30:14,050 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:30:14,850 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 800064202/800.
2025-03-25 12:30:14,850 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:14,850 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:14,851 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #154 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:14,852 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #154
2025-03-25 12:30:14,852 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:30:14,853 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:30:14,853 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000071 on host slave1 for executor with ID 70 for ResourceProfile Id 0
2025-03-25 12:30:14,854 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000072 on host slave2 for executor with ID 71 for ResourceProfile Id 0
2025-03-25 12:30:14,854 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000073 on host slave0 for executor with ID 72 for ResourceProfile Id 0
2025-03-25 12:30:14,854 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-21] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-18] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-21] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-22] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-22] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-18] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-21] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:14,854 DEBUG [ContainerLauncher-18] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:14,855 INFO [ContainerLauncher-18] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:14,855 INFO [ContainerLauncher-21] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:14,855 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:30:14,855 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:14,855 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:14,855 DEBUG [ContainerLauncher-22] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:14,855 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:14,855 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@336b3070]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:14,856 INFO [ContainerLauncher-22] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@4af84489]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:14,856 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@61f7bcf2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@d6bfe28]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@4225aa1b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:30:14,857 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1738c15e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@3810aea9
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-21] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"bARLY+BXw5zWE/jbksygBh82hRPBsGCfdJrLFgxM\",nc=00000001,cnonce=\"sjjcGmfDtEhcbckk+OUrXDAwlxGiUl2yj/CH5h6x\",digest-uri=\"/default\",maxbuf=65536,response=34d84556d50ed053df1893c92ed1c51f,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@5108d5bf
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:14,858 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-18] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"U5UDEmRtifVqih1SVCTiPnF932XzSNYIogurwJU0\",nc=00000001,cnonce=\"NyYNEBH+KDCak2TpsBvgVNSrVOuc5TvCDtIOZsI1\",digest-uri=\"/default\",maxbuf=65536,response=a9ebc2aa3aee8db957b1a8706c8d79af,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@64f39442
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:14,859 DEBUG [ContainerLauncher-22] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"v4rjXT3d4ByhiV5HjWuEuWRTkTW3d8ec4Y/XjWbb\",nc=00000001,cnonce=\"GC8Unc+K7Lgxw0pjYCL7prcJDm0Z18RyEdGZ84Zj\",digest-uri=\"/default\",maxbuf=65536,response=323f61097291c606794e5a4d5a7ce70b,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:14,860 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:14,861 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #156 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:14,861 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:14,862 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:14,863 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:14,863 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #157 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:14,863 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:14,863 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #156
2025-03-25 12:30:14,872 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:14,872 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:30:14,872 DEBUG [ContainerLauncher-22] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 15ms
2025-03-25 12:30:14,872 ERROR [ContainerLauncher-22] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 72 on container container_1742905670216_0001_01_000073
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000073 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:14,868 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:14,873 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #155 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:14,873 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #157
2025-03-25 12:30:14,873 DEBUG [ContainerLauncher-18] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 16ms
2025-03-25 12:30:14,873 ERROR [ContainerLauncher-18] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 70 on container container_1742905670216_0001_01_000071
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000071 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:14,873 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:14,873 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:30:14,874 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #155
2025-03-25 12:30:14,874 DEBUG [ContainerLauncher-21] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 17ms
2025-03-25 12:30:14,874 ERROR [ContainerLauncher-21] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 71 on container container_1742905670216_0001_01_000072
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000072 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:14,874 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:14,874 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:30:14,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:15,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:16,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000107244/3000.
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-25 12:30:17,854 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:17,854 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:17,855 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:17,855 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:17,855 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:17,855 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-25 12:30:17,855 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-25 12:30:17,855 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-25 12:30:17,855 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #158 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:17,856 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #158
2025-03-25 12:30:17,857 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:30:17,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:18,057 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200114740/200.
2025-03-25 12:30:18,057 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:18,057 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:18,057 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #159 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:18,058 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #159
2025-03-25 12:30:18,058 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-25 12:30:18,059 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 3 containers
2025-03-25 12:30:18,059 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000072
2025-03-25 12:30:18,059 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000072 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:18,059 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000072. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:18,059 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000071
2025-03-25 12:30:18,059 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000071 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:18,059 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000071. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:18,059 WARN [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1742905670216_0001_01_000073
2025-03-25 12:30:18,059 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed container container_1742905670216_0001_01_000073 (state: COMPLETE, exit status: -100)
2025-03-25 12:30:18,059 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Container marked as failed: container_1742905670216_0001_01_000073. Exit status: -100. Diagnostics: Container released by application.
2025-03-25 12:30:18,059 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 3 completed containers. Current running executor count: 0.
2025-03-25 12:30:18,459 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400229307/400.
2025-03-25 12:30:18,459 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-25 12:30:18,460 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-25 12:30:18,460 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #160 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-25 12:30:18,462 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #160
2025-03-25 12:30:18,462 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-25 12:30:18,462 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-25 12:30:18,462 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,462 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,462 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,463 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,463 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,463 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-25 12:30:18,463 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-25 12:30:18,463 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000074 on host slave1 for executor with ID 73 for ResourceProfile Id 0
2025-03-25 12:30:18,463 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000075 on host slave2 for executor with ID 74 for ResourceProfile Id 0
2025-03-25 12:30:18,463 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742905670216_0001_01_000076 on host slave0 for executor with ID 75 for ResourceProfile Id 0
2025-03-25 12:30:18,463 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:18,463 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-25 12:30:18,463 DEBUG [ContainerLauncher-20] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:18,463 DEBUG [ContainerLauncher-20] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-20] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-23] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-23] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:18,464 DEBUG [ContainerLauncher-23] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:18,465 INFO [ContainerLauncher-20] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:18,465 INFO [ContainerLauncher-23] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:18,466 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:18,466 DEBUG [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-25 12:30:18,466 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-25 12:30:18,466 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-25 12:30:18,466 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-25 12:30:18,466 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-25 12:30:18,467 INFO [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Initializing service data for shuffle service using name 'spark_shuffle'
2025-03-25 12:30:18,467 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:41289
2025-03-25 12:30:18,467 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:41877
2025-03-25 12:30:18,467 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:18,467 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:18,467 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@61a09d89]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:18,467 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@65f79241]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:35961
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:41289
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:41289
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@2fcb0dd]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:18,468 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1f3bf478]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@243a39a2
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:41289. Current token is Kind: NMToken, Service: 172.20.1.12:41289, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave1" port: 41289 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:35961
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:35961
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-20] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMRDJwgIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"EGPZFhyTvgxB47honidVdLDp3dIkKFrUe7TLvH5i\",nc=00000001,cnonce=\"YpBHfiPVXMo0QPQNyLOtAgPqG50ob9gioDjFINaf\",digest-uri=\"/default\",maxbuf=65536,response=0593de33af06c6a0ca4fa89676af8726,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3b37892]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: getting client out of cache: Client-4c235dce65674d808398f2cb1ae359e8
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-25 12:30:18,469 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:41877
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:41877
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742905670216_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@530af007]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@5654b688
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:35961. Current token is Kind: NMToken, Service: 172.20.1.13:35961, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave2" port: 35961 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:18,470 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMhD5mAIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"9RfjdWrgUqSIMSzTtGoQsN2hLsXwYJG2Fo6gh3i4\",nc=00000001,cnonce=\"xCCAq7CsireQG0bL8z5h45xQ4BNU/qcG8CJW9OBf\",digest-uri=\"/default\",maxbuf=65536,response=8373321c3cff0354f66d39c4bfb6b1c6,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:18,471 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:18,472 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 sending #162 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:18,472 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:18,472 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:18,472 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@59b84dd9
2025-03-25 12:30:18,476 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 sending #161 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:18,472 DEBUG [ContainerLauncher-23] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:41877. Current token is Kind: NMToken, Service: 172.20.1.11:41877, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742905670216 } attemptId: 1 } nodeId { host: "slave0" port: 41877 } appSubmitter: "root" keyId: 938234785)
2025-03-25 12:30:18,476 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-25 12:30:18,476 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-25 12:30:18,476 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=
2025-03-25 12:30:18,476 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-25 12:30:18,476 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-25 12:30:18,476 DEBUG [ContainerLauncher-23] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEMj0l+rcMhABEgwKBnNsYXZlMBCVxwIaBHJvb3QgoaexvwM=\",realm=\"default\",nonce=\"19nWWwISdoT+ujDPlZhlMPE3SurqekbKWWgZa8hI\",nc=00000001,cnonce=\"PMttudhKlIZMYNiIrP8aGG2Oe8kbq9lPZEnugA7r\",digest-uri=\"/default\",maxbuf=65536,response=0b88df3d9002ac603e2d321c8bab2e3f,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-25 12:30:18,479 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-25 12:30:18,479 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: starting, having connections 4
2025-03-25 12:30:18,480 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001 got value #162
2025-03-25 12:30:18,480 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:18,480 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:35961 from appattempt_1742905670216_0001_000001: stopped, remaining connections 3
2025-03-25 12:30:18,480 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 11ms
2025-03-25 12:30:18,480 ERROR [ContainerLauncher-2] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 74 on container container_1742905670216_0001_01_000075
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000075 on host slave2
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:18,480 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: starting, having connections 3
2025-03-25 12:30:18,481 DEBUG [IPC Parameter Sending Thread #2] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 sending #163 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-25 12:30:18,483 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001 got value #161
2025-03-25 12:30:18,483 DEBUG [ContainerLauncher-20] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 15ms
2025-03-25 12:30:18,483 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:18,483 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:41289 from appattempt_1742905670216_0001_000001: stopped, remaining connections 2
2025-03-25 12:30:18,483 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001 got value #163
2025-03-25 12:30:18,483 DEBUG [ContainerLauncher-23] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 14ms
2025-03-25 12:30:18,483 ERROR [ContainerLauncher-20] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 73 on container container_1742905670216_0001_01_000074
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000074 on host slave1
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:18,484 ERROR [ContainerLauncher-23] org.apache.spark.deploy.yarn.YarnAllocator: Failed to launch executor 75 on container container_1742905670216_0001_01_000076
org.apache.spark.SparkException: Exception while starting container container_1742905670216_0001_01_000076 on host slave0
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:128)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:spark_shuffle does not exist
	at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:217)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	... 5 more
2025-03-25 12:30:18,484 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: closed
2025-03-25 12:30:18,484 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:41877 from appattempt_1742905670216_0001_000001: stopped, remaining connections 1
2025-03-25 12:30:18,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-25 12:30:19,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
